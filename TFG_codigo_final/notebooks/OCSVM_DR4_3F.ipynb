{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fname = \"../data/catalog_data_4FGL_DR4.h5\"\n",
    "\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    # read attributes\n",
    "    E0 = f.attrs[\"E0\"]\n",
    "    \n",
    "    # read assoc data (fuentes conocidas - datos de entrenamiento)\n",
    "    alpha_as = f[\"assoc\"][\"alpha\"][:]\n",
    "    beta_as = f[\"assoc\"][\"beta\"][:]\n",
    "    flux_as = f[\"assoc\"][\"flux\"][:]\n",
    "    \n",
    "    # read unassoc data (candidatos a materia oscura)\n",
    "    alpha_unas = f[\"unas\"][\"alpha\"][:]\n",
    "    beta_unas = f[\"unas\"][\"beta\"][:]\n",
    "    flux_unas = f[\"unas\"][\"flux\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('E0 (energy): attribute value', E0)\n",
    "print('UNAS - alpha, beta & flux shape: ', alpha_unas.shape, beta_unas.shape, flux_unas.shape)\n",
    "print('AS - alpha, beta & flux shape: ', alpha_as.shape, beta_as.shape, flux_as.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_as = pd.DataFrame({\n",
    "    'alpha': alpha_as,\n",
    "    'beta': beta_as,\n",
    "    'flux': flux_as\n",
    "})\n",
    "\n",
    "df_unas = pd.DataFrame({\n",
    "    'alpha': alpha_unas,\n",
    "    'beta': beta_unas,\n",
    "    'flux': flux_unas\n",
    "})\n",
    "\n",
    "print(f\"Datos cargados exitosamente:\")\n",
    "print(f\"- Fuentes asociadas (entrenamiento): {len(df_as)}\")\n",
    "print(f\"- Fuentes no asociadas (predicción): {len(df_unas)}\")\n",
    "print(f\"- Energía de referencia E0: {E0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check the data conversion\n",
    "df_as.shape[0] == len(alpha_as)\n",
    "df_unas.shape[0] == len(alpha_unas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_as.shape)\n",
    "df_as.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_unas.shape)\n",
    "df_unas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Associated sources: ')\n",
    "df_as.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nUnassociated sources:')\n",
    "df_unas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEstadísticas descriptivas - Fuentes Asociadas:\")\n",
    "print(df_as.describe())\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas - Fuentes No Asociadas:\")\n",
    "print(df_unas.describe())\n",
    "\n",
    "# Verificar calidad de datos\n",
    "print(f\"\\nCalidad de datos:\")\n",
    "print(f\"- Valores nulos en asociadas: {df_as.isnull().sum().sum()}\")\n",
    "print(f\"- Valores nulos en no asociadas: {df_unas.isnull().sum().sum()}\")\n",
    "print(f\"- Valores infinitos en asociadas: {np.isinf(df_as.values).sum()}\")\n",
    "print(f\"- Valores infinitos en no asociadas: {np.isinf(df_unas.values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data the same way to check the distributions\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "nbins = 15\n",
    "unas_color = \"#3e4550\"\n",
    "as_color = \"#c2d9c7\"\n",
    "\n",
    "fig.suptitle(r\"4FGL DR4 data at E$_0$ = {:.0f} MeV\".format(E0), fontsize=18)\n",
    "\n",
    "# Alpha\n",
    "axs[0].hist(df_as['alpha'], bins=nbins, range=[-2, 4], color=as_color, edgecolor=\"white\", lw=2, density=True, label=\"Assoc\")\n",
    "axs[0].hist(df_unas['alpha'], bins=nbins, range=[-2, 4], histtype='step', edgecolor=unas_color, lw=2, density=True, label=\"Unas\")\n",
    "axs[0].set_xlabel(r\"$\\alpha$\")\n",
    "axs[0].set_ylabel(\"Density\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(0)\n",
    "axs[0].set_ylim(0, 1.0)\n",
    "\n",
    "# Beta\n",
    "axs[1].hist(df_as['beta'], bins=nbins, range=[-0.25, 1.0], color=as_color, edgecolor=\"white\", lw=2, density=True, label=\"Assoc\")\n",
    "axs[1].hist(df_unas['beta'], bins=nbins, range=[-0.25, 1.0], histtype='step', edgecolor=unas_color, lw=2, density=True, label=\"Unas\")\n",
    "axs[1].set_xlabel(r\"$\\beta$\")\n",
    "axs[1].set_ylabel(\"Density\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(0)\n",
    "\n",
    "# Flux\n",
    "axs[2].hist(df_as['flux'], bins=nbins, range=[-12, -6], color=as_color, edgecolor=\"white\", lw=2, density=True, label=\"Assoc\")\n",
    "axs[2].hist(df_unas['flux'], bins=nbins, range=[-12, -6], histtype='step', edgecolor=unas_color, lw=2, density=True, label=\"Unas\")\n",
    "axs[2].set_xlabel(r\"$\\log_{10} \\phi$\")\n",
    "axs[2].set_ylabel(\"Density\")\n",
    "axs[2].legend()\n",
    "axs[2].grid(0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de distribuciones\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "features = ['alpha', 'beta', 'flux']\n",
    "for i, feature in enumerate(features):\n",
    "    # Histogramas comparativos\n",
    "    axes[0, i].hist(df_as[feature], bins=50, alpha=0.7, label='Asociadas', density=True, color='blue')\n",
    "    axes[0, i].hist(df_unas[feature], bins=50, alpha=0.7, label='No Asociadas', density=True, color='red')\n",
    "    axes[0, i].set_xlabel(feature)\n",
    "    axes[0, i].set_ylabel('Densidad')\n",
    "    axes[0, i].legend()\n",
    "    axes[0, i].set_title(f'Distribución de {feature}')\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    # Box plots comparativos\n",
    "    data_to_plot = [df_as[feature], df_unas[feature]]\n",
    "    box_plot = axes[1, i].boxplot(data_to_plot, labels=['Asociadas', 'No Asociadas'], patch_artist=True)\n",
    "    box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "    box_plot['boxes'][1].set_facecolor('lightcoral')\n",
    "    axes[1, i].set_ylabel(feature)\n",
    "    axes[1, i].set_title(f'Box Plot de {feature}')\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar features\n",
    "features = ['alpha', 'beta', 'flux']\n",
    "X = df_as[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar datos: remover infinitos y NaN\n",
    "print(f\"Datos originales: {X.shape[0]} muestras\")\n",
    "mask = np.isfinite(X).all(axis=1)\n",
    "X_clean = X[mask]\n",
    "print(f\"Datos después de limpiar infinitos/NaN: {X_clean.shape[0]} muestras\")\n",
    "print(f\"Muestras quitadas: {X.shape[0] - X_clean.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# División de datos\n",
    "X_train, X_temp = train_test_split(X_clean, test_size=0.4, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"- Entrenamiento: {X_train.shape[0]} muestras ({X_train.shape[0]/X_clean.shape[0]*100:.1f}%)\")\n",
    "print(f\"- Validación: {X_val.shape[0]} muestras ({X_val.shape[0]/X_clean.shape[0]*100:.1f}%)\")\n",
    "print(f\"- Test: {X_test.shape[0]} muestras ({X_test.shape[0]/X_clean.shape[0]*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Escalado de datos - usando RobustScaler para mayor robustez ante outliers\n",
    "scaler = RobustScaler()  # Menos sensible a outliers que StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nEscalado completado usando RobustScaler\")\n",
    "print(f\"Estadísticas de datos escalados (train):\")\n",
    "print(f\"- Media: {np.mean(X_train_scaled, axis=0)}\")\n",
    "print(f\"- Std: {np.std(X_train_scaled, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Train the model - 3F OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid de hiperparámetros ampliado\n",
    "# nu_values = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1]\n",
    "# gamma_values = ['scale', 'auto'] + list(np.logspace(-4, 1, 8))\n",
    "\n",
    "nu_values = [0.002]\n",
    "gamma_values = [0.02]\n",
    "\n",
    "print(f\"Probando {len(nu_values)} valores de nu y {len(gamma_values)} valores de gamma\")\n",
    "print(f\"Total de combinaciones: {len(nu_values) * len(gamma_values)}\")\n",
    "\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_score = np.inf\n",
    "results = []\n",
    "\n",
    "total_combinations = len(nu_values) * len(gamma_values)\n",
    "current_combination = 0\n",
    "\n",
    "for nu in nu_values:\n",
    "    for gamma in gamma_values:\n",
    "        current_combination += 1\n",
    "        \n",
    "        # Mostrar progreso cada 10 iteraciones\n",
    "        if current_combination % 10 == 0 or current_combination == total_combinations:\n",
    "            print(f\"Progreso: {current_combination}/{total_combinations} ({current_combination/total_combinations*100:.1f}%)\")\n",
    "        \n",
    "        model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "        model.fit(X_train_scaled)\n",
    "        \n",
    "        # Predicciones en validación\n",
    "        preds_val = model.predict(X_val_scaled)\n",
    "        decision_scores = model.decision_function(X_val_scaled)\n",
    "        \n",
    "        # Métricas detalladas\n",
    "        n_outliers = np.sum(preds_val == -1)\n",
    "        outlier_ratio = n_outliers / len(preds_val)\n",
    "        mean_score = np.mean(decision_scores)\n",
    "        std_score = np.std(decision_scores)\n",
    "        \n",
    "        results.append({\n",
    "            'nu': nu, \n",
    "            'gamma': gamma, \n",
    "            'outliers': n_outliers,\n",
    "            'outlier_ratio': outlier_ratio,\n",
    "            'mean_score': mean_score,\n",
    "            'std_score': std_score\n",
    "        })\n",
    "        \n",
    "        # Criterio de selección mejorado\n",
    "        target_ratio = nu  # nu aproxima el ratio esperado de outliers\n",
    "        ratio_penalty = abs(outlier_ratio - target_ratio)\n",
    "        score_quality = abs(mean_score)  # Preferimos scores más extremos\n",
    "        combined_score = ratio_penalty + (1 - score_quality) / 10\n",
    "        \n",
    "        if combined_score < best_score:\n",
    "            best_score = combined_score\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "\n",
    "# Convertir resultados a DataFrame para análisis\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nMEJORES PARÁMETROS ENCONTRADOS\")\n",
    "print(f\"Nu: {best_params['nu']}\")\n",
    "print(f\"Gamma: {best_params['gamma']}\")\n",
    "\n",
    "# Mostrar estadísticas del mejor modelo\n",
    "best_result = results_df[(results_df['nu'] == best_params['nu']) & \n",
    "                        (results_df['gamma'] == best_params['gamma'])].iloc[0]\n",
    "\n",
    "print(f\"\\nEstadísticas del mejor modelo en validación:\")\n",
    "print(f\"- Outliers detectados: {best_result['outliers']} ({best_result['outlier_ratio']*100:.2f}%)\")\n",
    "print(f\"- Score promedio: {best_result['mean_score']:.4f} ± {best_result['std_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamiento final del modelo con los mejores hiperparámetros\n",
    "final_model = OneClassSVM(kernel='rbf', nu=best_params['nu'], gamma=best_params['gamma'])\n",
    "final_model.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicciones en test\n",
    "test_preds = final_model.predict(X_test_scaled)\n",
    "test_scores = final_model.decision_function(X_test_scaled)\n",
    "\n",
    "# Estadísticas básicas\n",
    "n_inliers_test = np.sum(test_preds == 1)\n",
    "n_outliers_test = np.sum(test_preds == -1)\n",
    "\n",
    "print(f\"Resultados en datos de test:\")\n",
    "print(f\"- Inliers: {n_inliers_test} ({n_inliers_test/len(test_preds)*100:.2f}%)\")\n",
    "print(f\"- Outliers: {n_outliers_test} ({n_outliers_test/len(test_preds)*100:.2f}%)\")\n",
    "print(f\"- Score promedio: {np.mean(test_scores):.4f} ± {np.std(test_scores):.4f}\")\n",
    "print(f\"- Score mínimo: {np.min(test_scores):.4f}\")\n",
    "print(f\"- Score máximo: {np.max(test_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Nombres cortos para cada dimensión en escala\n",
    "feature_names = ['Alpha', 'Beta', 'Flux']\n",
    "\n",
    "# Todas las combinaciones de pares (índices) de las 3 características\n",
    "feature_pairs = list(combinations(range(len(feature_names)), 2))\n",
    "n_pairs = len(feature_pairs)\n",
    "\n",
    "# Definimos el layout del grid\n",
    "cols = 3\n",
    "rows = int(np.ceil(n_pairs / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, 6*rows))\n",
    "\n",
    "# Asegurarnos de que axes siempre sea 2D\n",
    "if rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "if cols == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Máscaras de inliers/outliers sobre los datos ASOC de test\n",
    "inliers_mask_asoc = (test_preds == 1)\n",
    "outliers_mask_asoc = (test_preds == -1)\n",
    "\n",
    "# Recorremos cada par de características para dibujar subplots\n",
    "for i, (idx1, idx2) in enumerate(feature_pairs):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # La dimensión que no se muestra en este par\n",
    "    other_dim = [j for j in range(3) if j not in (idx1, idx2)][0]\n",
    "    # Fijamos esa dimensión en su mediana (sobre X_test_scaled)\n",
    "    med_val = np.median(X_test_scaled[:, other_dim])\n",
    "    \n",
    "    # Rango de valores en idx1 e idx2 para la malla 2D\n",
    "    x_min = X_test_scaled[:, idx1].min() - 0.5\n",
    "    x_max = X_test_scaled[:, idx1].max() + 0.5\n",
    "    y_min = X_test_scaled[:, idx2].min() - 0.5\n",
    "    y_max = X_test_scaled[:, idx2].max() + 0.5\n",
    "    \n",
    "    # Creamos la malla 2D\n",
    "    res = 150\n",
    "    xx = np.linspace(x_min, x_max, res)\n",
    "    yy = np.linspace(y_min, y_max, res)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    \n",
    "    # Preparamos el grid completo (res^2 × 3)\n",
    "    grid = np.zeros((res*res, 3))\n",
    "    grid[:, idx1] = XX.ravel()\n",
    "    grid[:, idx2] = YY.ravel()\n",
    "    grid[:, other_dim] = med_val\n",
    "    \n",
    "    # Computar decision_function en cada punto de la malla\n",
    "    Z = final_model.decision_function(grid).reshape((res, res))\n",
    "    \n",
    "    # Ajustar niveles para contourf\n",
    "    z_min = Z.min()\n",
    "    z_max = 0  # la frontera OCSVM está en decision_function=0\n",
    "    if z_min >= z_max:\n",
    "        z_max = z_min + 1e-3\n",
    "    \n",
    "    levels = np.linspace(z_min, z_max, 8)\n",
    "    \n",
    "    # Dibujar contorno relleno y frontera\n",
    "    cf = ax.contourf(XX, YY, Z, levels=levels, cmap='RdYlBu_r', alpha=0.6)\n",
    "    ax.contour(XX, YY, Z, levels=[0], colors='firebrick', linewidths=2, linestyles='--')\n",
    "    \n",
    "    # Scatter de los inliers de ASOC en test\n",
    "    ax.scatter(\n",
    "        X_test_scaled[inliers_mask_asoc, idx1], \n",
    "        X_test_scaled[inliers_mask_asoc, idx2],\n",
    "        c='navy', s=20, alpha=0.7,\n",
    "        label=f'Inliers (ASOC): {np.sum(inliers_mask_asoc)}'\n",
    "    )\n",
    "    # Scatter de los outliers de ASOC en test\n",
    "    if np.any(outliers_mask_asoc):\n",
    "        ax.scatter(\n",
    "            X_test_scaled[outliers_mask_asoc, idx1],\n",
    "            X_test_scaled[outliers_mask_asoc, idx2],\n",
    "            c='red', marker='D', s=50, alpha=1.0,\n",
    "            label=f'Outliers (ASOC): {np.sum(outliers_mask_asoc)}'\n",
    "        )\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    ax.set_xlabel(feature_names[idx1])\n",
    "    ax.set_ylabel(feature_names[idx2])\n",
    "    gamma_val = final_model.gamma if hasattr(final_model, 'gamma') else final_model._gamma\n",
    "    nu_val = final_model.nu\n",
    "    ax.set_title(\n",
    "        f\"{feature_names[idx1]} vs {feature_names[idx2]}\\n\"\n",
    "        f\"ν={nu_val}, γ={gamma_val:.2e} | \"\n",
    "        f\"Outliers: {np.sum(outliers_mask_asoc)}/{len(X_test_scaled)}\"\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Ocultar subplots vacíos si los hay\n",
    "total_subplots = rows * cols\n",
    "for j in range(n_pairs, total_subplots):\n",
    "    r = j // cols\n",
    "    c = j % cols\n",
    "    axes[r, c].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Información adicional del modelo\n",
    "print(f\"\\nOne-Class SVM (ASOC test):\")\n",
    "print(f\"  • Kernel : {final_model.kernel}\")\n",
    "print(f\"  • Gamma  : {gamma_val:.2e}\")\n",
    "print(f\"  • Nu     : {nu_val}\")\n",
    "print(f\"  • Soportes: {final_model.n_support_[0]}\")\n",
    "print(f\"  • Outliers detectados en ASOC test: {np.sum(outliers_mask_asoc)}/\"\n",
    "      f\"{len(X_test_scaled)}  ({100*np.sum(outliers_mask_asoc)/len(X_test_scaled):.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D  # necesario para la proyección 3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers de ASOC test (gris tenue)\n",
    "inliers_mask_asoc = (test_preds == 1)\n",
    "ax.scatter(\n",
    "    X_test_scaled[inliers_mask_asoc, 0],\n",
    "    X_test_scaled[inliers_mask_asoc, 1],\n",
    "    X_test_scaled[inliers_mask_asoc, 2],\n",
    "    c='purple', s=12, alpha=0.5, label=f'ASOC Inliers: {np.sum(inliers_mask_asoc)}'\n",
    ")\n",
    "\n",
    "# Outliers de ASOC test (rojo)\n",
    "outliers_mask_asoc = (test_preds == -1)\n",
    "if np.any(outliers_mask_asoc):\n",
    "    ax.scatter(\n",
    "        X_test_scaled[outliers_mask_asoc, 0],\n",
    "        X_test_scaled[outliers_mask_asoc, 1],\n",
    "        X_test_scaled[outliers_mask_asoc, 2],\n",
    "        c='red', marker='x', s=60, alpha=0.8,\n",
    "        label=f'ASOC Outliers: {np.sum(outliers_mask_asoc)}'\n",
    "    )\n",
    "\n",
    "# Etiquetas y título\n",
    "ax.set_xlabel('Alpha (escalado)')\n",
    "ax.set_ylabel('Beta (escalado)')\n",
    "ax.set_zlabel('Flux (escalado)')\n",
    "gamma_val = final_model.gamma if hasattr(final_model, 'gamma') else final_model._gamma\n",
    "nu_val = final_model.nu\n",
    "ax.set_title(f\"3D ASOC Test\\nν={nu_val}, γ={gamma_val:.2e}\")\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Predecir sobre unassociated data (unas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preparar datos de fuentes no asociadas\n",
    "features = ['alpha', 'beta', 'flux']\n",
    "X_unas = df_unas[features].values\n",
    "\n",
    "print(f\"Fuentes no asociadas originales: {len(X_unas)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Limpiar datos no asociados\n",
    "mask_unas = np.isfinite(X_unas).all(axis=1)\n",
    "X_unas_clean = X_unas[mask_unas]\n",
    "clean_indices = np.where(mask_unas)[0]\n",
    "\n",
    "print(f\"Fuentes no asociadas válidas: {len(X_unas_clean)}\")\n",
    "print(f\"Fuentes quitadas por datos inválidos: {len(X_unas) - len(X_unas_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Escalar datos usando el mismo scaler del entrenamiento\n",
    "X_unas_scaled = scaler.transform(X_unas_clean)\n",
    "\n",
    "# Realizar predicciones\n",
    "unas_preds = final_model.predict(X_unas_scaled)\n",
    "unas_scores = final_model.decision_function(X_unas_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get predictions + decision scores\n",
    "preds = best_model.predict(X_val_scaled)\n",
    "decision_scores = best_model.decision_function(X_val_scaled)\n",
    "\n",
    "# index maxs\n",
    "inlier_idx = preds == 1\n",
    "outlier_idx = preds == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Análisis de resultados\n",
    "n_normal = np.sum(unas_preds == 1)\n",
    "n_anomalous = np.sum(unas_preds == -1)\n",
    "\n",
    "print(f\"\\nResultados en fuentes no asociadas:\")\n",
    "print(f\"- Fuentes normales: {n_normal} ({n_normal/len(unas_preds)*100:.2f}%)\")\n",
    "print(f\"- Candidatos anómalos: {n_anomalous} ({n_anomalous/len(unas_preds)*100:.2f}%)\")\n",
    "\n",
    "# Estadísticas de scores\n",
    "print(f\"\\nEstadísticas de scores de anomalía:\")\n",
    "print(f\"- Score promedio: {np.mean(unas_scores):.4f} ± {np.std(unas_scores):.4f}\")\n",
    "print(f\"- Score más anómalo: {np.min(unas_scores):.4f}\")\n",
    "print(f\"- Score menos anómalo: {np.max(unas_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Análisis de candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear DataFrame con resultados completos\n",
    "results_unas = df_unas.iloc[clean_indices].copy()\n",
    "results_unas['prediction'] = unas_preds\n",
    "results_unas['anomaly_score'] = unas_scores\n",
    "results_unas['is_candidate'] = unas_preds == -1\n",
    "\n",
    "# Filtrar candidatos anómalos\n",
    "candidates = results_unas[results_unas['is_candidate']].copy()\n",
    "candidates_sorted = candidates.sort_values('anomaly_score').reset_index(drop=True)\n",
    "\n",
    "print(f\"ANÁLISIS DE CANDIDATOS A MATERIA OSCURA\")\n",
    "print(f\"Total de candidatos encontrados: {len(candidates)}\")\n",
    "\n",
    "if len(candidates) > 0:\n",
    "    print(f\"\\nCaracterísticas de los candidatos:\")\n",
    "    print(f\"- Alpha promedio: {candidates['alpha'].mean():.4f} ± {candidates['alpha'].std():.4f}\")\n",
    "    print(f\"- Beta promedio: {candidates['beta'].mean():.4f} ± {candidates['beta'].std():.4f}\")\n",
    "    print(f\"- Flux promedio: {candidates['flux'].mean():.2e} ± {candidates['flux'].std():.2e}\")\n",
    "    print(f\"- Score de anomalía promedio: {candidates['anomaly_score'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 candidatos más anómalos:\")\n",
    "    top_candidates = candidates_sorted[['alpha', 'beta', 'flux', 'anomaly_score']].head(10)\n",
    "    print(top_candidates.to_string(index=True, float_format='%.4f'))\n",
    "    \n",
    "    print(f\"\\nComparación con fuentes asociadas:\")\n",
    "    print(f\"- Alpha: Candidatos={candidates['alpha'].mean():.4f}, Asociadas={df_as['alpha'].mean():.4f}\")\n",
    "    print(f\"- Beta: Candidatos={candidates['beta'].mean():.4f}, Asociadas={df_as['beta'].mean():.4f}\")\n",
    "    print(f\"- Flux: Candidatos={candidates['flux'].mean():.2e}, Asociadas={df_as['flux'].mean():.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['Alpha', 'Beta', 'Flux']\n",
    "feature_pairs = list(combinations(range(len(feature_names)), 2))\n",
    "n_pairs = len(feature_pairs)\n",
    "\n",
    "cols = 3\n",
    "rows = int(np.ceil(n_pairs / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, 6*rows))\n",
    "\n",
    "if rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "if cols == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Máscaras de inliers/outliers en UNAS\n",
    "inliers_mask_unas = (unas_preds == 1)\n",
    "outliers_mask_unas = (unas_preds == -1)\n",
    "\n",
    "for i, (idx1, idx2) in enumerate(feature_pairs):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    other_dim = [j for j in range(3) if j not in (idx1, idx2)][0]\n",
    "    med_val = np.median(X_unas_scaled[:, other_dim])\n",
    "    \n",
    "    x_min = X_unas_scaled[:, idx1].min() - 0.5\n",
    "    x_max = X_unas_scaled[:, idx1].max() + 0.5\n",
    "    y_min = X_unas_scaled[:, idx2].min() - 0.5\n",
    "    y_max = X_unas_scaled[:, idx2].max() + 0.5\n",
    "    \n",
    "    res = 150\n",
    "    xx = np.linspace(x_min, x_max, res)\n",
    "    yy = np.linspace(y_min, y_max, res)\n",
    "    XX, YY = np.meshgrid(xx, yy)\n",
    "    \n",
    "    grid = np.zeros((res*res, 3))\n",
    "    grid[:, idx1] = XX.ravel()\n",
    "    grid[:, idx2] = YY.ravel()\n",
    "    grid[:, other_dim] = med_val\n",
    "    \n",
    "    Z = final_model.decision_function(grid).reshape((res, res))\n",
    "    z_min = Z.min()\n",
    "    z_max = 0\n",
    "    if z_min >= z_max:\n",
    "        z_max = z_min + 1e-3\n",
    "    levels = np.linspace(z_min, z_max, 8)\n",
    "    \n",
    "    cf = ax.contourf(XX, YY, Z, levels=levels, cmap='RdYlBu_r', alpha=0.6)\n",
    "    ax.contour(XX, YY, Z, levels=[0], colors='firebrick', linewidths=2, linestyles='--')\n",
    "    \n",
    "    # Puntos UNAS inliers\n",
    "    ax.scatter(\n",
    "        X_unas_scaled[inliers_mask_unas, idx1],\n",
    "        X_unas_scaled[inliers_mask_unas, idx2],\n",
    "        c='royalblue', s=25, alpha=0.5,\n",
    "        label=f'UNAS Inliers: {np.sum(inliers_mask_unas)}'\n",
    "    )\n",
    "    # Puntos UNAS outliers (candidatos)\n",
    "    if np.any(outliers_mask_unas):\n",
    "        ax.scatter(\n",
    "            X_unas_scaled[outliers_mask_unas, idx1],\n",
    "            X_unas_scaled[outliers_mask_unas, idx2],\n",
    "            c='darkred', marker='^', s=80, alpha=0.9,\n",
    "            label=f'UNAS Outliers: {np.sum(outliers_mask_unas)}'\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(feature_names[idx1])\n",
    "    ax.set_ylabel(feature_names[idx2])\n",
    "    gamma_val = final_model.gamma if hasattr(final_model, 'gamma') else final_model._gamma\n",
    "    nu_val = final_model.nu\n",
    "    ax.set_title(\n",
    "        f\"{feature_names[idx1]} vs {feature_names[idx2]}\\n\"\n",
    "        f\"ν={nu_val}, γ={gamma_val:.2e} | \"\n",
    "        f\"Outliers UNAS: {np.sum(outliers_mask_unas)}/{len(X_unas_scaled)}\"\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "for j in range(n_pairs, rows * cols):\n",
    "    r = j // cols\n",
    "    c = j % cols\n",
    "    axes[r, c].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOne-Class SVM (UNAS):\")\n",
    "print(f\"  • Kernel : {final_model.kernel}\")\n",
    "print(f\"  • Gamma  : {gamma_val:.2e}\")\n",
    "print(f\"  • Nu     : {nu_val}\")\n",
    "print(f\"  • Candidatos UNAS (outliers): {np.sum(outliers_mask_unas)}/\"\n",
    "      f\"{len(X_unas_scaled)}  ({100*np.sum(outliers_mask_unas)/len(X_unas_scaled):.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers UNAS (azul claro)\n",
    "inliers_mask_unas = (unas_preds == 1)\n",
    "if np.any(inliers_mask_unas):\n",
    "    ax.scatter(\n",
    "        X_unas_scaled[inliers_mask_unas, 0],\n",
    "        X_unas_scaled[inliers_mask_unas, 1],\n",
    "        X_unas_scaled[inliers_mask_unas, 2],\n",
    "        c='orange', s=20, alpha=0.5,\n",
    "        label=f'UNAS Inliers: {np.sum(inliers_mask_unas)}'\n",
    "    )\n",
    "\n",
    "# Outliers UNAS (rojo oscuro)\n",
    "outliers_mask_unas = (unas_preds == -1)\n",
    "if np.any(outliers_mask_unas):\n",
    "    ax.scatter(\n",
    "        X_unas_scaled[outliers_mask_unas, 0],\n",
    "        X_unas_scaled[outliers_mask_unas, 1],\n",
    "        X_unas_scaled[outliers_mask_unas, 2],\n",
    "        c='darkred', marker='^', s=80, alpha=0.9,\n",
    "        label=f'UNAS Outliers: {np.sum(outliers_mask_unas)}'\n",
    "    )\n",
    "\n",
    "# Etiquetas y título\n",
    "ax.set_xlabel('Alpha (escalado)')\n",
    "ax.set_ylabel('Beta (escalado)')\n",
    "ax.set_zlabel('Flux (escalado)')\n",
    "gamma_val = final_model.gamma if hasattr(final_model, 'gamma') else final_model._gamma\n",
    "nu_val = final_model.nu\n",
    "ax.set_title(f\"3D UNAS Predictions\\nν={nu_val}, γ={gamma_val:.2e}\")\n",
    "ax.legend(loc='upper left', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
