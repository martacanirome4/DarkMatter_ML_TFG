{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fname = \"../data/catalog_data_4FGL_DR4.h5\"\n",
    "\n",
    "with h5py.File(fname, \"r\") as f:\n",
    "    # read attributes\n",
    "    E0 = f.attrs[\"E0\"]\n",
    "    \n",
    "    # read assoc data (fuentes conocidas - datos de entrenamiento)\n",
    "    alpha_as = f[\"assoc\"][\"alpha\"][:]\n",
    "    beta_as = f[\"assoc\"][\"beta\"][:]\n",
    "    flux_as = f[\"assoc\"][\"flux\"][:]\n",
    "    \n",
    "    # read unassoc data (candidatos a materia oscura)\n",
    "    alpha_unas = f[\"unas\"][\"alpha\"][:]\n",
    "    beta_unas = f[\"unas\"][\"beta\"][:]\n",
    "    flux_unas = f[\"unas\"][\"flux\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('E0 (energy): attribute value', E0)\n",
    "print('UNAS - alpha, beta & flux shape: ', alpha_unas.shape, beta_unas.shape, flux_unas.shape)\n",
    "print('AS - alpha, beta & flux shape: ', alpha_as.shape, beta_as.shape, flux_as.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_as = pd.DataFrame({\n",
    "    'alpha': alpha_as,\n",
    "    'beta': beta_as,\n",
    "    'flux': flux_as\n",
    "})\n",
    "\n",
    "df_unas = pd.DataFrame({\n",
    "    'alpha': alpha_unas,\n",
    "    'beta': beta_unas,\n",
    "    'flux': flux_unas\n",
    "})\n",
    "\n",
    "print(f\"Datos cargados exitosamente:\")\n",
    "print(f\"- Fuentes asociadas (entrenamiento): {len(df_as)}\")\n",
    "print(f\"- Fuentes no asociadas (predicción): {len(df_unas)}\")\n",
    "print(f\"- Energía de referencia E0: {E0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check the data conversion\n",
    "df_as.shape[0] == len(alpha_as)\n",
    "df_unas.shape[0] == len(alpha_unas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_as.shape)\n",
    "df_as.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_unas.shape)\n",
    "df_unas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Associated sources: ')\n",
    "df_as.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nUnassociated sources:')\n",
    "df_unas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEstadísticas descriptivas - Fuentes Asociadas:\")\n",
    "print(df_as.describe())\n",
    "\n",
    "print(\"\\nEstadísticas descriptivas - Fuentes No Asociadas:\")\n",
    "print(df_unas.describe())\n",
    "\n",
    "# Verificar calidad de datos\n",
    "print(f\"\\nCalidad de datos:\")\n",
    "print(f\"- Valores nulos en asociadas: {df_as.isnull().sum().sum()}\")\n",
    "print(f\"- Valores nulos en no asociadas: {df_unas.isnull().sum().sum()}\")\n",
    "print(f\"- Valores infinitos en asociadas: {np.isinf(df_as.values).sum()}\")\n",
    "print(f\"- Valores infinitos en no asociadas: {np.isinf(df_unas.values).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data the same way to check the distributions\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "nbins = 15\n",
    "unas_color = \"#3e4550\"\n",
    "as_color = \"#c2d9c7\"\n",
    "\n",
    "fig.suptitle(r\"4FGL DR4 data at E$_0$ = {:.0f} MeV\".format(E0), fontsize=18)\n",
    "\n",
    "# Alpha\n",
    "axs[0].hist(df_as['alpha'], bins=nbins, range=[-2, 4], color=as_color, edgecolor=\"white\", lw=2, density=True, label=\"Assoc\")\n",
    "axs[0].hist(df_unas['alpha'], bins=nbins, range=[-2, 4], histtype='step', edgecolor=unas_color, lw=2, density=True, label=\"Unas\")\n",
    "axs[0].set_xlabel(r\"$\\alpha$\")\n",
    "axs[0].set_ylabel(\"Density\")\n",
    "axs[0].legend()\n",
    "axs[0].grid(0)\n",
    "axs[0].set_ylim(0, 1.0)\n",
    "\n",
    "# Beta\n",
    "axs[1].hist(df_as['beta'], bins=nbins, range=[-0.25, 1.0], color=as_color, edgecolor=\"white\", lw=2, density=True, label=\"Assoc\")\n",
    "axs[1].hist(df_unas['beta'], bins=nbins, range=[-0.25, 1.0], histtype='step', edgecolor=unas_color, lw=2, density=True, label=\"Unas\")\n",
    "axs[1].set_xlabel(r\"$\\beta$\")\n",
    "axs[1].set_ylabel(\"Density\")\n",
    "axs[1].legend()\n",
    "axs[1].grid(0)\n",
    "\n",
    "# Flux\n",
    "axs[2].hist(df_as['flux'], bins=nbins, range=[-12, -6], color=as_color, edgecolor=\"white\", lw=2, density=True, label=\"Assoc\")\n",
    "axs[2].hist(df_unas['flux'], bins=nbins, range=[-12, -6], histtype='step', edgecolor=unas_color, lw=2, density=True, label=\"Unas\")\n",
    "axs[2].set_xlabel(r\"$\\log_{10} \\phi$\")\n",
    "axs[2].set_ylabel(\"Density\")\n",
    "axs[2].legend()\n",
    "axs[2].grid(0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de distribuciones\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "features = ['alpha', 'beta', 'flux']\n",
    "for i, feature in enumerate(features):\n",
    "    # Histogramas comparativos\n",
    "    axes[0, i].hist(df_as[feature], bins=50, alpha=0.7, label='Asociadas', density=True, color='blue')\n",
    "    axes[0, i].hist(df_unas[feature], bins=50, alpha=0.7, label='No Asociadas', density=True, color='red')\n",
    "    axes[0, i].set_xlabel(feature)\n",
    "    axes[0, i].set_ylabel('Densidad')\n",
    "    axes[0, i].legend()\n",
    "    axes[0, i].set_title(f'Distribución de {feature}')\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    # Box plots comparativos\n",
    "    data_to_plot = [df_as[feature], df_unas[feature]]\n",
    "    box_plot = axes[1, i].boxplot(data_to_plot, labels=['Asociadas', 'No Asociadas'], patch_artist=True)\n",
    "    box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "    box_plot['boxes'][1].set_facecolor('lightcoral')\n",
    "    axes[1, i].set_ylabel(feature)\n",
    "    axes[1, i].set_title(f'Box Plot de {feature}')\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## PREPROCESAMIENTO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar features\n",
    "features = ['alpha', 'beta', 'flux']\n",
    "X = df_as[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar datos: remover infinitos y NaN\n",
    "print(f\"Datos originales: {X.shape[0]} muestras\")\n",
    "mask = np.isfinite(X).all(axis=1)\n",
    "X_clean = X[mask]\n",
    "print(f\"Datos después de limpiar infinitos/NaN: {X_clean.shape[0]} muestras\")\n",
    "print(f\"Muestras quitadas: {X.shape[0] - X_clean.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# División de datos\n",
    "X_train, X_temp = train_test_split(X_clean, test_size=0.4, random_state=42)\n",
    "X_val, X_test = train_test_split(X_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"\\nDivisión de datos:\")\n",
    "print(f\"- Entrenamiento: {X_train.shape[0]} muestras ({X_train.shape[0]/X_clean.shape[0]*100:.1f}%)\")\n",
    "print(f\"- Validación: {X_val.shape[0]} muestras ({X_val.shape[0]/X_clean.shape[0]*100:.1f}%)\")\n",
    "print(f\"- Test: {X_test.shape[0]} muestras ({X_test.shape[0]/X_clean.shape[0]*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de datos - usando RobustScaler para mayor robustez ante outliers\n",
    "scaler = RobustScaler()  # Menos sensible a outliers que StandardScaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nEscalado completado usando RobustScaler\")\n",
    "print(f\"Estadísticas de datos escalados (train):\")\n",
    "print(f\"- Media: {np.mean(X_train_scaled, axis=0)}\")\n",
    "print(f\"- Std: {np.std(X_train_scaled, axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Train the model - 3F OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid de hiperparámetros ampliado\n",
    "nu_values = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1]\n",
    "gamma_values = ['scale', 'auto'] + list(np.logspace(-4, 1, 8))\n",
    "\n",
    "print(f\"Probando {len(nu_values)} valores de nu y {len(gamma_values)} valores de gamma\")\n",
    "print(f\"Total de combinaciones: {len(nu_values) * len(gamma_values)}\")\n",
    "\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_score = np.inf\n",
    "results = []\n",
    "\n",
    "total_combinations = len(nu_values) * len(gamma_values)\n",
    "current_combination = 0\n",
    "\n",
    "for nu in nu_values:\n",
    "    for gamma in gamma_values:\n",
    "        current_combination += 1\n",
    "        \n",
    "        # Mostrar progreso cada 10 iteraciones\n",
    "        if current_combination % 10 == 0 or current_combination == total_combinations:\n",
    "            print(f\"Progreso: {current_combination}/{total_combinations} ({current_combination/total_combinations*100:.1f}%)\")\n",
    "        \n",
    "        model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "        model.fit(X_train_scaled)\n",
    "        \n",
    "        # Predicciones en validación\n",
    "        preds_val = model.predict(X_val_scaled)\n",
    "        decision_scores = model.decision_function(X_val_scaled)\n",
    "        \n",
    "        # Métricas detalladas\n",
    "        n_outliers = np.sum(preds_val == -1)\n",
    "        outlier_ratio = n_outliers / len(preds_val)\n",
    "        mean_score = np.mean(decision_scores)\n",
    "        std_score = np.std(decision_scores)\n",
    "        \n",
    "        results.append({\n",
    "            'nu': nu, \n",
    "            'gamma': gamma, \n",
    "            'outliers': n_outliers,\n",
    "            'outlier_ratio': outlier_ratio,\n",
    "            'mean_score': mean_score,\n",
    "            'std_score': std_score\n",
    "        })\n",
    "        \n",
    "        # Criterio de selección mejorado\n",
    "        target_ratio = nu  # nu aproxima el ratio esperado de outliers\n",
    "        ratio_penalty = abs(outlier_ratio - target_ratio)\n",
    "        score_quality = abs(mean_score)  # Preferimos scores más extremos\n",
    "        combined_score = ratio_penalty + (1 - score_quality) / 10\n",
    "        \n",
    "        if combined_score < best_score:\n",
    "            best_score = combined_score\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "\n",
    "# Convertir resultados a DataFrame para análisis\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nMEJORES PARÁMETROS ENCONTRADOS\")\n",
    "print(f\"Nu: {best_params['nu']}\")\n",
    "print(f\"Gamma: {best_params['gamma']}\")\n",
    "\n",
    "# Mostrar estadísticas del mejor modelo\n",
    "best_result = results_df[(results_df['nu'] == best_params['nu']) & \n",
    "                        (results_df['gamma'] == best_params['gamma'])].iloc[0]\n",
    "\n",
    "print(f\"\\nEstadísticas del mejor modelo en validación:\")\n",
    "print(f\"- Outliers detectados: {best_result['outliers']} ({best_result['outlier_ratio']*100:.2f}%)\")\n",
    "print(f\"- Score promedio: {best_result['mean_score']:.4f} ± {best_result['std_score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la búsqueda de hiperparámetros\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Heatmap de outlier ratio\n",
    "pivot_outliers = results_df.pivot(index='nu', columns='gamma', values='outlier_ratio')\n",
    "im1 = axes[0].imshow(pivot_outliers.values, aspect='auto', cmap='viridis')\n",
    "axes[0].set_title('Ratio de Outliers por Hiperparámetros')\n",
    "axes[0].set_xlabel('Gamma (index)')\n",
    "axes[0].set_ylabel('Nu (index)')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Distribución de ratios de outliers\n",
    "axes[1].hist(results_df['outlier_ratio'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(best_result['outlier_ratio'], color='red', linestyle='--', \n",
    "                label=f'Mejor modelo: {best_result[\"outlier_ratio\"]:.3f}')\n",
    "axes[1].set_xlabel('Ratio de Outliers')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].set_title('Distribución de Ratios de Outliers')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Relación entre nu y outlier ratio\n",
    "axes[2].scatter(results_df['nu'], results_df['outlier_ratio'], alpha=0.6)\n",
    "axes[2].plot([0, 0.1], [0, 0.1], 'r--', label='Relación ideal (nu = outlier_ratio)')\n",
    "axes[2].scatter(best_params['nu'], best_result['outlier_ratio'], \n",
    "                color='red', s=100, label='Mejor modelo', zorder=5)\n",
    "axes[2].set_xlabel('Nu')\n",
    "axes[2].set_ylabel('Outlier Ratio Observado')\n",
    "axes[2].set_title('Nu vs Outlier Ratio')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamiento final del modelo con los mejores hiperparámetros\n",
    "final_model = OneClassSVM(kernel='rbf', nu=best_params['nu'], gamma=best_params['gamma'])\n",
    "final_model.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en test\n",
    "test_preds = final_model.predict(X_test_scaled)\n",
    "test_scores = final_model.decision_function(X_test_scaled)\n",
    "\n",
    "# Estadísticas básicas\n",
    "n_inliers_test = np.sum(test_preds == 1)\n",
    "n_outliers_test = np.sum(test_preds == -1)\n",
    "\n",
    "print(f\"Resultados en datos de test:\")\n",
    "print(f\"- Inliers: {n_inliers_test} ({n_inliers_test/len(test_preds)*100:.2f}%)\")\n",
    "print(f\"- Outliers: {n_outliers_test} ({n_outliers_test/len(test_preds)*100:.2f}%)\")\n",
    "print(f\"- Score promedio: {np.mean(test_scores):.4f} ± {np.std(test_scores):.4f}\")\n",
    "print(f\"- Score mínimo: {np.min(test_scores):.4f}\")\n",
    "print(f\"- Score máximo: {np.max(test_scores):.4f}\")\n",
    "\n",
    "\"\"\"\n",
    "# Análisis por cuartiles\n",
    "quartiles = np.percentile(test_scores, [25, 50, 75])\n",
    "print(f\"\\nCuartiles de scores:\")\n",
    "print(f\"- Q1 (25%): {quartiles[0]:.4f}\")\n",
    "print(f\"- Q2 (50%): {quartiles[1]:.4f}\")\n",
    "print(f\"- Q3 (75%): {quartiles[2]:.4f}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis visual de la evaluación\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Distribución de scores de decisión\n",
    "axes[0,0].hist(test_scores, bins=50, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[0,0].axvline(0, color='red', linestyle='--', linewidth=2, label='Frontera de decisión')\n",
    "axes[0,0].axvline(np.mean(test_scores), color='green', linestyle='--', label='Score promedio')\n",
    "axes[0,0].set_xlabel('Decision Score')\n",
    "axes[0,0].set_ylabel('Frecuencia')\n",
    "axes[0,0].set_title('Distribución de Scores de Decisión (Test)')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparación de scores por clasificación\n",
    "inlier_scores = test_scores[test_preds == 1]\n",
    "outlier_scores = test_scores[test_preds == -1]\n",
    "\n",
    "box_data = [inlier_scores, outlier_scores]\n",
    "box_plot = axes[0,1].boxplot(box_data, labels=['Inliers', 'Outliers'], patch_artist=True)\n",
    "box_plot['boxes'][0].set_facecolor('lightblue')\n",
    "box_plot['boxes'][1].set_facecolor('lightcoral')\n",
    "axes[0,1].set_ylabel('Decision Score')\n",
    "axes[0,1].set_title('Scores por Clasificación')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot para normalidad\n",
    "from scipy import stats\n",
    "sorted_scores = np.sort(test_scores)\n",
    "theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, len(sorted_scores)))\n",
    "axes[1,0].scatter(theoretical_quantiles, sorted_scores, alpha=0.6)\n",
    "axes[1,0].plot(theoretical_quantiles, theoretical_quantiles, 'r--', label='Normalidad perfecta')\n",
    "axes[1,0].set_xlabel('Quantiles Teóricos (Normal)')\n",
    "axes[1,0].set_ylabel('Scores Observados')\n",
    "axes[1,0].set_title('Q-Q Plot - Normalidad de Scores')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Scatter plot de scores vs índices\n",
    "axes[1,1].scatter(range(len(test_scores)), test_scores, \n",
    "                  c=test_preds, cmap='coolwarm', alpha=0.6)\n",
    "axes[1,1].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1,1].set_xlabel('Índice de muestra')\n",
    "axes[1,1].set_ylabel('Decision Score')\n",
    "axes[1,1].set_title('Scores por Muestra (Azul=Inlier, Rojo=Outlier)')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Predecir sobre unassociated data (unas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos de fuentes no asociadas\n",
    "features = ['alpha', 'beta', 'flux']\n",
    "X_unas = df_unas[features].values\n",
    "\n",
    "print(f\"Fuentes no asociadas originales: {len(X_unas)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar datos no asociados\n",
    "mask_unas = np.isfinite(X_unas).all(axis=1)\n",
    "X_unas_clean = X_unas[mask_unas]\n",
    "clean_indices = np.where(mask_unas)[0]\n",
    "\n",
    "print(f\"Fuentes no asociadas válidas: {len(X_unas_clean)}\")\n",
    "print(f\"Fuentes quitadas por datos inválidos: {len(X_unas) - len(X_unas_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar datos usando el mismo scaler del entrenamiento\n",
    "X_unas_scaled = scaler.transform(X_unas_clean)\n",
    "\n",
    "# Realizar predicciones\n",
    "unas_preds = final_model.predict(X_unas_scaled)\n",
    "unas_scores = final_model.decision_function(X_unas_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions + decision scores\n",
    "preds = best_model.predict(X_val_scaled)\n",
    "decision_scores = best_model.decision_function(X_val_scaled)\n",
    "\n",
    "# index maxs\n",
    "inlier_idx = preds == 1\n",
    "outlier_idx = preds == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de resultados\n",
    "n_normal = np.sum(unas_preds == 1)\n",
    "n_anomalous = np.sum(unas_preds == -1)\n",
    "\n",
    "print(f\"\\nResultados en fuentes no asociadas:\")\n",
    "print(f\"- Fuentes normales: {n_normal} ({n_normal/len(unas_preds)*100:.2f}%)\")\n",
    "print(f\"- Candidatos anómalos: {n_anomalous} ({n_anomalous/len(unas_preds)*100:.2f}%)\")\n",
    "\n",
    "# Estadísticas de scores\n",
    "print(f\"\\nEstadísticas de scores de anomalía:\")\n",
    "print(f\"- Score promedio: {np.mean(unas_scores):.4f} ± {np.std(unas_scores):.4f}\")\n",
    "print(f\"- Score más anómalo: {np.min(unas_scores):.4f}\")\n",
    "print(f\"- Score menos anómalo: {np.max(unas_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Análisis de candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados completos\n",
    "results_unas = df_unas.iloc[clean_indices].copy()\n",
    "results_unas['prediction'] = unas_preds\n",
    "results_unas['anomaly_score'] = unas_scores\n",
    "results_unas['is_candidate'] = unas_preds == -1\n",
    "\n",
    "# Filtrar candidatos anómalos\n",
    "candidates = results_unas[results_unas['is_candidate']].copy()\n",
    "candidates_sorted = candidates.sort_values('anomaly_score').reset_index(drop=True)\n",
    "\n",
    "print(f\"ANÁLISIS DE CANDIDATOS A MATERIA OSCURA\")\n",
    "print(f\"Total de candidatos encontrados: {len(candidates)}\")\n",
    "\n",
    "if len(candidates) > 0:\n",
    "    print(f\"\\nCaracterísticas de los candidatos:\")\n",
    "    print(f\"- Alpha promedio: {candidates['alpha'].mean():.4f} ± {candidates['alpha'].std():.4f}\")\n",
    "    print(f\"- Beta promedio: {candidates['beta'].mean():.4f} ± {candidates['beta'].std():.4f}\")\n",
    "    print(f\"- Flux promedio: {candidates['flux'].mean():.2e} ± {candidates['flux'].std():.2e}\")\n",
    "    print(f\"- Score de anomalía promedio: {candidates['anomaly_score'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 candidatos más anómalos:\")\n",
    "    top_candidates = candidates_sorted[['alpha', 'beta', 'flux', 'anomaly_score']].head(10)\n",
    "    print(top_candidates.to_string(index=True, float_format='%.4f'))\n",
    "    \n",
    "    print(f\"\\nComparación con fuentes asociadas:\")\n",
    "    print(f\"- Alpha: Candidatos={candidates['alpha'].mean():.4f}, Asociadas={df_as['alpha'].mean():.4f}\")\n",
    "    print(f\"- Beta: Candidatos={candidates['beta'].mean():.4f}, Asociadas={df_as['beta'].mean():.4f}\")\n",
    "    print(f\"- Flux: Candidatos={candidates['flux'].mean():.2e}, Asociadas={df_as['flux'].mean():.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear figura con subplots 3D\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Plot 1: Clasificación en datos de test\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "\n",
    "# Separar inliers y outliers en test\n",
    "inliers_mask = test_preds == 1\n",
    "outliers_mask = test_preds == -1\n",
    "\n",
    "scatter1 = ax1.scatter(X_test_scaled[inliers_mask, 0], \n",
    "                      X_test_scaled[inliers_mask, 1], \n",
    "                      X_test_scaled[inliers_mask, 2], \n",
    "                      c='blue', alpha=0.6, label='Inliers', s=20)\n",
    "\n",
    "scatter2 = ax1.scatter(X_test_scaled[outliers_mask, 0], \n",
    "                      X_test_scaled[outliers_mask, 1], \n",
    "                      X_test_scaled[outliers_mask, 2], \n",
    "                      c='red', alpha=0.8, label='Outliers Test', s=40, marker='^')\n",
    "\n",
    "ax1.set_xlabel('Alpha (escalado)')\n",
    "ax1.set_ylabel('Beta (escalado)')\n",
    "ax1.set_zlabel('Flux (escalado)')\n",
    "ax1.set_title('Clasificación en Datos de Test')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Candidatos a materia oscura\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "\n",
    "if len(candidates) > 0:\n",
    "    # Escalar candidatos para visualización\n",
    "    candidates_features = candidates[['alpha', 'beta', 'flux']].values\n",
    "    candidates_scaled = scaler.transform(candidates_features)\n",
    "    \n",
    "    scatter3 = ax2.scatter(candidates_scaled[:, 0], \n",
    "                          candidates_scaled[:, 1], \n",
    "                          candidates_scaled[:, 2], \n",
    "                          c=candidates['anomaly_score'], \n",
    "                          cmap='plasma', alpha=0.8, s=50)\n",
    "    \n",
    "    plt.colorbar(scatter3, ax=ax2, shrink=0.5, aspect=10, label='Anomaly Score')\n",
    "\n",
    "ax2.set_xlabel('Alpha (escalado)')\n",
    "ax2.set_ylabel('Beta (escalado)')\n",
    "ax2.set_zlabel('Flux (escalado)')\n",
    "ax2.set_title('Candidatos a Materia Oscura')\n",
    "\n",
    "# Plot 3: Comparación general\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "\n",
    "# Muestra representativa de fuentes asociadas\n",
    "sample_size = min(1000, len(X_train_scaled))\n",
    "sample_indices = np.random.choice(len(X_train_scaled), sample_size, replace=False)\n",
    "sample_associated = X_train_scaled[sample_indices]\n",
    "\n",
    "scatter4 = ax3.scatter(sample_associated[:, 0], \n",
    "                      sample_associated[:, 1], \n",
    "                      sample_associated[:, 2], \n",
    "                      c='lightblue', alpha=0.3, label='Asociadas', s=10)\n",
    "\n",
    "# Candidatos anómalos\n",
    "if len(candidates) > 0:\n",
    "    scatter5 = ax3.scatter(candidates_scaled[:, 0], \n",
    "                          candidates_scaled[:, 1], \n",
    "                          candidates_scaled[:, 2], \n",
    "                          c='red', alpha=0.9, label='Candidatos DM', s=60, marker='^')\n",
    "\n",
    "ax3.set_xlabel('Alpha (escalado)')\n",
    "ax3.set_ylabel('Beta (escalado)')\n",
    "ax3.set_zlabel('Flux (escalado)')\n",
    "ax3.set_title('Comparación: Asociadas vs Candidatos')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
