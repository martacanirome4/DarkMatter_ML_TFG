{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN with 2F\n",
    "\n",
    "This code:\n",
    "- Classifies astrophysical sources into two groups using two features and a neural network.\n",
    "- Uses stratified repeated k-fold cross-validation to ensure robust evaluation.\n",
    "- Collects accuracy, true positive rate, and true negative rate.\n",
    "- Predicts class probabilities for unknown (unlabeled) sources (unids).\n",
    "- Writes out those probabilities for downstream analysis.\n",
    "\n",
    "Then\n",
    "1. Loads unID object features and neural network prediction results.\n",
    "2. Reshapes and organizes prediction probabilities by object.\n",
    "3. Computes mean and standard deviation of predicted probabilities across multiple models.\n",
    "4. Prepares for threshold-based classification of unIDs (based on p_cut)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "XY_bal_log_Rel= np.genfromtxt('../data/XY_bal_log_Rel.txt',dtype='str') \n",
    "XY_bal_log_Rel_data = np.asarray(XY_bal_log_Rel[1::,:],dtype=float)\n",
    "print('Columns: ', XY_bal_log_Rel [0,:])\n",
    "\n",
    "print('Shape of XY_bal_log_Rel_data: ', XY_bal_log_Rel_data.shape)\n",
    "\n",
    "\n",
    "XY_bal_log_Rel_data_sigma0=np.zeros([0,XY_bal_log_Rel_data.shape[1]])\n",
    "\n",
    "sigmaastro=0\n",
    "\n",
    "for i in range (0,len(XY_bal_log_Rel_data)):\n",
    "    if XY_bal_log_Rel_data[i,2]>=sigmaastro: #remeber column are 0=beta, 1=beta_err, 2=E_peak, 3=sigma, 4=curv_sign\n",
    "        XY_bal_log_Rel_data_sigma0=np.concatenate( (XY_bal_log_Rel_data_sigma0, [XY_bal_log_Rel_data[i,:]] ) , axis=0)\n",
    "\n",
    "\n",
    "XY_bal_log_Rel_data=XY_bal_log_Rel_data_sigma0\n",
    "\n",
    "X_bal_log_Rel_data= XY_bal_log_Rel_data[:,[0,1]] # This selects only columns 0 and 1 (shape: (n, 2)), \n",
    "Y=XY_bal_log_Rel_data[:,4]\n",
    "print('Shape of X_bal_log_Rel_data:', X_bal_log_Rel_data.shape)\n",
    "print('Shape of Y: ', Y.shape)\n",
    "print('10**XY_bal_log_Rel_data[:,2].min() ---- ', 10**XY_bal_log_Rel_data[:,2].min())\n",
    "print('Y: ', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "ax0, ax1, ax2, ax3 = axes.flatten()\n",
    "\n",
    "#colors = ['red', 'tan', 'lime']\n",
    "ax0.hist(X_bal_log_Rel_data[:,[0]], 100, color='orange')\n",
    "#ax0.hist(DM_log_bal_Rel[:,[0]], 100, color='m')\n",
    "#ax0.hist(unids_log[:,[0]], 100, color='red')\n",
    "#ax0.legend(prop={'size': 10})\n",
    "#ax0.set_title('Epeak distribution')\n",
    "ax0.set_xlabel(r' $Log(E_{peak})$')\n",
    "ax0.set_ylabel('count')\n",
    "\n",
    "ax1.hist(X_bal_log_Rel_data[:,[1]], 100, color='orange')\n",
    "#ax1.hist(DM_log_bal_Rel[:,[1]], 100, color='m')\n",
    "#ax1.hist(unids_log[:,[1]], 100,color='red')\n",
    "ax1.legend(('TOT: Astro+DM'))\n",
    "#ax1.set_title('Beta distribution')\n",
    "ax1.set_xlabel(r' $Log(\\beta)$')\n",
    "ax1.set_ylabel('count')\n",
    "\n",
    "\"\"\"\n",
    "ax2.hist(X_bal_log_Rel_data[:,[2]], 100, color='orange')\n",
    "#ax2.hist(DM_log_bal_Rel[:,[2]], 100, color='m')\n",
    "#ax2.hist(unids_log[:,[2]], 100, color='red')\n",
    "#ax2.set_title('sigma distribution')\n",
    "ax2.set_xlabel(r' $Log(\\sigma_{TS})$')\n",
    "ax2.set_ylabel('count')\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "ax3.hist(X_bal_log_Rel_data[:,[3]], 100, color='orange')\n",
    "#ax3.hist(DM_log_bal_Rel[:,[3]], 100, color='m')\n",
    "#ax3.hist(unids_log[:,[3]], 100, color='red')\n",
    "#ax3.set_title('beta_err distribution')\n",
    "ax3.set_xlabel(r' $Log(\\beta_{rel})$')\n",
    "ax3.set_ylabel('count')\n",
    "\"\"\"\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#fig.savefig(\"histo_tot_data_bal.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('sigma max',10**X_bal_log_Rel_data[:,2].max())\n",
    "print('sigma min',10**X_bal_log_Rel_data[:,2].min())\n",
    "print('log sigma max',X_bal_log_Rel_data[:,2].max())\n",
    "print('log sigma min',X_bal_log_Rel_data[:,2].min())\n",
    "np.log10(100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of instances in each class of the binary label vector Y (0=astro, 1=DM)\n",
    "NDM_sample=0\n",
    "\n",
    "for i in range(0,len(Y)):\n",
    "       if Y[i]==1: \n",
    "        NDM_sample=NDM_sample+1\n",
    "\n",
    "print (NDM_sample)\n",
    "\n",
    "Nastro_sample=0\n",
    "\n",
    "for i in range(0,len(Y)):\n",
    "       if Y[i]==0: \n",
    "        Nastro_sample=Nastro_sample+1\n",
    "        \n",
    "print (Nastro_sample)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_log=X_bal_log_Rel_data\n",
    "\n",
    "#normalizer = sklearn.preprocessing.StandardScaler()\n",
    "#normalizer.fit(X_log)\n",
    "#print('StandardSaler mean', normalizer.mean_)\n",
    "#X_log = normalizer.transform(X_log)\n",
    "\n",
    "#X_log = np.log10(X_log)\n",
    "\n",
    "print(X_log.shape)\n",
    "print(X_log[1:5,0])\n",
    "print(X_log[1:5,1])\n",
    "\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading and Preprocessing New Data (unids)\n",
    "unids_3F = np.genfromtxt('../data/unids_3F_beta_err_names.txt',dtype='str') \n",
    "unids_3F_data = np.asarray(unids_3F[1::,:],dtype=float)\n",
    "\n",
    "print(unids_3F[0,:])\n",
    "\n",
    "unids_log=np.log10(unids_3F_data[:,[0,1]])\n",
    "print(unids_log.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure()\n",
    "plt.scatter(unids_log[:,0],unids_log[:,1], color='red',label='unids',s=5)\n",
    "plt.scatter(np.log10(unids_3F_data[:,0]),np.log10(unids_3F_data[:,1]), \n",
    "          color='green',label='DM-cand',s=1)\n",
    "#plt.errorbar(selected_unIDs_80[:,0], selected_unIDs_80[:,1], yerr=selected_unIDs_80[:,3], fmt=\"o\")\n",
    "\n",
    "plt.ylabel(r' $Log(\\beta)$')\n",
    "plt.xlabel(r' $Log(E_{peak})$')\n",
    "plt.xlim(-5,6)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "normalizer = sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "N_splits=5 #25% of testing set with N_splits=4, but we lost the easy 5 statitics in each bin\n",
    "N_Repeats=2\n",
    "#N_sample=N_splits*N_Repeats\n",
    "\n",
    "OA=[]\n",
    "TN=[]\n",
    "TP=[]\n",
    "#unIDs_std_proba_check_repeated_rs_stats_all=np.array((1,))\n",
    "\n",
    "#OA_rs_stats=open(\"OA_rs_stats.txt\", \"w\")\n",
    "#OA_rs_stats.write('seed_value OA \\n') \n",
    "#TN_rs_stats=open(\"TN_rs_stats.txt\", \"w\")\n",
    "#TN_rs_stats.write('seed_value TN \\n') \n",
    "#TP_rs_stats=open(\"TP_rs_stats.txt\", \"w\")\n",
    "#TP_rs_stats.write('seed_value TP \\n') \n",
    "\n",
    "unids_DM_std_proba_check_repeated_kfold_2F_21=open(\"../data/results/ann/2F/unids_DM_std_proba_check_repeated_kfold_2F_21.txt\", \"w\")\n",
    "unids_DM_std_proba_check_repeated_kfold_2F_21.write('Numb unids_DM_proba_check_repeated_kfold \\n') \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "------------------------------- Setting Up Cross-Validation -----------------------------------\n",
    "Splits the data into stratified folds (preserving class ratio) for better generalization\n",
    "Total 10 splits (5-fold repeated 2 times)\n",
    "-----------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "rskf = RepeatedStratifiedKFold(n_splits=N_splits, n_repeats=N_Repeats)\n",
    "rskf.get_n_splits(X_log, Y)\n",
    "print('rskf',rskf)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "--------------------------------------- Classifier Setup --------------------------------------\n",
    "A neural net with:\n",
    "        - One hidden layer of 21 neurons.\n",
    "        - ReLU activation.\n",
    "        - Learning rate of 0.015.\n",
    "        - 1000 max iterations.\n",
    "        - Adam optimizer.\n",
    "        - No L2 regularization (alpha=0.0).\n",
    "-----------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "ANN = MLPClassifier(solver='adam', alpha=0.0, batch_size=120, hidden_layer_sizes=(21,), \n",
    "                 learning_rate_init=0.015, max_iter=1000, random_state=None, activation='relu')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "--------------------------------- Training + Evaluation Loop ----------------------------------\n",
    "For each cross-validation split:\n",
    "1. Train-test split based on fold.\n",
    "2. Standardize the features using StandardScaler (fit on training, transform both).\n",
    "3. Train the MLP (ANN.fit()).\n",
    "4. Predict:\n",
    "        - Binary class predictions (predict()).\n",
    "        - Class probabilities (predict_proba()).\n",
    "5. Collect metrics:\n",
    "        - Accuracy (OA).\n",
    "        - Confusion matrix:\n",
    "        - TN (True Negative Rate)\n",
    "        - TP (True Positive Rate\n",
    "\"\"\"    \n",
    "for train_index, test_index in rskf.split(X_log, Y):\n",
    "        print('train_index',train_index.shape, \"test_index\", test_index.shape)\n",
    "        X_train_split, X_test_split = X_log[train_index], X_log[test_index]\n",
    "        Y_train_split, Y_test_split = Y[train_index], Y[test_index]\n",
    "        normalizer.fit(X_train_split)\n",
    "        X_train_split_std=normalizer.transform(X_train_split)\n",
    "        X_test_split_std=normalizer.transform(X_test_split)\n",
    "    \n",
    "        ANN_fit=ANN.fit(X_train_split_std, Y_train_split)\n",
    "        Y_test_split_01_std_check=ANN_fit.predict(X_test_split_std)\n",
    "        Y_test_split_proba_std_check=ANN_fit.predict_proba(X_test_split_std)\n",
    "        \n",
    "        OA.extend([accuracy_score(Y_test_split, Y_test_split_01_std_check)])\n",
    "        conf_matrix=sklearn.metrics.confusion_matrix(Y_test_split, Y_test_split_01_std_check, normalize='true')\n",
    "        TN.extend([conf_matrix[0,0]])\n",
    "        TP.extend([conf_matrix[1,1]])\n",
    "        \n",
    "        \n",
    "        \"------------------------------------ Predict on Unidentified Sources --------------------------------------\"\n",
    "        unids_std_check=normalizer.transform(unids_log)\n",
    "        unIDs_std_proba_check_repeated_kfold=ANN_fit.predict_proba(unids_std_check)\n",
    "        \"\"\" \n",
    "        For each split, the model is also applied to the unids_log dataset (unlabeled sources),  nd it writes out the probability of being class 1 for each one.\n",
    "        This provides multiple predictions across different models/splits.\n",
    "\n",
    "        This writes a file: \"unids_DM_std_proba_check_repeated_kfold_2F_21.txt\" which contains, for each fold/repeat:\n",
    "                - Column 0: the unID index (from 0 to N_unids-1)\n",
    "                - Column 1: the predicted probability of being DM-like from that fold\n",
    "        \"\"\"\n",
    "        for i in range(0,len(unids_std_check)):\n",
    "                #unIDs_std_proba_check_repeated_rs_stats_all[i]=np.append(ANN_fit.predict_proba(unids_std_check)[i,1])\n",
    "                unids_DM_std_proba_check_repeated_kfold_2F_21.write('{} {} \\n'.format(i, \n",
    "                                                                    unIDs_std_proba_check_repeated_kfold[i,1]))\n",
    "   \n",
    "\n",
    "       # OA_rs_stats.write('{} {} \\n'.format(seed_value[j], OA[j]))\n",
    "        #TN_rs_stats.write('{} {} \\n'.format(seed_value[j], TN[j]))\n",
    "        #TP_rs_stats.write('{} {} \\n'.format(seed_value[j], TP[j]))  \n",
    "\n",
    "    \n",
    "unids_DM_std_proba_check_repeated_kfold_2F_21.close()\n",
    "\n",
    "#OA_rs_stats.close()\n",
    "#TN_rs_stats.close()\n",
    "#TP_rs_stats.close()\n",
    "\n",
    "\n",
    "print('X_train_split.shape', X_train_split.shape)\n",
    "print('X_test_split.shape', X_test_split.shape)\n",
    "\n",
    "#unIDs_std_proba_check_repeated_rs_stats=np.array(unIDs_std_proba_check_repeated_rs_stats)\n",
    "#print('unIDs_std_proba_check_repeated_rs_stats.shape',unIDs_std_proba_check_repeated_rs_stats.shape)\n",
    "#print(unIDs_std_proba_check_repeated_rs_stats[0:3,:])\n",
    "\n",
    "OA=np.array(OA)\n",
    "#OA=np.reshape(OA,(len(unids_std_check),(N_sample)))\n",
    "TN=np.array(TN)\n",
    "#TN=np.reshape(TN,(len(unids_std_check),(N_sample)))\n",
    "TP=np.array(TP)\n",
    "#TP=np.reshape(TP,(len(unids_std_check),(N_sample)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OA.shape)\n",
    "#print(OA)\n",
    "print('OA mean', OA.mean(), 'OA std',OA.std(ddof=1))\n",
    "print('TN mean', TN.mean(), 'TN std',TN.std(ddof=1))\n",
    "print('TP mean', TP.mean(), 'TP std',TP.std(ddof=1))\n",
    "print(unIDs_std_proba_check_repeated_kfold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure()\n",
    "#plt.scatter(unids_log[:,0],unids_log[:,1], color='red',label='unids log',s=5)\n",
    "#plt.scatter(np.log10(unids_3F_data[:,0]),np.log10(unids_3F_data[:,1]), \n",
    "         # color='green',label='unids lin data',s=1)\n",
    "plt.scatter(unids_std_check[:,0],unids_std_check[:,1], \n",
    "          color='blue',label='unids norm',s=1)\n",
    "plt.scatter(X_test_split_std[:,0],X_test_split_std[:,1], \n",
    "          color='yellow',label='X_train_split',s=1)\n",
    "#plt.errorbar(selected_unIDs_80[:,0], selected_unIDs_80[:,1], yerr=selected_unIDs_80[:,3], fmt=\"o\")\n",
    "\n",
    "plt.ylabel(r' $Log(\\beta)$')\n",
    "plt.xlabel(r' $Log(E_{peak})$')\n",
    "plt.xlim(-5,6)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.5],\n",
    "        xlim=[0, len(X_log)],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cv = rskf\n",
    "plot_cv_indices(cv, X_log , Y, Y ,ax, N_splits*N_Repeats)\n",
    "ax.axes\n",
    "ax.legend(\n",
    "        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.2))],\n",
    "        [\"Testing set\", \"Training set\"],\n",
    "        loc=(1.02, 0.8),\n",
    "    )\n",
    "\n",
    "#fig.savefig(\"Reapeated5_Kfold5_split.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unIDs classification with errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective\n",
    "To compute the mean and standard deviation of predicted probabilities (to be class 1 = DM-like) for each unID source, across multiple runs of the trained classifier (from the previous MLPClassifier code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load unID source data\n",
    "unids_3F = np.genfromtxt('../data/unids_3F_beta_err_names.txt',dtype='str') \n",
    "unids_3F_data = np.asarray(unids_3F[1::,:],dtype=float)\n",
    "\n",
    "print(unids_3F[0,:])\n",
    "\n",
    "unids_log=np.log10(unids_3F_data[:,[0,1]])\n",
    "print(unids_log.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Load model prediction outputs\n",
    "    - Loads the probabilities written during each fold of training.\n",
    "    - Assumes format: [index, probability] for each unID, per split.\n",
    "\"\"\"\n",
    "unids_DM_std_proba_repeated_kfold= np.genfromtxt('../data/results/ann/2F/unids_DM_std_proba_check_repeated_kfold_2F_21.txt',dtype='str') \n",
    "unids_DM_std_proba_data_repeated_kfold=np.asarray(unids_DM_std_proba_repeated_kfold[1::],dtype=float)\n",
    "print(unids_DM_std_proba_data_repeated_kfold[0,:])\n",
    "print(unids_DM_std_proba_data_repeated_kfold[1,:])\n",
    "\n",
    "#N_splits=5\n",
    "#N_Repeats=3\n",
    "\n",
    "print('unids_DM_std_proba_data_repeated_kfold.shape',unids_DM_std_proba_data_repeated_kfold.shape)\n",
    "print(unids_DM_std_proba_data_repeated_kfold[0,0:3])\n",
    "print(unids_DM_std_proba_data_repeated_kfold[1,0:3])\n",
    "print(unids_DM_std_proba_data_repeated_kfold[2,0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#defining an array where each column is the probability to be DM for each unIDs in each split\n",
    "\n",
    "#defining an array where each column is the probability to be DM for each unIDs in each split\n",
    "\n",
    "\"\"\" \n",
    "Extract useful variables\n",
    "      - N_unids: number of unID sources.\n",
    "      - N_sample: number of times each unID was evaluated = number of folds × repeats.\n",
    "\"\"\"\n",
    "N_unids=unids_log.shape[0]\n",
    "print('N_unids',N_unids)\n",
    "\n",
    "#N_splits=3\n",
    "#N_Repeats=10\n",
    "\n",
    "N_sample=N_splits*N_Repeats\n",
    "print('N_sample',N_sample)\n",
    "\n",
    "print(unids_DM_std_proba_data_repeated_kfold.shape)\n",
    "\n",
    "\"\"\" \n",
    "Reshape probability data. Purpose:\n",
    "      Build a structured array where:\n",
    "            - First column = unID index\n",
    "            - Remaining columns = predicted probabilities across each of the N_sample splits\n",
    "      This assumes the file ordering is consistent and that predictions are block-structured:\n",
    "            - First N_unids rows = fold 1\n",
    "            - Second N_unids rows = fold 2\n",
    "            -  ...\n",
    "\"\"\"\n",
    "unids_number=unids_DM_std_proba_data_repeated_kfold[0:N_unids,0]\n",
    "\n",
    "print('unids number',unids_number)\n",
    "print('unids number shape',unids_number.shape)\n",
    "\n",
    "unids_DM_std_proba_N_sample_repeated_kfold=np.zeros((N_unids,(N_sample+1)))\n",
    "\n",
    "unids_DM_std_proba_N_sample_repeated_kfold[:,0]=unids_number[:].astype(int)\n",
    "unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)]=np.reshape(\n",
    "unids_DM_std_proba_data_repeated_kfold[:,1],(N_unids,(N_sample)))\n",
    "\n",
    "print('unids_DM_std_proba_N_sample_repeated_kfold.shape', \n",
    "      unids_DM_std_proba_N_sample_repeated_kfold.shape)\n",
    "print(unids_DM_std_proba_N_sample_repeated_kfold)\n",
    "\n",
    "#unids_DM_std_proba_N_sample_repeated_kfold=np.array(unids_DM_std_proba_N_sample_repeated_kfold)\n",
    "\n",
    "#unids_int_prob=float((unids_DM_std_proba_N_sample_repeated_kfold[:,1].T))\n",
    "#print(unids_int_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" \n",
    "Compute statistics\n",
    "    - unids_mean: average probability of being DM-like across all splits\n",
    "    - unids_std: standard deviation of that probability — gives a measure of confidence\n",
    "\"\"\"\n",
    "unids_mean=unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)].mean(axis=1)\n",
    "unids_std=unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)].std(axis=1,ddof=1)\n",
    "print('unids_mean', unids_mean, 'unids std',unids_std)\n",
    "print(unids_mean.shape)\n",
    "\n",
    "\"\"\" \n",
    "Define Probability Thresholds\n",
    "    - mean_prob ≥ 0.90 (strong candidate)\n",
    "    - mean_prob ≥ 0.50 (moderate candidate)\n",
    "\"\"\"\n",
    "p_cut=0.90\n",
    "p_cut_50=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration and data loading\n",
    "# Configuration\n",
    "N_splits = 5\n",
    "N_Repeats = 2\n",
    "N_sample = N_splits * N_Repeats\n",
    "\n",
    "print(f\"Cross-validation setup: {N_splits} splits × {N_Repeats} repeats = {N_sample} total folds\")\n",
    "\n",
    "# Load unID source data\n",
    "unids_3F = np.genfromtxt('../data/unids_3F_beta_err_names.txt', dtype='str') \n",
    "unids_3F_data = np.asarray(unids_3F[1::, :], dtype=float)\n",
    "feature_names = unids_3F[0, :]\n",
    "\n",
    "print(f\"Feature names: {feature_names}\")\n",
    "print(f\"UnID data shape: {unids_3F_data.shape}\")\n",
    "\n",
    "# Create log-transformed features (F_peak and beta)\n",
    "unids_log = np.log10(unids_3F_data[:, [0, 1]])\n",
    "print(f\"Log-transformed features shape: {unids_log.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model prediction outputs\n",
    "unids_DM_std_proba_repeated_kfold = np.genfromtxt('../data/results/ann/2F/unids_DM_std_proba_check_repeated_kfold_2F_21.txt', dtype='str') \n",
    "unids_DM_std_proba_data_repeated_kfold = np.asarray(unids_DM_std_proba_repeated_kfold[1::], dtype=float)\n",
    "\n",
    "print(f\"Predictions data shape: {unids_DM_std_proba_data_repeated_kfold.shape}\")\n",
    "print(f\"First few predictions:\")\n",
    "print(unids_DM_std_proba_data_repeated_kfold[:5, :])\n",
    "\n",
    "# Get number of unidentified sources\n",
    "N_unids = unids_log.shape[0]\n",
    "print(f\"Number of unidentified sources: {N_unids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract unID indices from first N_unids rows\n",
    "unids_number = unids_DM_std_proba_data_repeated_kfold[0:N_unids, 0]\n",
    "print(f\"UnID indices shape: {unids_number.shape}\")\n",
    "\n",
    "# Create probability matrix: rows = unIDs, columns = CV folds + index\n",
    "unids_DM_std_proba_N_sample_repeated_kfold = np.zeros((N_unids, N_sample + 1))\n",
    "\n",
    "# Fill in the data\n",
    "unids_DM_std_proba_N_sample_repeated_kfold[:, 0] = unids_number[:].astype(int)\n",
    "unids_DM_std_proba_N_sample_repeated_kfold[:, 1:(N_sample + 1)] = np.reshape(\n",
    "    unids_DM_std_proba_data_repeated_kfold[:, 1], (N_unids, N_sample)\n",
    ")\n",
    "\n",
    "print(f\"Probability matrix shape: {unids_DM_std_proba_N_sample_repeated_kfold.shape}\")\n",
    "print(\"First few rows of probability matrix:\")\n",
    "print(unids_DM_std_proba_N_sample_repeated_kfold[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "#ax0, ax1, ax2 = axes.flatten()\n",
    "#for i in range(0,len(unids_DM_std_proba_N_sample_repeated_kfold)):\n",
    "counts_all, bins_all, ignored = plt.hist(unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)], \n",
    "                                             bins, histtype='barstacked', density=False)\n",
    "plt.axvline(0.50, color='magenta', linestyle=':', linewidth=2)\n",
    "plt.axvline(0.68, color='red', linestyle=':', linewidth=2)\n",
    "plt.axvline(0.95, color='blue', linestyle='--', linewidth=2)\n",
    "plt.axvline(0.99, color='black', linestyle='-', linewidth=2)\n",
    "#plt.axvline(value_unID, color='k', linestyle='-', linewidth=1)\n",
    "#plt.axvline(unids_std.all(), color='green', linestyle='-', linewidth=1)\n",
    "#plt.axvline(unids_std.all(), color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel(r' $p_k(DM)$',size=20)\n",
    "plt.ylabel('count',size=20)\n",
    "\n",
    "#fig.savefig(\"full_histo_2F.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "#ax0, ax1, ax2 = axes.flatten()\n",
    "\n",
    "bins=[0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "\n",
    "counts_all, bins_all, ignored = plt.hist(unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)], \n",
    "                                         bins,histtype='barstacked', density=False, color=all_color[i,:])\n",
    "#plt.scatter(bins_all[:],counts_all[:])\n",
    "plt.axvline(0.50, color='magenta', linestyle=':', linewidth=1)\n",
    "plt.axvline(0.68, color='red', linestyle=':', linewidth=1)\n",
    "plt.axvline(0.90, color='blue', linestyle='--', linewidth=1)\n",
    "plt.axvline(0.95, color='black', linestyle='--', linewidth=1)\n",
    "plt.axvline(0.99, color='gray', linestyle='--', linewidth=1)\n",
    "#plt.axvline(value_unID, color='k', linestyle='-', linewidth=1)\n",
    "#plt.axvline(unids_std.all(), color='green', linestyle='-', linewidth=1)\n",
    "#plt.axvline(unids_std.all(), color='green', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.xlabel(r' $p_k^{DM}$',size=15)\n",
    "plt.ylabel('count',size=15)\n",
    "plt.title(r' $NN, 2F$', y=10**(0), x=10**(-0.5), pad=-30)\n",
    "#plt.yscale('log')\n",
    "\n",
    "#fig.savefig(\"full_histo_2F_single_count.pdf\", bbox_inches='tight')\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_color=np.asarray(unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)],dtype='str')\n",
    "\n",
    "print(all_color.shape)\n",
    "\n",
    "for i in range(0,len(unids_DM_std_proba_N_sample_repeated_kfold[:,1:(N_sample+1)])):\n",
    "    for j in range(0,N_sample):\n",
    "        all_color[i,j]='midnightblue'\n",
    "\n",
    "print(len(unids_log))    \n",
    "print(all_color.shape)\n",
    "print(all_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFG Marta - Additional analysis 2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract probability data (excluding index column)\n",
    "prob_data = unids_DM_std_proba_N_sample_repeated_kfold[:, 1:(N_sample + 1)]\n",
    "\n",
    "unids_mean = prob_data.mean(axis=1)              # Media - promedio de probabilidad across all folds\n",
    "unids_std = prob_data.std(axis=1, ddof=1)        # Desviación estándar - consistencia\n",
    "unids_median = np.median(prob_data, axis=1)      # Mediana - valor central, robusto a outliers\n",
    "unids_q25 = np.percentile(prob_data, 25, axis=1) # Cuartil 25\n",
    "unids_q75 = np.percentile(prob_data, 75, axis=1) # Cuartil 75\n",
    "unids_min = prob_data.min(axis=1)                # Valor mínimo\n",
    "unids_max = prob_data.max(axis=1)                # Valor máximo\n",
    "\n",
    "\"\"\" \n",
    "Si std es muy alta → El modelo es inconsistente para esa fuente\n",
    "Si mean es alta → El modelo cree que es un buen candidato a materia oscura\n",
    "Si median es muy diferente a mean → Hay valores extremos\n",
    "\"\"\"\n",
    "unids_q25 = np.percentile(prob_data, 25, axis=1) # Cuartil 25 - 25% de los valores son menores\n",
    "unids_q75 = np.percentile(prob_data, 75, axis=1) # Cuartil 75 - 75% de los valores son menores\n",
    "unids_min = prob_data.min(axis=1) # Valor mínimo - el más bajo\n",
    "unids_max = prob_data.max(axis=1) # Valor máximo - el más alto\n",
    "\n",
    "unids_iqr = unids_q75 - unids_q25               # Rango intercuartílico - robustez\n",
    "unids_cv = unids_std / (unids_mean + 1e-8)      # Coeficiente de variación - consistencia relativa\n",
    "unids_skew = stats.skew(prob_data, axis=1)      # Asimetría de la distribución\n",
    "unids_range = unids_max - unids_min             # Rango total\n",
    "\n",
    "print(f\"Total sources analyzed: {len(unids_mean)}\")\n",
    "print(f\"Mean probability: {unids_mean.mean():.4f} ± {unids_mean.std():.4f}\")\n",
    "print(f\"Mean uncertainty (std): {unids_std.mean():.4f} ± {unids_std.std():.4f}\")\n",
    "print(f\"Median probability: {np.median(unids_mean):.4f}\")\n",
    "print(f\"Mean coefficient of variation: {unids_cv.mean():.4f}\")\n",
    "print(f\"Sources with CV < 0.2 (low variability): {np.sum(unids_cv < 0.2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Primary thresholds\n",
    "p_cut_very_high = 0.95      # Very high confidence\n",
    "p_cut_high = 0.90           # High confidence \n",
    "p_cut_moderate = 0.50       # Moderate confidence\n",
    "uncertainty_threshold = 0.1  # Low uncertainty (std)\n",
    "consistency_threshold = 0.2  # Low coefficient of variation\n",
    "\n",
    "# Create masks for different candidate types\n",
    "very_high_conf_mask = unids_mean >= p_cut_very_high\n",
    "high_conf_mask = (unids_mean >= p_cut_high) & (unids_mean < p_cut_very_high)\n",
    "moderate_conf_mask = (unids_mean >= p_cut_moderate) & (unids_mean < p_cut_high)\n",
    "low_uncertainty_mask = unids_std <= uncertainty_threshold\n",
    "consistent_mask = unids_cv <= consistency_threshold\n",
    "\n",
    "# Candidatos \"premium\": alta probabilidad + baja incertidumbre\n",
    "premium_candidates_mask = (unids_mean >= p_cut_high) & (unids_std <= uncertainty_threshold)\n",
    "# Candidatos \"estables\": consistencia alta (bajo CV) independiente de probabilidad\n",
    "stable_candidates_mask = unids_cv <= 0.15\n",
    "\n",
    "# Get indices\n",
    "very_high_conf_indices = np.where(very_high_conf_mask)[0]\n",
    "high_conf_indices = np.where(high_conf_mask)[0]\n",
    "moderate_conf_indices = np.where(moderate_conf_mask)[0]\n",
    "low_uncertainty_indices = np.where(low_uncertainty_mask)[0]\n",
    "premium_candidates_indices = np.where(premium_candidates_mask)[0]\n",
    "stable_candidates_indices = np.where(stable_candidates_mask)[0]\n",
    "\n",
    "# Report candidate counts\n",
    "print(f\"VERY HIGH CONFIDENCE (≥{p_cut_very_high:.0%}): {len(very_high_conf_indices)}\")\n",
    "print(f\"HIGH CONFIDENCE ({p_cut_high:.0%}-{p_cut_very_high:.0%}): {len(high_conf_indices)}\")\n",
    "print(f\"MODERATE CONFIDENCE ({p_cut_moderate:.0%}-{p_cut_high:.0%}): {len(moderate_conf_indices)}\")\n",
    "print(f\"LOW UNCERTAINTY (std ≤{uncertainty_threshold}): {len(low_uncertainty_indices)}\")\n",
    "print(f\"PREMIUM CANDIDATES (high prob + low uncert): {len(premium_candidates_indices)}\")\n",
    "print(f\"STABLE CANDIDATES (CV ≤ 0.15): {len(stable_candidates_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(very_high_conf_indices) > 0:\n",
    "    print(f\"\\nTOP VERY HIGH CONFIDENCE CANDIDATES:\")\n",
    "    for i in very_high_conf_indices[:min(5, len(very_high_conf_indices))]:\n",
    "        print(f\"  Source {i}: p={unids_mean[i]:.4f} ± {unids_std[i]:.4f} (CV={unids_cv[i]:.3f})\")\n",
    "\n",
    "if len(premium_candidates_indices) > 0:\n",
    "    print(f\"\\nPREMIUM CANDIDATES (high prob + low uncertainty):\")\n",
    "    for i in premium_candidates_indices[:min(5, len(premium_candidates_indices))]:\n",
    "        print(f\"  Source {i}: p={unids_mean[i]:.4f} ± {unids_std[i]:.4f} (CV={unids_cv[i]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive probability distribution plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# All predictions histogram (original style)\n",
    "ax1 = axes[0, 0]\n",
    "bins = np.arange(0.0, 1.1, 0.1)\n",
    "counts, bins_edges, _ = ax1.hist(prob_data.flatten(), bins=bins, \n",
    "                                alpha=0.7, color='skyblue', edgecolor='black')\n",
    "\n",
    "ax1.axvline(0.50, color='magenta', linestyle=':', linewidth=2, label='p=0.50')\n",
    "ax1.axvline(0.68, color='red', linestyle=':', linewidth=2, label='p=0.68')\n",
    "ax1.axvline(0.90, color='blue', linestyle='--', linewidth=2, label='p=0.90')\n",
    "ax1.axvline(0.95, color='green', linestyle='--', linewidth=2, label='p=0.95')\n",
    "ax1.axvline(0.99, color='black', linestyle='-', linewidth=2, label='p=0.99')\n",
    "\n",
    "ax1.set_xlabel('DM Probability')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Distribution of All CV Predictions')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Mean probability distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(unids_mean, bins=bins, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "ax2.axvline(0.50, color='magenta', linestyle=':', linewidth=2, label='p=0.50')\n",
    "ax2.axvline(0.90, color='blue', linestyle='--', linewidth=2, label='p=0.90')\n",
    "ax2.axvline(0.95, color='green', linestyle='--', linewidth=2, label='p=0.95')\n",
    "ax2.set_xlabel('Mean DM Probability')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Distribution of Mean Predictions')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Uncertainty distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(unids_std, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "ax3.axvline(0.1, color='red', linestyle='--', linewidth=2, label='std=0.1')\n",
    "ax3.axvline(0.2, color='orange', linestyle='--', linewidth=2, label='std=0.2')\n",
    "ax3.set_xlabel('Standard Deviation')\n",
    "ax3.set_ylabel('Count')\n",
    "ax3.set_title('Prediction Uncertainty Distribution')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Mean vs Std scatter plot\n",
    "ax4 = axes[1, 1]\n",
    "scatter = ax4.scatter(unids_mean, unids_std, alpha=0.6, c=unids_mean, \n",
    "                     cmap='viridis', s=30)\n",
    "plt.colorbar(scatter, ax=ax4, label='Mean Probability')\n",
    "ax4.axvline(0.50, color='magenta', linestyle=':', alpha=0.7, label='p=0.50')\n",
    "ax4.axvline(0.90, color='blue', linestyle='--', alpha=0.7, label='p=0.90')\n",
    "ax4.axhline(0.1, color='red', linestyle='--', alpha=0.7, label='std=0.1')\n",
    "ax4.set_xlabel('Mean DM Probability')\n",
    "ax4.set_ylabel('Standard Deviation')\n",
    "ax4.set_title('Mean vs Uncertainty')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature space analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Feature space colored by mean probability\n",
    "ax1 = axes[0]\n",
    "scatter = ax1.scatter(unids_log[:, 0], unids_log[:, 1], \n",
    "                     c=unids_mean, cmap='plasma', alpha=0.7, s=40)\n",
    "plt.colorbar(scatter, ax=ax1, label='Mean DM Prob')\n",
    "ax1.set_xlabel('log10(E_peak)')\n",
    "ax1.set_ylabel('log10(beta)')\n",
    "ax1.set_title('Feature Space: Colored by DM Probability')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight high confidence candidates\n",
    "if len(high_conf_indices) > 0:\n",
    "    ax1.scatter(unids_log[high_conf_indices, 0], unids_log[high_conf_indices, 1], \n",
    "               s=100, facecolors='none', edgecolors='red', linewidth=2, \n",
    "               label=f'High Conf (≥{p_cut_high:.0%})')\n",
    "    ax1.legend()\n",
    "\n",
    "# Feature space colored by uncertainty\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(unids_log[:, 0], unids_log[:, 1], \n",
    "                      c=unids_std, cmap='viridis_r', alpha=0.7, s=40)\n",
    "plt.colorbar(scatter2, ax=ax2, label='Std Dev')\n",
    "ax2.set_xlabel('log10(E_peak)')\n",
    "ax2.set_ylabel('log10(beta)')\n",
    "ax2.set_title('Feature Space: Colored by Uncertainty')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight low uncertainty candidates\n",
    "if len(low_uncertainty_indices) > 0:\n",
    "    ax2.scatter(unids_log[low_uncertainty_indices, 0], unids_log[low_uncertainty_indices, 1], \n",
    "               s=100, facecolors='none', edgecolors='red', linewidth=2, \n",
    "               label=f'Low Uncert (≤{uncertainty_threshold})')\n",
    "    ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top candidates analysis\n",
    "# Create DataFrame for top candidates\n",
    "top_20_indices = np.argsort(unids_mean)[-20:]  # Top 20 by mean probability\n",
    "top_candidates_df = pd.DataFrame({\n",
    "    'Source_ID': top_20_indices,\n",
    "    'Mean_Prob': unids_mean[top_20_indices],\n",
    "    'Std_Dev': unids_std[top_20_indices],\n",
    "    'Median_Prob': unids_median[top_20_indices],\n",
    "    'Min_Prob': unids_min[top_20_indices],\n",
    "    'Max_Prob': unids_max[top_20_indices],\n",
    "    'E_peak': unids_3F_data[top_20_indices, 0],\n",
    "    'Beta': unids_3F_data[top_20_indices, 1],\n",
    "    'log_E_peak': unids_log[top_20_indices, 0],\n",
    "    'log_Beta': unids_log[top_20_indices, 1]\n",
    "})\n",
    "\n",
    "# Sort by mean probability (descending)\n",
    "top_candidates_df = top_candidates_df.sort_values('Mean_Prob', ascending=False)\n",
    "top_candidates_df = top_candidates_df.reset_index(drop=True)\n",
    "\n",
    "print(\"TOP 20 DARK MATTER CANDIDATES:\")\n",
    "display(top_candidates_df.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create complete results DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Source_ID': range(N_unids),\n",
    "    'Mean_Prob': unids_mean,\n",
    "    'Std_Dev': unids_std,\n",
    "    'Median_Prob': unids_median,\n",
    "    'Q25_Prob': unids_q25,\n",
    "    'Q75_Prob': unids_q75,\n",
    "    'Min_Prob': unids_min,\n",
    "    'Max_Prob': unids_max,\n",
    "    'E_peak': unids_3F_data[:, 0],\n",
    "    'Beta': unids_3F_data[:, 1],\n",
    "    'log_E_peak': unids_log[:, 0],\n",
    "    'log_Beta': unids_log[:, 1]\n",
    "})\n",
    "\n",
    "# Add candidate classification flags\n",
    "results_df['Very_High_Conf'] = unids_mean >= 0.95\n",
    "results_df['High_Conf'] = (unids_mean >= p_cut_high) & (unids_mean < 0.95)\n",
    "results_df['Moderate_Conf'] = (unids_mean >= p_cut_moderate) & (unids_mean < p_cut_high)\n",
    "results_df['Low_Uncertainty'] = unids_std <= uncertainty_threshold\n",
    "\n",
    "# Sort by mean probability\n",
    "results_df = results_df.sort_values('Mean_Prob', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv('../data/results/ANN/2F/unid_dm_analysis_complete_results_2F_run3.csv', index=False)\n",
    "print(f\"Complete results saved to '../data/results/ANN/2F/unid_dm_analysis_complete_results_2F.csv'\")\n",
    "print(f\"Total sources analyzed: {len(results_df)}\")\n",
    "\n",
    "# Display summary by category\n",
    "print(\"\\nSUMMARY BY CANDIDATE CATEGORY:\")\n",
    "categories = ['Very_High_Conf', 'High_Conf', 'Moderate_Conf', 'Low_Uncertainty']\n",
    "for cat in categories:\n",
    "    count = results_df[cat].sum()\n",
    "    if count > 0:\n",
    "        mean_prob = results_df[results_df[cat]]['Mean_Prob'].mean()\n",
    "        mean_uncert = results_df[results_df[cat]]['Std_Dev'].mean()\n",
    "        print(f\"{cat.replace('_', ' ')}: {count} sources (avg prob: {mean_prob:.3f}, avg uncert: {mean_uncert:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar reporte\n",
    "report_content = f\"\"\"\n",
    "{'='*80}\n",
    "REPORTE DE ANÁLISIS DE CANDIDATOS DE MATERIA OSCURA\n",
    "{'='*80}\n",
    "\n",
    "PARÁMETROS DEL ANÁLISIS:\n",
    "- Total de fuentes no identificadas: {N_unids}\n",
    "- Configuración de validación cruzada: {N_splits} pliegues × {N_Repeats} repeticiones = {N_sample} evaluaciones totales\n",
    "- Umbral de alta confianza: {p_cut_high:.0%}\n",
    "- Umbral de confianza moderada: {p_cut_moderate:.0%}\n",
    "- Umbral de baja incertidumbre: {uncertainty_threshold}\n",
    "\n",
    "ESTADÍSTICAS GENERALES:\n",
    "- Probabilidad media: {unids_mean.mean():.4f} ± {unids_mean.std():.4f}\n",
    "- Probabilidad mediana: {np.median(unids_mean):.4f}\n",
    "- Incertidumbre media: {unids_std.mean():.4f} ± {unids_std.std():.4f}\n",
    "\n",
    "RESUMEN DE CANDIDATOS:\n",
    "- Muy Alta Confianza (≥95%): {len(very_high_conf_indices)} fuentes\n",
    "- Alta Confianza (≥{p_cut_high:.0%}): {len(high_conf_indices)} fuentes\n",
    "- Confianza Moderada ({p_cut_moderate:.0%}-{p_cut_high:.0%}): {len(moderate_conf_indices)} fuentes\n",
    "- Baja Incertidumbre (≤{uncertainty_threshold}): {len(low_uncertainty_indices)} fuentes\n",
    "\n",
    "TOP 10 CANDIDATOS:\n",
    "{'-'*50}\n",
    "\"\"\"\n",
    "\n",
    "for i in range(min(10, len(results_df))):\n",
    "    row = results_df.iloc[i]\n",
    "    report_content += f\"Fuente {row['Source_ID']:3d}: p={row['Mean_Prob']:.4f}±{row['Std_Dev']:.4f} \"\n",
    "    report_content += f\"(E_peak={row['E_peak']:.3e}, beta={row['Beta']:.4f})\\n\"\n",
    "\n",
    "# Guardar reporte\n",
    "with open('../data/results/ann/2F/reporte_candidatos_dm_2F.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(\"Análisis de ANN 2F completado.\")\n",
    "print(\"Archivos generados:\")\n",
    "print(\"- unid_dm_analysis_complete_results_2F.csv\")\n",
    "print(\"- reporte_candidatos_dm_2F.txt\")\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(f\"\\nRESUMEN FINAL:\")\n",
    "print(f\"Se analizaron {N_unids} fuentes no identificadas\")\n",
    "print(f\"Se encontraron {len(very_high_conf_indices)} candidatos de muy alta confianza (≥95%)\")\n",
    "print(f\"Se encontraron {len(high_conf_indices)} candidatos de alta confianza (≥{p_cut_high:.0%})\")\n",
    "print(f\"Se identificaron {len(moderate_conf_indices)} candidatos de confianza moderada\")\n",
    "print(f\"Se detectaron {len(low_uncertainty_indices)} fuentes con baja incertidumbre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "bins = [i/10 for i in range(11)]\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "counts_all, bins_all, ignored = ax.hist(unids_DM_std_proba_N_sample_repeated_kfold[:, 1:(N_sample+1)],\n",
    "                                         bins=bins, histtype='barstacked', density=False)\n",
    "\n",
    "# Threshold lines\n",
    "ax.axvline(0.50, color='magenta', linestyle=':', linewidth=2)\n",
    "ax.axvline(0.68, color='red', linestyle=':', linewidth=2)\n",
    "ax.axvline(0.95, color='blue', linestyle='--', linewidth=2)\n",
    "ax.axvline(0.99, color='black', linestyle='-', linewidth=2)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(r'$p_k(DM)$', fontsize=20)\n",
    "ax.set_ylabel('Count', fontsize=20)\n",
    "ax.set_title(\"Histogram of $p_k(DM)$ across Unidentified Sources\", fontsize=16)\n",
    "ax.legend([\"$p = 0.50$\", \"$p = 0.68$\", \"$p = 0.95$\", \"$p = 0.99$\"], fontsize=12)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Save figure\n",
    "# fig.savefig(f\"full_histo_2F_{datetime.now():%Y%m%d_%H%M%S}.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de consenso entre 3 diferentes ejecuciones - 2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Configuración\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (14, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "execution_files = [\n",
    "    '../data/results/ann/2F/unid_dm_analysis_complete_results_2F_run1.csv',\n",
    "    '../data/results/ann/2F/unid_dm_analysis_complete_results_2F_run2.csv', \n",
    "    '../data/results/ann/2F/unid_dm_analysis_complete_results_2F_run3.csv'\n",
    "]\n",
    "\n",
    "executions = []\n",
    "for i, file in enumerate(execution_files, 1):\n",
    "    df = pd.read_csv(file)\n",
    "    executions.append(df)\n",
    "    print(f\"Ejecución {i}: {len(df)} fuentes\")\n",
    "\n",
    "# Verificar consistencia\n",
    "n_sources = len(executions[0])\n",
    "assert all(len(ex) == n_sources for ex in executions), \"Inconsistencia en número de fuentes\"\n",
    "print(f\"Verificación exitosa: {n_sources} fuentes en todas las ejecuciones\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_df = pd.DataFrame({\n",
    "    'Source_ID': executions[0]['Source_ID'].astype(int),\n",
    "    'E_peak': executions[0]['E_peak'],\n",
    "    'Beta': executions[0]['Beta'],\n",
    "    'log_E_peak': executions[0]['log_E_peak'],\n",
    "    'log_Beta': executions[0]['log_Beta']\n",
    "})\n",
    "\n",
    "# Agregar probabilidades de cada ejecución\n",
    "for i, ex in enumerate(executions, 1):\n",
    "    consensus_df[f'Prob_Run{i}'] = ex['Mean_Prob']\n",
    "    consensus_df[f'Std_Run{i}'] = ex['Std_Dev']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_cols = ['Prob_Run1', 'Prob_Run2', 'Prob_Run3']\n",
    "std_cols = ['Std_Run1', 'Std_Run2', 'Std_Run3']\n",
    "\n",
    "consensus_df['Mean_Consensus'] = consensus_df[prob_cols].mean(axis=1)\n",
    "consensus_df['Std_Consensus'] = consensus_df[prob_cols].std(axis=1, ddof=1)\n",
    "consensus_df['Min_Consensus'] = consensus_df[prob_cols].min(axis=1)\n",
    "consensus_df['Max_Consensus'] = consensus_df[prob_cols].max(axis=1)\n",
    "consensus_df['Range_Consensus'] = consensus_df['Max_Consensus'] - consensus_df['Min_Consensus']\n",
    "consensus_df['CV_Consensus'] = consensus_df['Std_Consensus'] / (consensus_df['Mean_Consensus'] + 1e-8)\n",
    "\n",
    "print(\"ESTADÍSTICAS GENERALES DEL CONSENSO:\")\n",
    "print(f\"Probabilidad media: {consensus_df['Mean_Consensus'].mean():.4f} ± {consensus_df['Mean_Consensus'].std():.4f}\")\n",
    "print(f\"Variabilidad promedio entre ejecuciones: {consensus_df['Std_Consensus'].mean():.4f}\")\n",
    "print(f\"Coeficiente de variación promedio: {consensus_df['CV_Consensus'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, kendalltau\n",
    "\n",
    "print(f\"\\nANÁLISIS DE ESTABILIDAD:\")\n",
    "\n",
    "# Correlaciones entre ejecuciones\n",
    "correlations = []\n",
    "corr_pairs = [(0,1), (0,2), (1,2)]\n",
    "for i, j in corr_pairs:\n",
    "    r, p = pearsonr(consensus_df[f'Prob_Run{i+1}'], consensus_df[f'Prob_Run{j+1}'])\n",
    "    correlations.append(r)\n",
    "    print(f\"Correlación Run{i+1}-Run{j+1}: {r:.4f} (p={p:.2e})\")\n",
    "\n",
    "mean_correlation = np.mean(correlations)\n",
    "print(f\"Correlación promedio: {mean_correlation:.4f}\")\n",
    "\n",
    "# Concordancia de rankings (top 100 para eficiencia)\n",
    "rankings = []\n",
    "for i, ex in enumerate(executions):\n",
    "    rank = ex.sort_values('Mean_Prob', ascending=False)['Source_ID'].values\n",
    "    rankings.append(rank)\n",
    "\n",
    "top_n = min(100, n_sources)\n",
    "tau_values = []\n",
    "for i, j in corr_pairs:\n",
    "    tau, p = kendalltau(rankings[i][:top_n], rankings[j][:top_n])\n",
    "    tau_values.append(tau)\n",
    "\n",
    "mean_tau = np.mean(tau_values)\n",
    "print(f\"Concordancia de rankings (Kendall's τ): {mean_tau:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nIDENTIFICACIÓN DE CANDIDATOS ROBUSTOS:\")\n",
    "\n",
    "# Definir criterios simplificados\n",
    "STABILITY_THRESHOLD = 0.10  # Baja variabilidad entre ejecuciones\n",
    "MIN_PROB_THRESHOLD = 0.40   # Probabilidad mínima aceptable\n",
    "MEAN_PROB_THRESHOLD = 0.45  # Probabilidad media mínima\n",
    "\n",
    "# Candidatos estables (baja variabilidad)\n",
    "stable_mask = consensus_df['Std_Consensus'] <= STABILITY_THRESHOLD\n",
    "stable_candidates = consensus_df[stable_mask]\n",
    "\n",
    "# Candidatos robustos (criterios múltiples)\n",
    "robust_mask = (\n",
    "    (consensus_df['Min_Consensus'] >= MIN_PROB_THRESHOLD) &\n",
    "    (consensus_df['Mean_Consensus'] >= MEAN_PROB_THRESHOLD) &\n",
    "    (consensus_df['Std_Consensus'] <= STABILITY_THRESHOLD)\n",
    ")\n",
    "robust_candidates = consensus_df[robust_mask]\n",
    "\n",
    "# Análisis de top rankings\n",
    "top_20_sets = []\n",
    "for ex in executions:\n",
    "    top_20 = set(ex.nlargest(20, 'Mean_Prob')['Source_ID'])\n",
    "    top_20_sets.append(top_20)\n",
    "\n",
    "# Intersecciones\n",
    "intersection_all = top_20_sets[0] & top_20_sets[1] & top_20_sets[2]\n",
    "intersection_2of3 = set()\n",
    "for i in range(3):\n",
    "    for j in range(i+1, 3):\n",
    "        intersection_2of3.update(top_20_sets[i] & top_20_sets[j])\n",
    "\n",
    "print(f\"Candidatos estables (std ≤ {STABILITY_THRESHOLD}): {len(stable_candidates)}\")\n",
    "print(f\"Candidatos robustos (criterios múltiples): {len(robust_candidates)}\")\n",
    "print(f\"Candidatos en top 20 de todas las ejecuciones: {len(intersection_all)}\")\n",
    "print(f\"Candidatos en top 20 de al menos 2 ejecuciones: {len(intersection_2of3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_sorted = consensus_df.sort_values('Mean_Consensus', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTOP 10 CANDIDATOS DE CONSENSO:\")\n",
    "print(\"Source | Mean±Std | Min-Max | CV   | E_peak   | Beta\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i in range(min(10, len(consensus_sorted))):\n",
    "    row = consensus_sorted.iloc[i]\n",
    "    source_id = int(row['Source_ID'])\n",
    "    mean_p = row['Mean_Consensus']\n",
    "    std_p = row['Std_Consensus']\n",
    "    min_p = row['Min_Consensus']\n",
    "    max_p = row['Max_Consensus']\n",
    "    cv = row['CV_Consensus']\n",
    "    e_peak = row['E_peak']\n",
    "    beta = row['Beta']\n",
    "    \n",
    "    print(f\"{source_id:6d} | {mean_p:.3f}±{std_p:.3f} | {min_p:.3f}-{max_p:.3f} | {cv:.3f} | {e_peak:.2e} | {beta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nEVALUACIÓN DE CALIDAD DEL MODELO:\")\n",
    "\n",
    "# Distribución de variabilidades\n",
    "low_var_pct = (consensus_df['Std_Consensus'] < 0.05).mean() * 100\n",
    "med_var_pct = ((consensus_df['Std_Consensus'] >= 0.05) & (consensus_df['Std_Consensus'] < 0.15)).mean() * 100\n",
    "high_var_pct = (consensus_df['Std_Consensus'] >= 0.15).mean() * 100\n",
    "\n",
    "print(f\"Distribución de variabilidad:\")\n",
    "print(f\"  - Baja variabilidad (<0.05): {low_var_pct:.1f}%\")\n",
    "print(f\"  - Variabilidad media (0.05-0.15): {med_var_pct:.1f}%\") \n",
    "print(f\"  - Alta variabilidad (≥0.15): {high_var_pct:.1f}%\")\n",
    "\n",
    "# Interpretación de estabilidad\n",
    "if mean_correlation > 0.8:\n",
    "    stability_level = \"ALTA\"\n",
    "elif mean_correlation > 0.6:\n",
    "    stability_level = \"MODERADA\"\n",
    "else:\n",
    "    stability_level = \"BAJA\"\n",
    "\n",
    "print(f\"\\nESTABILIDAD DEL MODELO: {stability_level}\")\n",
    "print(f\"  - Correlación promedio: {mean_correlation:.3f}\")\n",
    "print(f\"  - Concordancia de rankings: {mean_tau:.3f}\")\n",
    "print(f\"  - Candidatos estables identificados: {len(stable_candidates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../data/results/ann/2F/consensus_analysis_ann_2f_improved.csv'\n",
    "consensus_sorted.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nResultados guardados en: {output_file}\")\n",
    "print(f\"Análisis de consenso completado exitosamente\")\n",
    "\n",
    "# Retornar métricas clave para uso posterior\n",
    "consensus_metrics = {\n",
    "    'mean_correlation': mean_correlation,\n",
    "    'mean_tau': mean_tau,\n",
    "    'n_stable_candidates': len(stable_candidates),\n",
    "    'n_robust_candidates': len(robust_candidates),\n",
    "    'n_top20_all_runs': len(intersection_all),\n",
    "    'stability_level': stability_level\n",
    "}\n",
    "\n",
    "print(f\"\\nRESUMEN EJECUTIVO:\")\n",
    "print(f\"Modelo con estabilidad {stability_level.lower()} (r={mean_correlation:.3f})\")\n",
    "print(f\"Se identificaron {len(robust_candidates)} candidatos robustos para validación con OCSVM\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
