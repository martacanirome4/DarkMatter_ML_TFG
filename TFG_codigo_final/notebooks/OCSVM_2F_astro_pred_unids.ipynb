{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de OneClassSVM entrenado con 2F de datos Astro, y predicción sobre datos Unid (no identificados)\n",
    "\n",
    "**Proyecto**: Detección de posibles fuentes de materia oscura usando ML en datos Fermi-LAT  \n",
    "**Autor**: Marta Canino Romero  \n",
    "**Fecha**: febrero-mayo 20225\n",
    "\n",
    "---\n",
    "\n",
    "## Descripción:\n",
    "\n",
    "Este notebook aplica un modelo **One-Class SVM** entrenado con datos de fuentes astrofísicas conocidas (ASTRO) usando las siguientes características:\n",
    "\n",
    "- E_peak\n",
    "- beta\n",
    "\n",
    "Este modelo se entrena para identificar anomalías que puedan corresponder a posibles fuentes de materia oscura (UNIDs) en los datos no identificados del catálogo 4FGL.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos específicos:\n",
    "\n",
    "- Entrenar modelo OCSVM con 2 features\n",
    "- Optimizar hiperparámetros (grid search sobre `nu` y `gamma`)\n",
    "- Evaluar sobre datos de validación y prueba\n",
    "- Aplicar modelo final sobre datos UNID para predicción\n",
    "- Comparar los resultados de anomalía/outliers para OCSVM 2F con los resultados de probabilidad de DM de la ANN 2F (sobre UNIDs)\n",
    "\n",
    "---\n",
    "\n",
    "## Entrada de datos:\n",
    "\n",
    "- `../data/astro_df.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "\n",
    "# data_path = \"../data/astro_df.txt\"\n",
    "data_path = \"../data/astro_data_with_labels.txt\"\n",
    "\n",
    "df_astro = pd.read_csv(data_path, sep='\\s+')\n",
    "print(f\" Nombres de las columnas: {list(df_astro.columns)}\")\n",
    "\n",
    "df_astro = df_astro.rename(columns={\"astro_DM\": \"class\"})\n",
    "\n",
    "print(f\" Dataset cargado. Forma: {df_astro.shape}\")\n",
    "print(f\" Nombres de las columnas: {list(df_astro.columns)}\")\n",
    "\n",
    "df_astro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selección de características\n",
    "features = ['Log(E_peak)', 'Log(beta)']\n",
    "\n",
    "\"\"\"Establecemos la columna objetivo aunque al ser un problema de detección de anomalías no la utilizaremos para entrenar el modelo.\n",
    "Además de que todos los datos están etiquetados como 'astro_DM' = 0.0\"\"\"\n",
    "target = 'class'\n",
    "\n",
    "\n",
    "print(f\"Features seleccionadas: {features}\")\n",
    "print(f\"Columna objetivo: {target}\")\n",
    "\n",
    "# --- Comprobamos valores nulos ---\n",
    "print(\"\\n Valores faltantes por columna:\")\n",
    "print(df_astro[features + [target]].isnull().sum())\n",
    "\n",
    "print(\"\\n Muestra del dataset:\")\n",
    "display(df_astro[features + [target]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la distribución de los datos astro antes de escalar\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_astro,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"cornflowerblue\",  # \"skyblue\", \"turquoise\", \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "\n",
    "plt.title(\"ASTRO Data: Log(E_peak) vs Log(Beta)\")\n",
    "plt.xlabel(\"Log(E_peak)\")\n",
    "plt.ylabel(\"Log(beta)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df_astro[features].values\n",
    "y = df_astro[target].values\n",
    "\n",
    "# SPLIT: Train / Val / Test\n",
    "# 60% train, 20% val, 20% test\n",
    "# de esta manera, el test set no se ve en el entrenamiento\n",
    "# y el val set se usa para ajustar los hiperparámetros)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Forma de X_train_scaled:\", X_train_scaled.shape)\n",
    "print(\"Forma de X_val_scaled:\"  , X_val_scaled.shape)\n",
    "print(\"Forma de X_test_scaled:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que los datos están bien escalados\n",
    "# plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_scaled[:, 0],\n",
    "    y=X_train_scaled[:, 1],\n",
    "    color=\"cornflowerblue\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "plt.title(\"Scaled Train Data: Log(E_peak) vs Log(Beta)\")\n",
    "plt.xlabel(\"Log(E_peak)\")\n",
    "plt.ylabel(\"Log(beta)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "PARAMETROS DE OneClassSVM:\n",
    "    - kernel: rbf (solo cambiar si conocemos la fórmula para la forma de la distribución)\n",
    "    - gamma: \n",
    "        - coeficiente del kernel \n",
    "        - usado para hiperplanos no lineares\n",
    "        - influye en la forma de la frontera de decisión + el desempeño predictivo\n",
    "        - define la influencia de un único ejemplo de entrenamiento\n",
    "        - cuanto más grande, más cerca tienen que estar los otros ejemplos para 'verse afectados'\n",
    "        - (por defecto 'scale' (antes 'auto')) \n",
    "    - nu: \n",
    "        - límite superior de la fracción de errores permitidos en entrenamiento \n",
    "        - límite inferior de la fracción de vectores de soporte en relación con nº total de datos de entrenamiento\n",
    "            -   ejemplo: si se establece en 0,05 se tiene la garantía de encontrar como máximo el 5 % de los datos de entrenamiento mal clasificados \n",
    "                y al menos el 5 % de los datos de entrenamiento siendo vectores de soporte\n",
    "        - ( (0,1] - 0.5 por defecto )\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" \n",
    "EJEMPLOS DE UNDER Y OVERFITTING:\n",
    "\n",
    "    Underfitting severo\n",
    "        gamma = 0.001  # muy bajo\n",
    "        nu = 0.7       # muy alto\n",
    "\n",
    "    Overfitting severo\n",
    "        gamma = 10.0    # muy alto\n",
    "        nu = 0.0001     # extremadamente bajo\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Hiperparámetros a explorar\"\"\"\n",
    "# gamma_values = ['scale', 'auto'] + list(np.logspace(-3, 1, 5))\n",
    "gamma_values = [0.1] # Justificación de gamma = 0.1 basada en análisis previo: balance óptimo para que \"abrace\" los datos sin ser demasiado rígido\n",
    "nu_values = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "             \n",
    "\"\"\"Tracking\"\"\"\n",
    "results = []\n",
    "best_outliers = np.inf\n",
    "best_model = None\n",
    "best_params = {}\n",
    "best_mean_score = 0.0\n",
    "\n",
    "\"\"\"Grid Search\"\"\"\n",
    "print(\"Buscando hiperparámetros que minimicen outliers en ASTRO (validación)...\")\n",
    "for nu in nu_values:\n",
    "    for gamma in gamma_values:\n",
    "\n",
    "        model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "        model.fit(X_train_scaled)\n",
    "\n",
    "        # Calcular score de decisión para análisis más detallado\n",
    "        decision_scores = model.decision_function(X_val_scaled)\n",
    "        preds_val = model.predict(X_val_scaled)\n",
    "\n",
    "        # Predicciones\n",
    "        preds_val = model.predict(X_val_scaled) # 1 = normal, -1 = outlier\n",
    "        pred_labels = np.where(preds_val == 1, 0, 1) # Mapear a 0 = normal, 1 = anomalía\n",
    "        true_labels = y_val.astype(int)\n",
    "        n_outliers = np.sum(preds_val == -1)\n",
    "        mean_score = np.mean(decision_scores)  # Distancia media al hiperplano\n",
    "\n",
    "        # f1 = f1_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "        results.append({\n",
    "            'nu': nu, \n",
    "            'gamma': gamma, \n",
    "            'val_outliers': n_outliers,\n",
    "            'mean_decision_score': mean_score\n",
    "        })\n",
    "\n",
    "        \"\"\"\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "        \"\"\"\n",
    "\n",
    "        if n_outliers < best_outliers:\n",
    "            best_outliers = n_outliers\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "            best_mean_score = mean_score\n",
    "\n",
    "# Mostrar resultado óptimo\n",
    "print(f\"\\n Mejor combinación de hiperparámetros:\")\n",
    "print(f\"   - ν = {best_params['nu']}\")\n",
    "print(f\"   - γ = {best_params['gamma']}\")\n",
    "print(f\"   - Outliers (val set): {best_outliers} de {len(X_val_scaled)} muestras\")\n",
    "print(f\"   - Mejor distancia media al hiperplano: {best_mean_score} \")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values(by='val_outliers'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Evaluar el modelo en el conjunto de validación\n",
    "val_preds = best_model.predict(X_val_scaled)\n",
    "n_val_outliers = np.sum(val_preds == -1)\n",
    "print(f\"Outliers (val set): {n_val_outliers} de {len(X_val_scaled)} muestras\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de test\n",
    "# (no se ha visto en el entrenamiento)\n",
    "test_preds = best_model.predict(X_test_scaled)\n",
    "n_test_outliers = np.sum(test_preds == -1)\n",
    "print(f\"Outliers (test set): {n_test_outliers} de {len(X_test_scaled)} muestras\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reentrenar con X_train + X_val\n",
    "X_final_train = np.vstack([X_train, X_val])\n",
    "y_final_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "scaler_final = StandardScaler()\n",
    "\n",
    "X_final_train_scaled = scaler_final.fit_transform(X_final_train)\n",
    "\n",
    "X_test_scaled = scaler_final.transform(X_test)\n",
    "\n",
    "# Entrenar modelo final\n",
    "final_model = OneClassSVM(kernel='rbf', gamma=best_params['gamma'], nu=best_params['nu'])\n",
    "final_model.fit(X_final_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Análisis de la distribución de scores\n",
    "decision_scores_test = final_model.decision_function(X_test_scaled)\n",
    "\n",
    "print(f\"Decision scores estadísticas:\")\n",
    "print(f\"  Media: {np.mean(decision_scores_test):.4f}\")\n",
    "print(f\"  Std: {np.std(decision_scores_test):.4f}\")\n",
    "print(f\"  Min: {np.min(decision_scores_test):.4f}\")\n",
    "print(f\"  Max: {np.max(decision_scores_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluar en test\n",
    "test_preds = final_model.predict(X_test_scaled)\n",
    "test_labels = np.where(test_preds == 1, 0, 1)\n",
    "\n",
    "print(\"Evaluación en el conjunto de test:\")\n",
    "print(f\"\\nOutliers (test set): {np.sum(test_preds == -1)} de {len(X_test_scaled)} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metricas\n",
    "print(\"Matriz de confusión:\")\n",
    "cm = confusion_matrix(y_test, test_labels)\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, test_labels, target_names=unique_labels(y_test, test_labels).astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar qué características tienen los \"outliers\" detectados\n",
    "outlier_indices = np.where(test_preds == -1)[0]\n",
    "if len(outlier_indices) > 0:\n",
    "    print(f\"\\nCaracterísticas de los outliers detectados:\")\n",
    "    outlier_features = X_test[outlier_indices]\n",
    "    print(f\"Log(E_peak) range: [{np.min(outlier_features[:, 0]):.3f}, {np.max(outlier_features[:, 0]):.3f}]\")\n",
    "    print(f\"Log(beta) range: [{np.min(outlier_features[:, 1]):.3f}, {np.max(outlier_features[:, 1]):.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar la malla para la frontera de decisión\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_final_train_scaled[:, 0].min() - 0.5, X_final_train_scaled[:, 0].max() + 0.5, 300),\n",
    "    np.linspace(X_final_train_scaled[:, 1].min() - 0.5, X_final_train_scaled[:, 1].max() + 0.5, 300)\n",
    ")\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = final_model.decision_function(grid)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Crear la figura\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Contornos de la función de decisión - GUARDAR LA REFERENCIA\n",
    "contour_plot = plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu_r, alpha=0.8)\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='crimson', linestyles='--')\n",
    "\n",
    "# Añadir barra de color usando la referencia\n",
    "cbar = plt.colorbar(contour_plot)\n",
    "cbar.set_label('Decision Function Value', rotation=270, labelpad=20)\n",
    "\n",
    "# Plotear datos de entrenamiento y test\n",
    "plt.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], \n",
    "           c='darkblue', edgecolors='white', s=50, alpha=0.8,\n",
    "           label='ASTRO Test Data Sources')\n",
    "plt.scatter(X_final_train_scaled[:, 0], X_final_train_scaled[:, 1], \n",
    "           c='skyblue', edgecolors='white', s=50, alpha=0.8,\n",
    "           label='ASTRO Train Data Sources')\n",
    "\n",
    "# Etiquetas y título con parámetros\n",
    "plt.xlabel(\"Log(E_peak) (scaled)\", fontsize=12)\n",
    "plt.ylabel(\"Log(beta) (scaled)\", fontsize=12)\n",
    "\n",
    "# Título dinámico con parámetros del modelo\n",
    "gamma_val = final_model.gamma if isinstance(final_model.gamma, (int, float)) else final_model.gamma\n",
    "title = f\"One-Class SVM Decision Boundary\\nγ = {gamma_val}, ν = {final_model.nu}\"\n",
    "plt.title(title, fontsize=14, fontweight='bold')\n",
    "\n",
    "# Leyenda y grid\n",
    "plt.legend(loc='upper right', framealpha=0.9)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Información adicional del modelo\n",
    "print(f\"Modelo One-Class SVM:\")\n",
    "print(f\"  - Kernel: {final_model.kernel}\")\n",
    "print(f\"  - Gamma: {final_model.gamma}\")\n",
    "print(f\"  - Nu: {final_model.nu}\")\n",
    "print(f\"  - Número de vectores soporte: {final_model.n_support_[0]}\")\n",
    "print(f\"  - Proporción de outliers en entrenamiento: {(final_model.predict(X_final_train_scaled) == -1).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cargar datos UnIDs\n",
    "\n",
    "# unids_path = \"../data/unids_log.txt\"\n",
    "unids_path = \"../data/unids_transformed_complete.txt\"\n",
    "\n",
    "# df_unids = pd.read_csv(unids_path, sep='\\s+')\n",
    "df_unids = pd.read_csv(unids_path, sep='\\t')\n",
    "\n",
    "print(\"Datos UnIDs cargados:\")\n",
    "print(f\"Shape: {df_unids.shape}\")\n",
    "print(\"Primeras filas:\")\n",
    "display(df_unids.head())\n",
    "\n",
    "# Verificar columnas disponibles\n",
    "print(f\"Columnas disponibles: {list(df_unids.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extraer y escalar \n",
    "X_unids_log = df_unids[[\"Log(E_peak)\", \"Log(beta)\"]].values\n",
    "X_unids_scaled = scaler.transform(X_unids_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar rangos con datos de entrenamiento para detectar extrapolación\n",
    "train_range_epeak = [X_train[:, 0].min(), X_train[:, 0].max()]\n",
    "train_range_beta = [X_train[:, 1].min(), X_train[:, 1].max()]\n",
    "\n",
    "unids_range_epeak = [X_unids_log[:, 0].min(), X_unids_log[:, 0].max()]\n",
    "unids_range_beta = [X_unids_log[:, 1].min(), X_unids_log[:, 1].max()]\n",
    "\n",
    "print(f\"Rangos de datos:\")\n",
    "print(f\"  Train E_peak: {train_range_epeak}\")\n",
    "print(f\"  UNIDs E_peak: {unids_range_epeak}\")\n",
    "print(f\"  Train beta: {train_range_beta}\")\n",
    "print(f\"  UNIDs beta: {unids_range_beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Crear subplots 3x2 ---\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "\n",
    "# --- Plot 1: UNIDs sin escalar ---\n",
    "sns.scatterplot(\n",
    "    data=df_unids,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[0, 0]\n",
    ")\n",
    "axes[0, 0].set_title(\"UNIDs Data (sin escalar): Log(E_peak) vs Log(β)\")\n",
    "axes[0, 0].set_xlabel(\"Log(E_peak)\")\n",
    "axes[0, 0].set_ylabel(\"Log(beta)\")\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# --- Plot 2: UNIDs escalados ---\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[0, 1]\n",
    ")\n",
    "axes[0, 1].set_title(\"UNIDs Escalados: Log(E_peak) vs Log(β)\")\n",
    "axes[0, 1].set_xlabel(\"Log(E_peak) (escalado)\")\n",
    "axes[0, 1].set_ylabel(\"Log(beta) (escalado)\")\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# --- Plot 3: Astro sin escalar ---\n",
    "sns.scatterplot(\n",
    "    data=df_astro,  # asegúrate de tener este DataFrame cargado\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"skyblue\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[1, 0]\n",
    ")\n",
    "axes[1, 0].set_title(\"Astro Data (sin escalar): Log(E_peak) vs Log(β)\")\n",
    "axes[1, 0].set_xlabel(\"Log(E_peak)\")\n",
    "axes[1, 0].set_ylabel(\"Log(beta)\")\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# --- Plot 4: Astro escalado ---\n",
    "sns.scatterplot(\n",
    "    x=X_final_train_scaled[:, 0],\n",
    "    y=X_final_train_scaled[:, 1],\n",
    "    color=\"skyblue\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[1, 1]\n",
    ")\n",
    "axes[1, 1].set_title(\"Astro Escalado: Log(E_peak) vs Log(β)\")\n",
    "axes[1, 1].set_xlabel(\"Log(E_peak) (escalado)\")\n",
    "axes[1, 1].set_ylabel(\"Log(beta) (escalado)\")\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "# --- Plot 5: Comparación UNIDs vs Astro escalados ---\n",
    "sns.scatterplot(\n",
    "    x=X_final_train_scaled[:, 0],\n",
    "    y=X_final_train_scaled[:, 1],\n",
    "    color=\"skyblue\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    label='Astro',\n",
    "    ax=axes[2, 0]\n",
    ")\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    label='UNIDs',\n",
    "    ax=axes[2, 0]\n",
    ")\n",
    "axes[2, 0].set_title(\"UNIDs vs Astro Escalados: Log(E_peak) vs Log(β)\")\n",
    "axes[2, 0].set_xlabel(\"Log(E_peak) (escalado)\")\n",
    "axes[2, 0].set_ylabel(\"Log(beta) (escalado)\")\n",
    "axes[2, 0].legend()\n",
    "axes[2, 0].grid(True)\n",
    "\n",
    "# --- Eliminar celda vacía (3,2) ---\n",
    "fig.delaxes(axes[2, 1])\n",
    "\n",
    "# --- Layout final ---\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir sobre UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Predecir sobre UNIDs usando el mejor modelo \"\"\"\n",
    "\"\"\" IMPORTANTE: ESTOS PARÁMETROS SE USAN EN LOS PLOTS --- NO TOCAR \"\"\"\n",
    "\n",
    "decision_scores = final_model.decision_function(X_unids_scaled)\n",
    "\n",
    "# Top 5 most anomalous\n",
    "\"\"\"top_anomalies = X_unids_scaled[np.argsort(decision_scores)[:5]]\"\"\"\n",
    "preds_unids = final_model.predict(X_unids_scaled)\n",
    "\n",
    "n_outliers = np.sum(preds_unids == -1)\n",
    "n_inliers = np.sum(preds_unids == 1)\n",
    "total_unids = len(preds_unids)\n",
    "\n",
    "# Para gráficas\n",
    "outlier_percentage = n_outliers / total_unids * 100\n",
    "inlier_percentage = n_inliers / total_unids * 100\n",
    "\n",
    "inliers = X_unids_scaled[preds_unids == 1]    # Para scatter gold\n",
    "outliers = X_unids_scaled[preds_unids == -1]  # Para scatter red\n",
    "top_anomalies = X_unids_scaled[np.argsort(decision_scores)[:5]]  # Para stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"RESULTADOS DE PREDICCIÓN:\")\n",
    "print(f\"  - Total UNIDs: {total_unids}\")\n",
    "print(f\"  - Outliers: {n_outliers} ({n_outliers/total_unids*100:.1f}%)\")\n",
    "print(f\"  - Inliers: {n_inliers} ({n_inliers/total_unids*100:.1f}%)\")\n",
    "\n",
    "print(f\"Outliers detectados con sus IDs:\")\n",
    "\n",
    "outlier_ids = df_unids[preds_unids == -1].index.tolist()\n",
    "print(outlier_ids)\n",
    "\n",
    "# Calcular anomaly scores y rankings\n",
    "# Invertir scores: valores más altos = más anómalos\n",
    "anom_scores = -decision_scores\n",
    "\n",
    "# Escalar a percentiles [0, 100]\n",
    "anom_percent = MinMaxScaler(feature_range=(0, 100)).fit_transform(\n",
    "    anom_scores.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "# Agregar resultados al DataFrame\n",
    "df_unids_results = df_unids.copy()\n",
    "df_unids_results[\"svm_score\"] = decision_scores\n",
    "df_unids_results[\"prediction\"] = preds_unids\n",
    "df_unids_results[\"Anomaly_Score\"] = anom_scores\n",
    "df_unids_results[\"Anomaly_Rank(%)\"] = anom_percent\n",
    "\n",
    "print(\"Scores calculados y agregados al DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top candidatos\n",
    "outliers_only = df_unids_results[df_unids_results[\"prediction\"] == -1].copy()\n",
    "top_10_outliers = outliers_only.sort_values(\"Anomaly_Rank(%)\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outliers_only = outliers_only.sort_values(\"Anomaly_Rank(%)\", ascending=False)\n",
    "display(outliers_only.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos los valores mínimos y máximos de astro_df\n",
    "\"\"\"\n",
    "print(\"\\nValores mínimos y máximos de las características en astro_df:\")\n",
    "for feature in features:\n",
    "    min_val = df_astro[feature].min()\n",
    "    max_val = df_astro[feature].max()\n",
    "    print(f\"{feature}: [{min_val:.4f}, {max_val:.4f}]\")\n",
    "    \"\"\"\n",
    "# Comprobamos los valores mínimos y máximos de unids\n",
    "print(\"\\nValores mínimos y máximos de las características en unids:\")\n",
    "for feature in df_unids.columns:\n",
    "    min_val = df_unids[feature].min()\n",
    "    max_val = df_unids[feature].max()\n",
    "    print(f\"{feature}: [{min_val:.4f}, {max_val:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unids_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Obtener frontera de decisión del entrenamiento del modelo \"\"\"\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_train_scaled[:, 0].min() - 0.5, X_train_scaled[:, 0].max() + 0.5, 300),  # E_peak\n",
    "    np.linspace(X_train_scaled[:, 1].min() - 0.5, X_train_scaled[:, 1].max() + 0.5, 300)   # beta\n",
    ")\n",
    "\"\"\"  Establecer frontera \"\"\"\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = final_model.decision_function(grid)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "\"\"\" Definir plot \"\"\"\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu_r, alpha=0.8)\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='crimson', linestyles='--')\n",
    "\n",
    "\"\"\"\" Plot scatter data \"\"\"\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], \n",
    "           c='gold', edgecolors='black', s=50, alpha=0.7,\n",
    "           label=f'UNID Inliers ({len(inliers)})')\n",
    "           \n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], \n",
    "           c='red', edgecolors='black', s=60, alpha=0.9,\n",
    "           label=f'UNID Outliers ({len(outliers)})')\n",
    "           \n",
    "plt.scatter(top_anomalies[:, 0], top_anomalies[:, 1], \n",
    "           c='darkred', edgecolors='white', s=100, \n",
    "           label='Top Anomalies', marker='*', linewidth=1)\n",
    "\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(f\"OneClassSVM Predictions on {total_unids} UNIDs\\n\"\n",
    "          f\"Outliers: {n_outliers} ({outlier_percentage:.1f}%) | \"\n",
    "          f\"γ={best_params['gamma']}, ν={best_params['nu']}\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (likely astro)', alpha=0.6)\n",
    "plt.scatter(outliers[:, 0], outliers[:,1], c='red', edgecolors='k', label='Outlier (potentially new)', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Log(E_peak) (scaled)\")\n",
    "plt.ylabel(\"Log(beta) (scaled)\")\n",
    "plt.title(\"UNIDs: Inlier vs Outlier (One-Class SVM)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Scoring - UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Predecir sobre UNIDs usando el mejor modelo \"\"\"\n",
    "\"\"\" IMPORTANTE: ESTOS PARÁMETROS SE USAN EN LOS PLOTS --- NO TOCAR \"\"\"\n",
    "\n",
    "decision_scores = final_model.decision_function(X_unids_scaled)\n",
    "# Top 5 most anomalous\n",
    "top_anomalies = X_unids_scaled[np.argsort(decision_scores)[:5]]\n",
    "preds_unids = final_model.predict(X_unids_scaled)\n",
    "total_unids = len(preds_unids)\n",
    "\n",
    "# Contar resultados\n",
    "inliers = X_unids_scaled[preds_unids == 1]\n",
    "outliers = X_unids_scaled[preds_unids == -1]\n",
    "\n",
    "n_outliers = np.sum(preds_unids == -1)\n",
    "n_inliers = np.sum(preds_unids == 1)\n",
    "\n",
    "outlier_percentage = n_outliers / total_unids * 100\n",
    "inlier_percentage = n_inliers / total_unids * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrar solo outliers y ordenar por anomaly rank\n",
    "outliers_only = df_unids_results[df_unids_results[\"prediction\"] == -1].copy()\n",
    "outliers_sorted = outliers_only.sort_values(by=\"Anomaly_Rank(%)\", ascending=False)\n",
    "\n",
    "# Top 10 outliers más anómalos\n",
    "top_10_outliers = outliers_sorted.head(10)\n",
    "\n",
    "print(f\"\\nTOP 10 CANDIDATOS MÁS ANÓMALOS:\")\n",
    "\n",
    "# Mostrar información relevante\n",
    "display_cols = ['Log(E_peak)', 'Log(beta)', 'Log(sigma)', 'Log(beta_Rel)', \n",
    "                'svm_score', 'Anomaly_Score', 'Anomaly_Rank(%)']\n",
    "\n",
    "if 'number' in df_unids_results.columns:\n",
    "    display_cols = ['number'] + display_cols\n",
    "\n",
    "display(top_10_outliers[display_cols].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de la gráfica\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Separar inliers y outliers\n",
    "inliers_mask = preds_unids == 1\n",
    "outliers_mask = preds_unids == -1\n",
    "\n",
    "# Plot inliers (usando las dos primeras features: Log(E_peak) vs Log(beta))\n",
    "plt.scatter(X_unids_scaled[inliers_mask, 0], X_unids_scaled[inliers_mask, 1], \n",
    "           c='lightblue', s=25, alpha=0.6, edgecolors='blue', linewidth=0.3,\n",
    "           label=f'Inliers (astro-like): {np.sum(inliers_mask)}')\n",
    "\n",
    "# Plot outliers con gradient de color según anomaly rank\n",
    "if np.any(outliers_mask):\n",
    "    scatter = plt.scatter(X_unids_scaled[outliers_mask, 0], X_unids_scaled[outliers_mask, 1], \n",
    "                         c=anom_percent[outliers_mask], cmap='Reds', s=80,\n",
    "                         alpha=0.9, edgecolors='black', linewidth=0.8,\n",
    "                         label=f'Outliers (anomalous): {np.sum(outliers_mask)}')\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(scatter, label='Anomaly Rank %')\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "# Etiquetar TODOS los outliers con sus IDs\n",
    "if np.any(outliers_mask):\n",
    "    outlier_indices = np.where(outliers_mask)[0]\n",
    "    \n",
    "    for idx in outlier_indices:\n",
    "        x = X_unids_scaled[idx, 0]  # Log(E_peak)\n",
    "        y = X_unids_scaled[idx, 1]  # Log(beta)\n",
    "        \n",
    "        # Obtener el ID del UNID\n",
    "        if 'number' in df_unids_results.columns:\n",
    "            unid_id = int(df_unids_results.loc[idx, 'number'])\n",
    "        else:\n",
    "            unid_id = idx\n",
    "        \n",
    "        # Calcular offset para evitar solapamientos\n",
    "        offset_x = (X_unids_scaled[:, 0].max() - X_unids_scaled[:, 0].min()) * 0.015\n",
    "        offset_y = (X_unids_scaled[:, 1].max() - X_unids_scaled[:, 1].min()) * 0.015\n",
    "        \n",
    "        # Etiqueta con caja para mejor legibilidad\n",
    "        plt.text(x + offset_x, y + offset_y, str(unid_id), \n",
    "                fontsize=8, color='black', fontweight='bold',\n",
    "                ha='left', va='bottom',\n",
    "                bbox=dict(boxstyle='round,pad=0.2', facecolor='white', \n",
    "                         alpha=0.8, edgecolor='gray', linewidth=0.5))\n",
    "\n",
    "# Destacar top 10 anomalías con círculos amarillos\n",
    "if 'top_10_outliers' in locals() and len(top_10_outliers) > 0:\n",
    "    top_10_indices = top_10_outliers.index\n",
    "    plt.scatter(X_unids_scaled[top_10_indices, 0], X_unids_scaled[top_10_indices, 1],\n",
    "               s=150, facecolors='none', edgecolors='yellow', linewidth=3,\n",
    "               label=f'Top Anomalies', marker='o')\n",
    "\n",
    "# Configuración de la gráfica\n",
    "plt.xlabel('Log(E_peak)', fontsize=12)\n",
    "plt.ylabel('Log(beta)', fontsize=12)\n",
    "plt.title(f'UNIDs: Detección de Outliers ({np.sum(outliers_mask)} detectados)\\n'\n",
    "          f'Log(E_peak) vs Log(beta) - Gradient por Anomaly Rank',\n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Ajustar límites para mejor visualización de etiquetas\n",
    "x_margin = (X_unids_scaled[:, 0].max() - X_unids_scaled[:, 0].min()) * 0.1\n",
    "y_margin = (X_unids_scaled[:, 1].max() - X_unids_scaled[:, 1].min()) * 0.1\n",
    "plt.xlim(X_unids_scaled[:, 0].min() - x_margin, X_unids_scaled[:, 0].max() + x_margin)\n",
    "plt.ylim(X_unids_scaled[:, 1].min() - y_margin, X_unids_scaled[:, 1].max() + y_margin)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Análisis Estadístico del Modelo OCSVM en UNIDs', fontsize=16, fontweight='bold', y=0.98)\n",
    "\n",
    "# 1. Distribución de Decision Scores CON ESTADÍSTICAS\n",
    "ax1 = axes[0, 0]\n",
    "n, bins, patches = ax1.hist(decision_scores, bins=50, alpha=0.7, color='skyblue', \n",
    "                           edgecolor='black', density=True)\n",
    "\n",
    "# Añadir curva de densidad suavizada\n",
    "x_smooth = np.linspace(decision_scores.min(), decision_scores.max(), 100)\n",
    "density = stats.gaussian_kde(decision_scores)\n",
    "ax1.plot(x_smooth, density(x_smooth), 'navy', linewidth=2, label='Densidad estimada')\n",
    "\n",
    "# Líneas de referencia\n",
    "ax1.axvline(0, color='red', linestyle='--', linewidth=2, label='Frontera (score=0)')\n",
    "ax1.axvline(decision_scores.mean(), color='green', linestyle='--', linewidth=2,\n",
    "           label=f'Media: {decision_scores.mean():.3f}')\n",
    "ax1.axvline(np.median(decision_scores), color='orange', linestyle='--', linewidth=2,\n",
    "           label=f'Mediana: {np.median(decision_scores):.3f}')\n",
    "\n",
    "# Estadísticas adicionales\n",
    "std_dev = decision_scores.std()\n",
    "ax1.fill_betweenx([0, ax1.get_ylim()[1]], decision_scores.mean()-std_dev, \n",
    "                  decision_scores.mean()+std_dev, alpha=0.2, color='green', \n",
    "                  label=f'±1σ: {std_dev:.3f}')\n",
    "\n",
    "ax1.set_xlabel('SVM Decision Score')\n",
    "ax1.set_ylabel('Densidad de Probabilidad')\n",
    "ax1.set_title('Distribución de Decision Scores\\n(Análisis de Normalidad)')\n",
    "ax1.legend(fontsize=9)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Texto con estadísticas\n",
    "stats_text = f'n = {len(decision_scores)}\\nSkewness: {stats.skew(decision_scores):.3f}\\nKurtosis: {stats.kurtosis(decision_scores):.3f}'\n",
    "ax1.text(0.02, 0.98, stats_text, transform=ax1.transAxes, fontsize=9, \n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 2. Distribución de Anomaly Ranks CON PERCENTILES\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(anom_percent, bins=50, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Percentiles importantes\n",
    "percentiles = [50, 75, 90, 95, 99]\n",
    "colors = ['blue', 'orange', 'red', 'darkred', 'purple']\n",
    "for p, color in zip(percentiles, colors):\n",
    "    value = np.percentile(anom_percent, p)\n",
    "    ax2.axvline(value, color=color, linestyle='--', linewidth=2, \n",
    "               label=f'P{p}: {value:.1f}%')\n",
    "\n",
    "ax2.set_xlabel('Anomaly Rank (%)')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "ax2.set_title('Distribución de Anomaly Rankings\\n(Análisis de Percentiles)')\n",
    "ax2.legend(fontsize=9, loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Comparación Inliers vs Outliers\n",
    "ax3 = axes[1, 0]\n",
    "outliers_scores = anom_percent[preds_unids == -1]\n",
    "inliers_scores = anom_percent[preds_unids == 1]\n",
    "\n",
    "# Histograma\n",
    "bins = np.linspace(0, 100, 31)\n",
    "ax3.hist([inliers_scores, outliers_scores], bins=bins, alpha=0.7,\n",
    "         color=['lightblue', 'red'], label=[f'Inliers (n={len(inliers_scores)})', \n",
    "                                           f'Outliers (n={len(outliers_scores)})'],\n",
    "         edgecolor='black')\n",
    "\n",
    "# Añadir líneas de medias\n",
    "ax3.axvline(inliers_scores.mean(), color='blue', linestyle='-', linewidth=2,\n",
    "           label=f'Media Inliers: {inliers_scores.mean():.1f}%')\n",
    "ax3.axvline(outliers_scores.mean(), color='darkred', linestyle='-', linewidth=2,\n",
    "           label=f'Media Outliers: {outliers_scores.mean():.1f}%')\n",
    "\n",
    "ax3.set_xlabel('Anomaly Rank (%)')\n",
    "ax3.set_ylabel('Frecuencia')\n",
    "ax3.set_title('Separación Inliers vs Outliers\\n(Validación del Modelo)')\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Test estadístico\n",
    "stat, p_value = stats.mannwhitneyu(outliers_scores, inliers_scores, alternative='greater')\n",
    "test_text = f'Mann-Whitney U test:\\np-value: {p_value:.2e}'\n",
    "ax3.text(0.02, 0.98, test_text, transform=ax3.transAxes, fontsize=9,\n",
    "         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 4. Scatter con regiones de interés\n",
    "ax4 = axes[1, 1]\n",
    "colors = ['red' if pred == -1 else 'blue' for pred in preds_unids]\n",
    "sizes = [40 if pred == -1 else 20 for pred in preds_unids]\n",
    "\n",
    "scatter = ax4.scatter(decision_scores, anom_percent, c=colors, alpha=0.6, s=sizes,\n",
    "                     edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Regiones de interés\n",
    "ax4.axvline(0, color='black', linestyle='--', alpha=0.7, linewidth=2, label='Frontera decisión')\n",
    "ax4.axhline(90, color='red', linestyle='--', alpha=0.7, label='Top 10% anomalías')\n",
    "ax4.axhline(95, color='darkred', linestyle='--', alpha=0.7, label='Top 5% anomalías')\n",
    "\n",
    "# Destacar zona de interés (outliers extremos)\n",
    "extreme_mask = (preds_unids == -1) & (anom_percent > 95)\n",
    "if np.any(extreme_mask):\n",
    "    ax4.scatter(decision_scores[extreme_mask], anom_percent[extreme_mask], \n",
    "               s=100, facecolors='none', edgecolors='yellow', linewidth=3,\n",
    "               label=f'Outliers extremos (n={np.sum(extreme_mask)})')\n",
    "\n",
    "# Correlación\n",
    "correlation = np.corrcoef(decision_scores, anom_percent)[0, 1]\n",
    "ax4.text(0.02, 0.98, f'Correlación: {correlation:.3f}', transform=ax4.transAxes, \n",
    "         fontsize=11, verticalalignment='top', fontweight='bold',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.8))\n",
    "\n",
    "ax4.set_xlabel('SVM Decision Score')\n",
    "ax4.set_ylabel('Anomaly Rank (%)')\n",
    "ax4.set_title('Relación Decision Score vs Anomaly Rank\\n(Coherencia del Modelo)')\n",
    "ax4.legend(fontsize=9, loc='lower right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model for API extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trained model to disk\n",
    "import joblib\n",
    "model_path = \"../models/model_ocsvm_2f.pkl\"\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"Modelo One-Class SVM guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCSVM 2F vs ANN 2F - Comparar los resultados (sobre UNIDs) con los de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS COMPARATIVO: ANN 2F vs OCSVM 2F\n",
    "\n",
    "print(\"ANÁLISIS COMPARATIVO: ANN 2F vs OCSVM 2F\\n\")\n",
    "\n",
    "# Cargar resultados de consenso ANN 2F\n",
    "ann_consensus_path = \"../data/results/ann/2F/consensus_analysis_ann_2f_improved.csv\"\n",
    "df_ann_consensus = pd.read_csv(ann_consensus_path)\n",
    "\n",
    "print(f\"Datos ANN 2F cargados:\")\n",
    "print(f\"  - Shape: {df_ann_consensus.shape}\")\n",
    "print(f\"  - Columnas principales: Source_ID, Mean_Consensus, Std_Consensus\\n\")\n",
    "\n",
    "df_ann_consensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener candidatos OCSVM 2F (outliers detectados)\n",
    "ocsvm_outliers = set()\n",
    "if np.any(preds_unids == -1):\n",
    "    outlier_indices = np.where(preds_unids == -1)[0]\n",
    "    for idx in outlier_indices:\n",
    "        if 'number' in df_unids_results.columns:\n",
    "            unid_id = int(df_unids_results.loc[idx, 'number'])\n",
    "            ocsvm_outliers.add(unid_id)\n",
    "\n",
    "# Top 10 OCSVM por anomaly rank\n",
    "ocsvm_top10 = set()\n",
    "if len(df_unids_results) > 0:\n",
    "    top_10_ocsvm = df_unids_results.nlargest(10, 'Anomaly_Rank(%)')\n",
    "    for idx, row in top_10_ocsvm.iterrows():\n",
    "        if 'number' in row:\n",
    "            ocsvm_top10.add(int(row['number']))\n",
    "\n",
    "print(f\"Candidatos OCSVM 2F:\")\n",
    "print(f\"  - Outliers detectados: {len(ocsvm_outliers)} → {sorted(ocsvm_outliers)}\")\n",
    "print(f\"  - Top 10 anomalías: {len(ocsvm_top10)} → {sorted(ocsvm_top10)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener candidatos ANN 2F\n",
    "ann_top4 = set(df_ann_consensus.head(4)['Source_ID'].astype(int))\n",
    "ann_top10 = set(df_ann_consensus.head(10)['Source_ID'].astype(int))\n",
    "\n",
    "# Candidatos ANN por threshold de consenso\n",
    "consensus_threshold = 0.5\n",
    "high_consensus_mask = df_ann_consensus['Mean_Consensus'] >= consensus_threshold\n",
    "ann_high_consensus = set()\n",
    "if high_consensus_mask.any():\n",
    "    ann_high_consensus = set(df_ann_consensus[high_consensus_mask]['Source_ID'].astype(int))\n",
    "\n",
    "print(f\"Candidatos ANN 2F:\")\n",
    "print(f\"  - Top 4: {sorted(ann_top4)}\")\n",
    "print(f\"  - Top 10: {sorted(ann_top10)}\")\n",
    "print(f\"  - Alto consenso (≥{consensus_threshold}): {len(ann_high_consensus)} → {sorted(ann_high_consensus)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERIFICACIÓN DE CONSISTENCIA DE DATOS\n",
    "print(\"VERIFICACIÓN DE CONSISTENCIA DE DATOS\\n\")\n",
    "\n",
    "# Obtener algunos candidatos para verificar\n",
    "verification_candidates = list(ocsvm_outliers.union(ann_top4))[:5]  # Primeros 5 para verificar\n",
    "\n",
    "print(\"Verificando que Source_ID (ANN) = number (OCSVM) corresponden a las mismas fuentes:\\n\")\n",
    "\n",
    "consistent_data = True\n",
    "for candidate in verification_candidates:\n",
    "    # Buscar en datos ANN\n",
    "    ann_row = df_ann_consensus[df_ann_consensus['Source_ID'] == candidate]\n",
    "    # Buscar en datos OCSVM\n",
    "    ocsvm_row = df_unids_results[df_unids_results['number'] == candidate]\n",
    "    \n",
    "    if len(ann_row) > 0 and len(ocsvm_row) > 0:\n",
    "        # Extraer valores de features\n",
    "        ann_epeak = ann_row['log_E_peak'].iloc[0] if 'log_E_peak' in ann_row.columns else None\n",
    "        ann_beta = ann_row['log_Beta'].iloc[0] if 'log_Beta' in ann_row.columns else None\n",
    "        \n",
    "        ocsvm_epeak = ocsvm_row['Log(E_peak)'].iloc[0] if 'Log(E_peak)' in ocsvm_row.columns else None\n",
    "        ocsvm_beta = ocsvm_row['Log(beta)'].iloc[0] if 'Log(beta)' in ocsvm_row.columns else None\n",
    "        \n",
    "        if ann_epeak is not None and ocsvm_epeak is not None:\n",
    "            epeak_diff = abs(ann_epeak - ocsvm_epeak)\n",
    "            beta_diff = abs(ann_beta - ocsvm_beta)\n",
    "            \n",
    "            # Tolerancia para diferencias de precisión numérica\n",
    "            tolerance = 1e-6\n",
    "            epeak_match = epeak_diff < tolerance\n",
    "            beta_match = beta_diff < tolerance\n",
    "            \n",
    "            print(f\"UNID {candidate}:\")\n",
    "            print(f\"  Log(E_peak): ANN={ann_epeak:.6f}, OCSVM={ocsvm_epeak:.6f}, diff={epeak_diff:.2e} {'✓' if epeak_match else '✗'}\")\n",
    "            print(f\"  Log(beta):   ANN={ann_beta:.6f}, OCSVM={ocsvm_beta:.6f}, diff={beta_diff:.2e} {'✓' if beta_match else '✗'}\")\n",
    "            \n",
    "            if not (epeak_match and beta_match):\n",
    "                consistent_data = False\n",
    "                print(f\"  ⚠ INCONSISTENCIA detectada en UNID {candidate}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(f\"UNID {candidate}: No encontrado en uno de los datasets\")\n",
    "        if len(ann_row) == 0:\n",
    "            print(f\"  - Falta en datos ANN\")\n",
    "        if len(ocsvm_row) == 0:\n",
    "            print(f\"  - Falta en datos OCSVM\")\n",
    "        print()\n",
    "\n",
    "if consistent_data:\n",
    "    print(\"✓ VERIFICACIÓN EXITOSA: Los datos son consistentes entre ANN y OCSVM\")\n",
    "else:\n",
    "    print(\"✗ ADVERTENCIA: Se detectaron inconsistencias en los datos\")\n",
    "    print(\"  Revisar preprocesado y fuentes de datos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS DE INTERSECCIONES\n",
    "print(\"ANÁLISIS DE CONSENSO ENTRE ALGORITMOS\\n\")\n",
    "\n",
    "# Outliers OCSVM vs Top ANN\n",
    "intersection_outliers_ann4 = ocsvm_outliers.intersection(ann_top4)\n",
    "intersection_outliers_ann10 = ocsvm_outliers.intersection(ann_top10)\n",
    "intersection_outliers_consensus = ocsvm_outliers.intersection(ann_high_consensus)\n",
    "\n",
    "print(f\"Outliers OCSVM (4) vs ANN:\")\n",
    "print(f\"  - vs Top 4 ANN: {len(intersection_outliers_ann4)} común(es) → {sorted(intersection_outliers_ann4)}\")\n",
    "print(f\"  - vs Top 10 ANN: {len(intersection_outliers_ann10)} común(es) → {sorted(intersection_outliers_ann10)}\")\n",
    "print(f\"  - vs Alto consenso ANN: {len(intersection_outliers_consensus)} común(es) → {sorted(intersection_outliers_consensus)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 OCSVM vs Top 10 ANN\n",
    "intersection_top10 = ocsvm_top10.intersection(ann_top10)\n",
    "\n",
    "print(f\"Top 10 vs Top 10:\")\n",
    "print(f\"  - Candidatos comunes: {len(intersection_top10)} → {sorted(intersection_top10)}\")\n",
    "print(f\"  - Overlap rate: {len(intersection_top10)/10*100:.1f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CARACTERIZACIÓN DE CANDIDATOS COMUNES\n",
    "print(\"CARACTERIZACIÓN DE CANDIDATOS COMUNES\\n\")\n",
    "\n",
    "all_common_candidates = intersection_outliers_ann10.union(intersection_top10)\n",
    "\n",
    "if len(all_common_candidates) > 0:\n",
    "    print(f\"Candidatos con consenso entre algoritmos: {sorted(all_common_candidates)}\\n\")\n",
    "    \n",
    "    for candidate in sorted(all_common_candidates):\n",
    "        # Info OCSVM\n",
    "        ocsvm_info = df_unids_results[df_unids_results['number'] == candidate]\n",
    "        if len(ocsvm_info) > 0:\n",
    "            ocsvm_rank = ocsvm_info['Anomaly_Rank(%)'].iloc[0]\n",
    "            ocsvm_score = ocsvm_info['svm_score'].iloc[0]\n",
    "            is_outlier = ocsvm_info['prediction'].iloc[0] == -1\n",
    "        else:\n",
    "            ocsvm_rank, ocsvm_score, is_outlier = 0, 0, False\n",
    "            \n",
    "        # Info ANN\n",
    "        ann_info = df_ann_consensus[df_ann_consensus['Source_ID'] == candidate]\n",
    "        if len(ann_info) > 0:\n",
    "            ann_rank = ann_info.index[0] + 1\n",
    "            ann_consensus = ann_info['Mean_Consensus'].iloc[0]\n",
    "            ann_std = ann_info['Std_Consensus'].iloc[0]\n",
    "        else:\n",
    "            ann_rank, ann_consensus, ann_std = 999, 0, 0\n",
    "            \n",
    "        print(f\"UNID {candidate}:\")\n",
    "        print(f\"  OCSVM: Rank {ocsvm_rank:5.1f}% | Score {ocsvm_score:8.4f} | Outlier: {'Sí' if is_outlier else 'No'}\")\n",
    "        print(f\"  ANN:   Pos #{ann_rank:2d}     | Consenso {ann_consensus:5.3f}±{ann_std:.3f}\\n\")\n",
    "else:\n",
    "    print(\"NO HAY CANDIDATOS COMUNES entre outliers OCSVM y top ANN\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS DE DIVERGENCIAS\n",
    "print(\"ANÁLISIS DE DIVERGENCIAS\\n\")\n",
    "\n",
    "ocsvm_only = ocsvm_outliers - ann_top10\n",
    "ann_only = ann_top10 - ocsvm_top10\n",
    "\n",
    "print(f\"Candidatos únicos por método:\")\n",
    "print(f\"  - Solo OCSVM outliers: {len(ocsvm_only)} → {sorted(ocsvm_only)}\")\n",
    "print(f\"  - Solo ANN top 10: {len(ann_only)} → {sorted(ann_only)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSICIONES CRUZADAS\n",
    "print(\"POSICIONES CRUZADAS DE CANDIDATOS\\n\")\n",
    "\n",
    "print(f\"Posición de outliers OCSVM en ranking ANN:\")\n",
    "for candidate in sorted(ocsvm_outliers):\n",
    "    ann_info = df_ann_consensus[df_ann_consensus['Source_ID'] == candidate]\n",
    "    if len(ann_info) > 0:\n",
    "        ann_rank = ann_info.index[0] + 1\n",
    "        ann_consensus = ann_info['Mean_Consensus'].iloc[0]\n",
    "        print(f\"  UNID {candidate}: Posición #{ann_rank:3d} en ANN (consenso: {ann_consensus:.3f})\")\n",
    "    else:\n",
    "        print(f\"  UNID {candidate}: No encontrado en resultados ANN\")\n",
    "\n",
    "print(f\"\\nPosición de top 4 ANN en ranking OCSVM:\")\n",
    "for candidate in sorted(ann_top4):\n",
    "    ocsvm_info = df_unids_results[df_unids_results['number'] == candidate]\n",
    "    if len(ocsvm_info) > 0:\n",
    "        ocsvm_rank = ocsvm_info['Anomaly_Rank(%)'].iloc[0]\n",
    "        is_outlier = ocsvm_info['prediction'].iloc[0] == -1\n",
    "        print(f\"  UNID {candidate}: Anomaly Rank {ocsvm_rank:5.1f}% ({'Outlier' if is_outlier else 'Inlier'})\")\n",
    "    else:\n",
    "        print(f\"  UNID {candidate}: No encontrado en resultados OCSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUMEN COMPARATIVO\n",
    "print(f\"\\nRESUMEN COMPARATIVO\\n\")\n",
    "\n",
    "total_candidates_combined = len(ocsvm_top10.union(ann_top10))\n",
    "overlap_rate = len(intersection_top10) / 10 * 100\n",
    "\n",
    "print(f\"Métricas de consenso:\")\n",
    "print(f\"  - Candidatos únicos combinados: {total_candidates_combined}\")\n",
    "print(f\"  - Overlap Top 10 vs Top 10: {len(intersection_top10)}/10 ({overlap_rate:.1f}%)\")\n",
    "print(f\"  - Complementariedad: {100-overlap_rate:.1f}%\\n\")\n",
    "\n",
    "print(f\"Niveles de consenso:\")\n",
    "if len(intersection_outliers_ann4) > 0:\n",
    "    print(f\"  Consenso alto: {len(intersection_outliers_ann4)} candidato(s) detectado(s) por ambos métodos\")\n",
    "else:\n",
    "    print(f\"  Consenso bajo: Sin overlap entre outliers OCSVM y top 4 ANN\")\n",
    "\n",
    "print(f\"\\nInterpretación:\")\n",
    "if overlap_rate >= 30:\n",
    "    print(f\"  Convergencia significativa entre algoritmos\")\n",
    "elif overlap_rate >= 10:\n",
    "    print(f\"  Convergencia moderada - métodos complementarios\")\n",
    "else:\n",
    "    print(f\"  Divergencia alta - algoritmos capturan anomalías diferentes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERSIÓN 2 - ANTERIOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar resultados del consenso ANN 2F\n",
    "ann_consensus = pd.read_csv('../data/results/ann/2F/consensus_analysis_ann_2f.csv')\n",
    "print(f\"Resultados ANN 2F cargados: {len(ann_consensus)} fuentes\")\n",
    "\n",
    "# Usar los resultados OCSVM con predicciones (NO df_unids original)\n",
    "ocsvm_results = df_unids_results.copy()  # Ya tiene las predicciones y scores\n",
    "print(f\"Resultados OCSVM 2F cargados: {len(ocsvm_results)} fuentes\")\n",
    "\n",
    "# Verificar mismo número de fuentes\n",
    "if len(ann_consensus) != len(ocsvm_results):\n",
    "    print(f\" ADVERTENCIA: Diferentes números de fuentes - ANN: {len(ann_consensus)}, OCSVM: {len(ocsvm_results)}\")\n",
    "else:\n",
    "    print(f\"Mismo número de fuentes: {len(ann_consensus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Resultados (top unids) consenso ANN 2F:\")\n",
    "ann_consensus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Resultados (todos) OCSVM 2F:')\n",
    "ocsvm_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar alineamiento de IDs\n",
    "ann_ids = ann_consensus['Source_ID'].values\n",
    "ocsvm_ids = ocsvm_results['number'].values if 'number' in ocsvm_results.columns else ocsvm_results.index.values\n",
    "\n",
    "ids_aligned = np.array_equal(ann_ids, ocsvm_ids)\n",
    "\n",
    "if ids_aligned:\n",
    "    print(\"Los IDs están alineados correctamente\")\n",
    "    ann_final = ann_consensus.copy()\n",
    "    ocsvm_final = ocsvm_results.copy()\n",
    "else:\n",
    "    print(\"Los IDs NO están alineados - procediendo a alinear...\")\n",
    "    print(f\"   Primeros 5 IDs ANN: {ann_ids[:5]}\")\n",
    "    print(f\"   Primeros 5 IDs OCSVM: {ocsvm_ids[:5]}\")\n",
    "    \n",
    "    # Alinear por ID común\n",
    "    if 'number' in ocsvm_results.columns:\n",
    "        ann_final = ann_consensus.sort_values('Source_ID').reset_index(drop=True)\n",
    "        ocsvm_final = ocsvm_results.sort_values('number').reset_index(drop=True)\n",
    "        \n",
    "        # Verificar alineamiento después de ordenar\n",
    "        if np.array_equal(ann_final['Source_ID'].values, ocsvm_final['number'].values):\n",
    "            print(\"IDs alineados correctamente después de ordenar\")\n",
    "        else:\n",
    "            print(\"ERROR: No se pudieron alinear los IDs - revisar datos\")\n",
    "            # Mostrar diferencias\n",
    "            ann_set = set(ann_final['Source_ID'].values)\n",
    "            ocsvm_set = set(ocsvm_final['number'].values)\n",
    "            print(f\"   IDs solo en ANN: {ann_set - ocsvm_set}\")\n",
    "            print(f\"   IDs solo en OCSVM: {ocsvm_set - ann_set}\")\n",
    "    else:\n",
    "        print(\"ERROR: Columna 'number' no encontrada en OCSVM results\")\n",
    "        ann_final = ann_consensus.copy()\n",
    "        ocsvm_final = ocsvm_results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR DATAFRAME COMBINADO\n",
    "\n",
    "# Verificar columnas necesarias existen\n",
    "required_ann_cols = ['Source_ID', 'E_peak', 'Beta', 'log_E_peak', 'log_Beta', 'Mean_Prob_Consensus', 'Std_Prob_Consensus']\n",
    "required_ocsvm_cols = ['prediction', 'Anomaly_Score', 'Anomaly_Rank(%)']\n",
    "\n",
    "missing_ann = [col for col in required_ann_cols if col not in ann_final.columns]\n",
    "missing_ocsvm = [col for col in required_ocsvm_cols if col not in ocsvm_final.columns]\n",
    "\n",
    "if missing_ann:\n",
    "    print(f\"Columnas faltantes en ANN: {missing_ann}\")\n",
    "if missing_ocsvm:\n",
    "    print(f\"Columnas faltantes en OCSVM: {missing_ocsvm}\")\n",
    "\n",
    "if not missing_ann and not missing_ocsvm:\n",
    "    comparison_df = pd.DataFrame({\n",
    "        # IDs y características originales\n",
    "        'Source_ID': ann_final['Source_ID'].values,\n",
    "        'E_peak': ann_final['E_peak'].values,\n",
    "        'Beta': ann_final['Beta'].values,\n",
    "        'Log_E_peak': ann_final['log_E_peak'].values,\n",
    "        'Log_Beta': ann_final['log_Beta'].values,\n",
    "        \n",
    "        # Resultados ANN 2F\n",
    "        'ANN_Prob_Mean': ann_final['Mean_Prob_Consensus'].values,\n",
    "        'ANN_Prob_Std': ann_final['Std_Prob_Consensus'].values,\n",
    "        \n",
    "        # Resultados OCSVM 2F\n",
    "        'OCSVM_Prediction': ocsvm_final['prediction'].values,  # 1=inlier, -1=outlier\n",
    "        'OCSVM_Anomaly_Score': ocsvm_final['Anomaly_Score'].values,\n",
    "        'OCSVM_Anomaly_Rank': ocsvm_final['Anomaly_Rank(%)'].values,\n",
    "    })\n",
    "    \n",
    "else:\n",
    "    print(\"No se pudo crear el DataFrame combinado debido a columnas faltantes\")\n",
    "    comparison_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNÓSTICO DIRECTO ANN 2F vs OCSVM 2F\n",
    "print(\"DIAGNÓSTICO ANN 2F vs OCSVM 2F\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"ANN 2F - Media: {comparison_df['ANN_Prob_Mean'].mean():.4f} | \"\n",
    "      f\"Mediana: {comparison_df['ANN_Prob_Mean'].median():.4f} | \"\n",
    "      f\"Rango: [{comparison_df['ANN_Prob_Mean'].min():.4f}-{comparison_df['ANN_Prob_Mean'].max():.4f}]\")\n",
    "\n",
    "print(f\"OCSVM 2F - Media: {comparison_df['OCSVM_Anomaly_Rank'].mean():.1f}% | \"\n",
    "      f\"Mediana: {comparison_df['OCSVM_Anomaly_Rank'].median():.1f}% | \"\n",
    "      f\"Rango: [{comparison_df['OCSVM_Anomaly_Rank'].min():.1f}%-{comparison_df['OCSVM_Anomaly_Rank'].max():.1f}%]\")\n",
    "\n",
    "# IDENTIFICACIÓN DE CANDIDATOS\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nIDENTIFICACIÓN DE CANDIDATOS:\")\n",
    "ann_threshold = np.percentile(comparison_df['ANN_Prob_Mean'], 95)\n",
    "ocsvm_threshold = np.percentile(comparison_df['OCSVM_Anomaly_Rank'], 95)\n",
    "\n",
    "top_ann = comparison_df[comparison_df['ANN_Prob_Mean'] >= ann_threshold].sort_values('ANN_Prob_Mean', ascending=False)\n",
    "ocsvm_outliers = comparison_df[comparison_df['OCSVM_Prediction'] == -1].sort_values('OCSVM_Anomaly_Rank', ascending=False)\n",
    "top_ocsvm = comparison_df[comparison_df['OCSVM_Anomaly_Rank'] >= ocsvm_threshold].sort_values('OCSVM_Anomaly_Rank', ascending=False)\n",
    "\n",
    "print(f\"Top ANN (P95={ann_threshold:.4f}): {len(top_ann)} fuentes\")\n",
    "print(f\"OCSVM Outliers: {len(ocsvm_outliers)} fuentes\")\n",
    "print(f\"Top OCSVM (P95={ocsvm_threshold:.1f}%): {len(top_ocsvm)} fuentes\")\n",
    "\n",
    "# SOLAPAMIENTOS\n",
    "print(f\"\\nSOLAPAMIENTOS:\")\n",
    "overlap_restrictivo = set(top_ann['Source_ID']) & set(ocsvm_outliers['Source_ID'])\n",
    "overlap_amplio = set(top_ann['Source_ID']) & set(top_ocsvm['Source_ID'])\n",
    "\n",
    "print(f\"Top ANN ∩ OCSVM Outliers: {len(overlap_restrictivo)} fuentes\")\n",
    "if overlap_restrictivo:\n",
    "    print(f\"  IDs: {sorted(list(overlap_restrictivo))}\")\n",
    "\n",
    "print(f\"Top ANN ∩ Top OCSVM: {len(overlap_amplio)} fuentes\")\n",
    "if overlap_amplio:\n",
    "    print(f\"  IDs: {sorted(list(overlap_amplio))}\")\n",
    "\n",
    "# TOP 10 COMPARACIÓN DIRECTA\n",
    "print(f\"\\nTOP 10 ANN vs OCSVM:\")\n",
    "print(\"-\" * 60)\n",
    "for i, (_, row) in enumerate(top_ann.head(10).iterrows()):\n",
    "    status = \"Outlier\" if row['OCSVM_Prediction'] == -1 else \"Normal\"\n",
    "    print(f\"{i+1:2d}. ID {int(row['Source_ID']):4d}: ANN={row['ANN_Prob_Mean']:.4f} | OCSVM={row['OCSVM_Anomaly_Rank']:5.1f}% {status}\")\n",
    "\n",
    "print(f\"\\nOUTLIERS OCSVM vs ANN:\")\n",
    "print(\"-\" * 60)\n",
    "if len(ocsvm_outliers) > 0:\n",
    "    for i, (_, row) in enumerate(ocsvm_outliers.iterrows()):\n",
    "        print(f\"{i+1:2d}. ID {int(row['Source_ID']):4d}: OCSVM={row['OCSVM_Anomaly_Rank']:5.1f}% | ANN={row['ANN_Prob_Mean']:.4f}\")\n",
    "else:\n",
    "    print(\"No hay outliers detectados por OCSVM\")\n",
    "\n",
    "# ANÁLISIS DE CONCORDANCIA\n",
    "print(f\"\\nANÁLISIS DE CONCORDANCIA:\")\n",
    "# Correlación entre métricas\n",
    "correlation = np.corrcoef(comparison_df['ANN_Prob_Mean'], comparison_df['OCSVM_Anomaly_Rank'])[0, 1]\n",
    "print(f\"Correlación ANN-OCSVM: {correlation:.4f}\")\n",
    "\n",
    "# Concordancia en clasificación binaria\n",
    "ann_high = comparison_df['ANN_Prob_Mean'] >= ann_threshold\n",
    "ocsvm_high = comparison_df['OCSVM_Anomaly_Rank'] >= ocsvm_threshold\n",
    "\n",
    "concordancia = np.mean(ann_high == ocsvm_high) * 100\n",
    "print(f\"Concordancia en top 5%: {concordancia:.1f}%\")\n",
    "\n",
    "# Casos discrepantes\n",
    "discrepantes_ann_high_ocsvm_low = comparison_df[(comparison_df['ANN_Prob_Mean'] >= ann_threshold) & \n",
    "                                               (comparison_df['OCSVM_Anomaly_Rank'] < 50)]\n",
    "discrepantes_ocsvm_high_ann_low = comparison_df[(comparison_df['OCSVM_Anomaly_Rank'] >= ocsvm_threshold) & \n",
    "                                               (comparison_df['ANN_Prob_Mean'] < 0.5)]\n",
    "\n",
    "print(f\"Discrepantes (ANN alta, OCSVM baja): {len(discrepantes_ann_high_ocsvm_low)}\")\n",
    "print(f\"Discrepantes (OCSVM alta, ANN baja): {len(discrepantes_ocsvm_high_ann_low)}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "# RESUMEN EJECUTIVO\n",
    "print(f\"\\nRESUMEN EJECUTIVO:\")\n",
    "if len(overlap_restrictivo) > 0:\n",
    "    print(f\"Consenso encontrado: {len(overlap_restrictivo)} fuentes identificadas por ambos métodos\")\n",
    "else:\n",
    "    print(\"Sin consenso directo entre métodos\")\n",
    "\n",
    "if abs(correlation) > 0.5:\n",
    "    print(f\"Correlación moderada-alta: {correlation:.3f}\")\n",
    "else:\n",
    "    print(f\"Correlación baja: {correlation:.3f}\")\n",
    "\n",
    "if concordancia > 70:\n",
    "    print(f\"Buena concordancia en top candidatos: {concordancia:.1f}%\")\n",
    "else:\n",
    "    print(f\"Baja concordancia en top candidatos: {concordancia:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
