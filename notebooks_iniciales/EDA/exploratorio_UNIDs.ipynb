{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos – Fuentes UNID\n",
    "\n",
    "En este notebook se realiza un análisis exploratorio de las fuentes no identificadas (UNIDs) contenidas en el archivo `unids_3F_beta_err_names.txt`. Estas fuentes no cuentan con una etiqueta de clase conocida (a diferencia de los datos ASTRO o DM simulados), pero se espera que puedan incluir candidatas a materia oscura.\n",
    "\n",
    "Cada instancia incluye las siguientes variables:\n",
    "\n",
    "- **E_peak**: Energía pico (sin logaritmar).\n",
    "- **beta**: Curvatura espectral.\n",
    "- **sigma_det**: Significancia de detección.\n",
    "- **beta_Rel**: Error relativo sobre la curvatura.\n",
    "- **number**: Identificador único de cada fuente.\n",
    "\n",
    "Este análisis busca comprender la distribución de estas variables, detectar patrones, posibles agrupaciones o comportamientos atípicos que puedan indicar candidatos interesantes para detección de anomalías con modelos no supervisados como One-Class SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación Logarítmica y Verificación de Compatibilidad - UNIDs Fermi-LAT\n",
    "# TFG: Utilización de técnicas de ML a datos del satélite Fermi-Lat para detección de posibles fuentes de materia oscura\n",
    "# Objetivo: Transformar datos UNIDs a escala logarítmica para compatibilidad con modelo OneClassSVM\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nombres de las columnas para UNIDs\n",
    "unids_features = ['E_peak', 'beta', 'sigma_det', 'beta_Rel', 'number']\n",
    "\n",
    "# Cargar los datos UNIDs\n",
    "unids_df = pd.read_csv('../../data/raw/unids_3F_beta_err_names.txt', \n",
    "                       sep=\"\\s+\", names=unids_features, engine='python', skiprows=1)\n",
    "\n",
    "print(f\"Dimensiones del dataset UNIDs: {unids_df.shape}\")\n",
    "print(f\"Número total de fuentes no identificadas: {len(unids_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información básica del dataset\n",
    "print(\"\\nInformación del dataset UNIDs:\")\n",
    "unids_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unids_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPrimeras 10 fuentes UNIDs:\")\n",
    "unids_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nÚltimas 5 fuentes UNIDs:\")\n",
    "unids_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar el rango de IDs\n",
    "print(f\"\\nRango de IDs de fuentes UNIDs:\")\n",
    "print(f\"ID mínimo: {unids_df['number'].min()}\")\n",
    "print(f\"ID máximo: {unids_df['number'].max()}\")\n",
    "print(f\"IDs únicos: {unids_df['number'].nunique()}\")\n",
    "\n",
    "if unids_df['number'].nunique() == len(unids_df):\n",
    "    print(\"Cada fuente UNID tiene un ID único\")\n",
    "else:\n",
    "    print(\"Hay IDs duplicados en el dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de características (excluyendo el ID)\n",
    "unids_feature_cols = ['E_peak', 'beta', 'sigma_det', 'beta_Rel']\n",
    "\n",
    "print(\"Estadísticas descriptivas de fuentes UNIDs:\")\n",
    "unids_stats = unids_df[unids_feature_cols].describe()\n",
    "print(unids_stats)\n",
    "\n",
    "# Verificar valores faltantes\n",
    "print(f\"\\nVerificación de valores faltantes:\")\n",
    "missing_values = unids_df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No hay valores faltantes en el dataset UNIDs\")\n",
    "else:\n",
    "    print(\"Se encontraron valores faltantes\")\n",
    "\n",
    "# Verificar valores duplicados (excluyendo el ID)\n",
    "duplicates = unids_df[unids_feature_cols].duplicated().sum()\n",
    "print(f\"\\nFilas duplicadas (sin considerar ID): {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramas de cada variable (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de todas las variables UNIDs\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(unids_feature_cols):\n",
    "    # Histograma\n",
    "    axes[i].hist(unids_df[col], bins=40, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribución de {col} - Fuentes UNIDs')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Añadir estadísticas básicas\n",
    "    mean_val = unids_df[col].mean()\n",
    "    std_val = unids_df[col].std()\n",
    "    median_val = unids_df[col].median()\n",
    "    \n",
    "    axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.8, \n",
    "                   label=f'Media: {mean_val:.3f}')\n",
    "    axes[i].axvline(median_val, color='blue', linestyle='-.', alpha=0.8, \n",
    "                   label=f'Mediana: {median_val:.3f}')\n",
    "    axes[i].axvline(mean_val + std_val, color='orange', linestyle=':', alpha=0.8, \n",
    "                   label=f'+1σ: {mean_val + std_val:.3f}')\n",
    "    axes[i].axvline(mean_val - std_val, color='orange', linestyle=':', alpha=0.8, \n",
    "                   label=f'-1σ: {mean_val - std_val:.3f}')\n",
    "    axes[i].legend(fontsize=10)\n",
    "\n",
    "plt.suptitle('Distribuciones de Variables - Fuentes UNIDs', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación para UNIDs\n",
    "unids_correlation = unids_df[unids_feature_cols].corr()\n",
    "print(\"Matriz de correlación entre variables UNIDs:\")\n",
    "print(unids_correlation)\n",
    "\n",
    "# Visualización de la matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(unids_correlation, dtype=bool))\n",
    "sns.heatmap(unids_correlation, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, mask=mask, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correlación - Fuentes UNIDs')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar correlaciones significativas\n",
    "print(\"\\nCorrelaciones significativas en UNIDs (|r| > 0.3):\")\n",
    "for i in range(len(unids_correlation.columns)):\n",
    "    for j in range(i+1, len(unids_correlation.columns)):\n",
    "        corr_val = unids_correlation.iloc[i, j]\n",
    "        if abs(corr_val) > 0.3:\n",
    "            print(f\"{unids_correlation.columns[i]} - {unids_correlation.columns[j]}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear scatter plots para pares de variables\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Pares de variables importantes\n",
    "pairs = [\n",
    "    ('E_peak', 'beta'),\n",
    "    ('E_peak', 'sigma_det'),\n",
    "    ('beta', 'sigma_det'),\n",
    "    ('beta', 'beta_Rel'),\n",
    "    ('sigma_det', 'beta_Rel'),\n",
    "    ('E_peak', 'beta_Rel')\n",
    "]\n",
    "\n",
    "for i, (x_var, y_var) in enumerate(pairs):\n",
    "    # Scatter plot\n",
    "    scatter = axes[i].scatter(unids_df[x_var], unids_df[y_var], \n",
    "                             alpha=0.6, c='darkgreen', s=30)\n",
    "    \n",
    "    axes[i].set_xlabel(x_var)\n",
    "    axes[i].set_ylabel(y_var)\n",
    "    axes[i].set_title(f'{x_var} vs {y_var} - Fuentes UNIDs')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Añadir línea de tendencia si hay correlación significativa\n",
    "    if abs(unids_correlation.loc[x_var, y_var]) > 0.3:\n",
    "        z = np.polyfit(unids_df[x_var], unids_df[y_var], 1)\n",
    "        p = np.poly1d(z)\n",
    "        axes[i].plot(unids_df[x_var], p(unids_df[x_var]), \"r--\", alpha=0.8,\n",
    "                    label=f'r = {unids_correlation.loc[x_var, y_var]:.3f}')\n",
    "        axes[i].legend()\n",
    "\n",
    "plt.suptitle('Análisis Bivariado - Fuentes UNIDs', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Convertir las columnas a logaritmo de base 10\n",
    "unids_df['E_peak'] = np.log10(unids_df['E_peak'])\n",
    "unids_df['beta'] = np.log10(unids_df['beta'])\n",
    "unids_df['sigma_det'] = np.log10(unids_df['sigma_det'])\n",
    "unids_df['beta_Rel'] = np.log10(unids_df['beta_Rel'])\n",
    "# Ver muestra\n",
    "unids_df.head()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observaciones del Análisis Exploratorio (EDA) – Fuentes UNID\n",
    "\n",
    "A continuación se detallan los principales hallazgos obtenidos del análisis de las variables contenidas en las fuentes no identificadas (UNIDs):\n",
    "\n",
    "### Distribuciones de variables\n",
    "- **E_peak** presenta una fuerte asimetría positiva (cola larga), con la mayoría de valores muy concentrados por debajo de 100, pero con valores extremos que superan los 1000. Esto sugiere la presencia de posibles outliers o escalas diferentes de emisión en algunas fuentes.\n",
    "- **beta** muestra una distribución sesgada hacia valores bajos, con una concentración destacada entre 0.0 y 0.4. Este patrón puede estar asociado a formas espectrales más típicas, mientras que valores mayores podrían representar fuentes más inusuales.\n",
    "- **beta_Rel** y **sigma_det** también muestran colas largas, lo que indica variabilidad en la calidad o fiabilidad de las mediciones espectrales.\n",
    "- La transformación logarítmica de estas variables ayuda a **reducir la asimetría y comprimir outliers**, como se evidencia en la última figura (`log10(E_peak)` vs `log10(beta)`).\n",
    "\n",
    "### Correlación entre variables\n",
    "- El mapa de correlación muestra **correlaciones débiles** entre las variables (`|r| < 0.25`), lo que sugiere que estas características aportan información relativamente independiente.\n",
    "- La variable `beta_Rel` está moderadamente correlacionada negativamente con `beta`, lo que podría indicar que la curvatura espectral más baja tiende a estar mejor caracterizada.\n",
    "\n",
    "### Relaciones bivariadas\n",
    "- El scatter plot `E_peak` vs `beta` evidencia **grandes concentraciones en regiones específicas del espacio**, pero también algunos puntos claramente aislados (posibles candidatos a anomalía).\n",
    "- Al aplicar la escala logarítmica (`log10`), se observa un **grupo denso bien delimitado** junto con varios puntos alejados, lo que refuerza la necesidad de utilizar un modelo de detección de anomalías.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Los datos de las fuentes UNID presentan una alta variabilidad en sus características espectrales, así como valores extremos que podrían indicar fenómenos no convencionales. Esta exploración apoya el uso de modelos de aprendizaje no supervisado, como **One-Class SVM**, para identificar observaciones que se desvíen significativamente del comportamiento de fuentes astrofísicas conocidas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
