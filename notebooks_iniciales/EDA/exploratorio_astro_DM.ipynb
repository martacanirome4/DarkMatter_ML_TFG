{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA) – ASTRO vs DM\n",
    "\n",
    "Este notebook realiza un análisis exploratorio del conjunto de datos `XY_bal_log_Rel.txt`, que contiene fuentes astrofísicas identificadas (ASTRO) y simulaciones de materia oscura (DM, Dark Matter). El objetivo es entender la estructura de los datos y estudiar el comportamiento de sus variables principales antes de realizar cualquier preprocesamiento o modelado, es decir explorar las características principales del dataset, identificar patrones útiles y preparar los datos para su uso en modelos de aprendizaje automático.\n",
    "\n",
    "El análisis se centra en las siguientes variables:\n",
    "\n",
    "1. **E_peak** – Pico de energía del espectro gamma.\n",
    "2. **beta** – Curvatura espectral.\n",
    "3. **sigma** – Significancia estadística de detección.\n",
    "4. **beta_Rel** – Error relativo de la curvatura.\n",
    "5. **astro_DM** – Etiqueta de clase: 0 para ASTRO, 1 para DM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del dataset original\n",
    "\n",
    "El archivo original `XY_bal_log_Rel.txt` se encuentra en la carpeta `data/raw/`. Contiene los datos balanceados entre fuentes ASTRO y DM. Se cargan los datos indicando manualmente los nombres de las columnas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propósito del EDA\n",
    "\n",
    "Antes de aplicar cualquier técnica de aprendizaje automático, es fundamental comprender la naturaleza de los datos disponibles. Este análisis tiene los siguientes objetivos específicos:\n",
    "\n",
    "- Estudiar la **distribución individual de cada feature**, diferenciando entre clases (ASTRO vs DM).\n",
    "- Explorar **relaciones entre variables**, como correlaciones o agrupamientos visuales.\n",
    "- Detectar posibles **outliers o patrones** inesperados.\n",
    "- Evaluar si existen diferencias sustanciales entre las clases que justifiquen el uso de técnicas de clasificación o detección de anomalías.\n",
    "- Obtener una primera intuición sobre qué características podrían resultar más **discriminativas o relevantes** para el modelado.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualizaciones realizadas\n",
    "\n",
    "- **Histogramas** por feature, diferenciados por clase (`astro_DM`), para visualizar la distribución.\n",
    "- **Gráficos de dispersión** (scatter plots) en pares de features clave.\n",
    "- **Matriz de correlación (heatmap)** para evaluar redundancias o relaciones lineales entre variables.\n",
    "- **Resumen estadístico** (media, desviación, mínimo, máximo, etc.) por clase.\n",
    "\n",
    "---\n",
    "\n",
    "## Principales observaciones\n",
    "\n",
    "- Las distribuciones de `Log(E_peak)` y `Log(beta)` muestran diferencias visibles entre las clases, lo cual sugiere que estas variables podrían ser útiles para la separación entre ASTRO y DM.\n",
    "- `Log(sigma)` y `Log(beta_Rel)` están más correlacionadas entre sí, posiblemente debido a su relación con la significancia y la precisión espectral.\n",
    "- En el espacio de características proyectado (por ejemplo en PCA o scatter 2D), las clases no se solapan completamente, lo cual apoya el uso de técnicas como One-Class SVM para identificar fuentes anómalas.\n",
    "\n",
    "---\n",
    "\n",
    "## Justificación para el modelado posterior\n",
    "\n",
    "A partir de este análisis se concluye que es viable aplicar un modelo de detección de anomalías (como One-Class SVM) usando las variables disponibles. Las observaciones ASTRO muestran un comportamiento relativamente coherente entre sí, mientras que las instancias simuladas (DM) presentan diferencias medibles en varias dimensiones.\n",
    "\n",
    "Este análisis también permite establecer una **expectativa razonable** sobre qué comportamientos el modelo debería considerar \"normales\" (ASTRO) y qué patrones se considerarían desviaciones del comportamiento esperado (posibles DM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nombres de las columnas\n",
    "features = ['E_peak', 'beta', 'sigma', 'beta_Rel', '0,1=astro,DM']\n",
    "\n",
    "# Cargar los datos\n",
    "df = pd.read_csv('../../data/raw/XY_bal_log_Rel.txt', sep=\"\\s+\", names=features, engine='python', skiprows=1)\n",
    "\n",
    "# Renombrar la columna de etiquetas para mayor claridad\n",
    "df = df.rename(columns={'0,1=astro,DM': 'astro_DM'})\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"Número total de observaciones: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información básica del dataset\n",
    "print(f\"\\nInformación del dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPrimeras 10 filas:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nÚltimas 5 filas:\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver los valores de correlación entre variables\n",
    "print(\"Matriz de correlación entre variables:\")\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas generales\n",
    "print(\"Estadísticas descriptivas generales:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores faltantes\n",
    "print(f\"\\nVerificación de valores faltantes:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"No hay valores faltantes en el dataset\")\n",
    "else:\n",
    "    print(\"Se encontraron valores faltantes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores duplicados\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nFilas duplicadas: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar observaciones por clase\n",
    "class_counts = df['astro_DM'].value_counts()\n",
    "class_percentages = df['astro_DM'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Distribución de clases:\")\n",
    "print(f\"ASTRO (0.0): {class_counts[0.0]:,} observaciones ({class_percentages[0.0]:.1f}%)\")\n",
    "print(f\"DM (1.0): {class_counts[1.0]:,} observaciones ({class_percentages[1.0]:.1f}%)\")\n",
    "\n",
    "# Verificar balance de clases\n",
    "balance_ratio = min(class_counts) / max(class_counts)\n",
    "print(f\"\\nRatio de balance: {balance_ratio:.3f}\")\n",
    "if balance_ratio > 0.8:\n",
    "    print(\"Dataset bien balanceado\")\n",
    "elif balance_ratio > 0.5:\n",
    "    print(\"Dataset moderadamente desbalanceado\")\n",
    "else:\n",
    "    print(\"Dataset significativamente desbalanceado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadísticas por clase\n",
    "print(f\"\\n\\nEstadísticas por clase:\")\n",
    "\n",
    "print(f\"\\nCLASE ASTRO (0.0):\")\n",
    "astro_stats = df[df['astro_DM'] == 0.0].describe()\n",
    "print(astro_stats)\n",
    "\n",
    "print(f\"\\nCLASE DM (1.0):\")\n",
    "dm_stats = df[df['astro_DM'] == 1.0].describe()\n",
    "print(dm_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de características (excluyendo la etiqueta)\n",
    "feature_cols = ['E_peak', 'beta', 'sigma', 'beta_Rel']\n",
    "\n",
    "# Histogramas de todas las variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    # Histograma general\n",
    "    axes[i].hist(df[col], bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
    "    axes[i].set_title(f'Distribución de {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Frecuencia')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Añadir estadísticas básicas\n",
    "    mean_val = df[col].mean()\n",
    "    std_val = df[col].std()\n",
    "    axes[i].axvline(mean_val, color='red', linestyle='--', alpha=0.8, label=f'Media: {mean_val:.3f}')\n",
    "    axes[i].axvline(mean_val + std_val, color='orange', linestyle=':', alpha=0.8, label=f'+1σ: {mean_val + std_val:.3f}')\n",
    "    axes[i].axvline(mean_val - std_val, color='orange', linestyle=':', alpha=0.8, label=f'-1σ: {mean_val - std_val:.3f}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas superpuestos por clase\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    # Datos por clase\n",
    "    astro_data = df[df['astro_DM'] == 0.0][col]\n",
    "    dm_data = df[df['astro_DM'] == 1.0][col]\n",
    "    \n",
    "    # Histogramas superpuestos\n",
    "    axes[i].hist(astro_data, bins=40, alpha=0.6, color='skyblue', label='ASTRO', density=True)\n",
    "    axes[i].hist(dm_data, bins=40, alpha=0.6, color='lightcoral', label='DM', density=True)\n",
    "    \n",
    "    axes[i].set_title(f'Distribución de {col} por Clase')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Densidad')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación\n",
    "correlation_matrix = df[feature_cols].corr()\n",
    "print(\"Matriz de correlación entre variables:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Visualización de la matriz de correlación\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "            square=True, mask=mask, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Matriz de Correlación - Variables Principales')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identificar correlaciones fuertes\n",
    "print(\"\\nCorrelaciones significativas (|r| > 0.5):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.5:\n",
    "            print(f\"{correlation_matrix.columns[i]} - {correlation_matrix.columns[j]}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear scatter plots para pares de variables más interesantes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Pares de variables importantes\n",
    "pairs = [\n",
    "    ('E_peak', 'beta'),\n",
    "    ('E_peak', 'sigma'),\n",
    "    ('beta', 'sigma'),\n",
    "    ('beta', 'beta_Rel'),\n",
    "    ('sigma', 'beta_Rel'),\n",
    "    ('E_peak', 'beta_Rel')\n",
    "]\n",
    "\n",
    "for i, (x_var, y_var) in enumerate(pairs):\n",
    "    # Separar por clase\n",
    "    astro_data = df[df['astro_DM'] == 0.0]\n",
    "    dm_data = df[df['astro_DM'] == 1.0]\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[i].scatter(astro_data[x_var], astro_data[y_var], alpha=0.6, \n",
    "                   c='skyblue', label='ASTRO', s=20)\n",
    "    axes[i].scatter(dm_data[x_var], dm_data[y_var], alpha=0.6, \n",
    "                   c='lightcoral', label='DM', s=20)\n",
    "    \n",
    "    axes[i].set_xlabel(x_var)\n",
    "    axes[i].set_ylabel(y_var)\n",
    "    axes[i].set_title(f'{x_var} vs {y_var}')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
