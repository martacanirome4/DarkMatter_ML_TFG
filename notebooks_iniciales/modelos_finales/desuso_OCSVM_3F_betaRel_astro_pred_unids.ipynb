{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 📓 Modelo de OneClassSVM entrenado con 3F de datos Astro, y predicción sobre datos Unid (no identificados)\n",
    "\n",
    "**Proyecto**: Detección de posibles fuentes de materia oscura usando ML en datos Fermi-LAT  \n",
    "**Autor**: Marta Canino Romero  \n",
    "**Fecha**: febrero-mayo 20225\n",
    "\n",
    "---\n",
    "\n",
    "## ✨ Descripción:\n",
    "\n",
    "Este notebook aplica un modelo **One-Class SVM** entrenado con datos de fuentes astrofísicas conocidas (ASTRO) usando las siguientes características:\n",
    "\n",
    "- E_peak\n",
    "- beta\n",
    "- betaRel\n",
    "\n",
    "Este modelo se entrena para identificar anomalías que puedan corresponder a posibles fuentes de materia oscura (UNIDs) en los datos no identificados del catálogo 4FGL.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Objetivos específicos:\n",
    "\n",
    "- Entrenar modelo OCSVM con [número de features] \n",
    "- Optimizar hiperparámetros (grid search sobre `nu` y `gamma`)\n",
    "- Evaluar sobre datos de validación y prueba\n",
    "- Aplicar modelo final sobre datos UNID para predicción\n",
    "\n",
    "---\n",
    "\n",
    "## 🗂️ Entrada de datos:\n",
    "\n",
    "- `../../data/processed/XY_bal_log_Rel/astro/XY_bal_log_Rel_astro.txt`\n",
    "\n",
    "## 💾 Salida esperada:\n",
    "\n",
    "- Mejor combinación de hiperparámetros\n",
    "- Métricas de evaluación (f1-score, confusion matrix)\n",
    "- Exportación de los UNIDs más anómalos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargar dataset ---\n",
    "data_path = \"../../data/processed/XY_bal_log_Rel/astro/XY_bal_log_Rel_astro.txt\"\n",
    "df_astro = pd.read_csv(data_path, sep=r\"\\s+\")\n",
    "\n",
    "# Renombramos la columna target por claridad\n",
    "df_astro = df_astro.rename(columns={\"0,1=astro,DM\": \"class\"})\n",
    "\n",
    "# --- Comprobamos distribución del dataset ---\n",
    "print(f\"📁 Dataset cargado. Forma: {df_astro.shape}\")\n",
    "print(f\"🧠 Nombres de las columnas: {list(df_astro.columns)}\")\n",
    "\n",
    "display(df_astro.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Selección de características ---\n",
    "features = ['E_peak', 'beta', 'beta_Rel']\n",
    "target = 'class'\n",
    "\n",
    "print(f\"✅ Features seleccionadas: {features}\")\n",
    "print(f\"🎯 Columna objetivo: {target}\")\n",
    "\n",
    "# --- Comprobamos valores nulos ---\n",
    "print(\"\\n🔍 Valores faltantes por columna:\")\n",
    "print(df_astro[features + [target]].isnull().sum())\n",
    "\n",
    "print(\"\\n📌 Muestra del dataset:\")\n",
    "display(df_astro[features + [target]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_astro,\n",
    "    x=\"E_peak\",\n",
    "    y=\"beta\",\n",
    "    color=\"turquoise\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "\n",
    "plt.title(\"2D Unscaled ASTRO Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"E_peak\")\n",
    "plt.ylabel(\"beta\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación 3D\n",
    "x = df_astro['E_peak']\n",
    "y = df_astro['beta']\n",
    "z = df_astro['beta_Rel']\n",
    "\n",
    "labels = df_astro['class']\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(x, y, z, c=labels, cmap='cool', edgecolor='k')\n",
    "\n",
    "ax.set_xlabel('E_peak')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_zlabel('beta_Rel')\n",
    "plt.title('3D Unscaled ASTRO Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Astro dataframe shape: ', df_astro.shape)\n",
    "print('Astro dataframe features shape: ', df_astro[features].shape)\n",
    "print('Astro dataframe target shape: ', df_astro[target].shape)\n",
    "\n",
    "# Seleccionamos las features dinámicamente\n",
    "X = df_astro[features].values\n",
    "y = df_astro[\"class\"].values\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)\n",
    "\n",
    "# Split: Train / Val / Test\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Hacemos una división estratificada para mantener la proporción de clases\n",
    "# First stratified split: 60% train, 40% temp (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Second stratified split: 50% val, 50% test from temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# Escalado\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train_scaled shape: ', X_train_scaled.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "\n",
    "print('\\nX_test_scaled shape: ',X_test_scaled.shape)\n",
    "print('y_test shape: ', y_test.shape)\n",
    "\n",
    "print('\\nX_val_scaled shape: ',X_val_scaled.shape)\n",
    "print('y_val shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que los datos están bien escalados\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_scaled[:, 0],\n",
    "    y=X_train_scaled[:, 1],\n",
    "    color=\"turquoise\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "plt.title(\"Scaled Train Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"E_peak\")\n",
    "plt.ylabel(\"beta\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos los datos escalados\n",
    "x = X_train_scaled[:, 0]\n",
    "y = X_train_scaled[:, 1]\n",
    "z = X_train_scaled[:, 2]\n",
    "\n",
    "# Scatter plot 3D de X_train_scaled\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(x, y, z, c=y_train, cmap='cool', edgecolor='k')\n",
    "ax.set_xlabel('E_peak')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_zlabel('beta_Rel')\n",
    "plt.title('3D Scaled ASTRO Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Entrenar modelo + Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZACION BASADA EN PUNTUACION F1 PARA DATOS ETIQUETADOS \n",
    "\n",
    "# --- Hiperparámetros a explorar ---\n",
    "nu_values = [0.005, 0.01, 0.02, 0.05]\n",
    "gamma_values = ['scale', 'auto'] + list(np.logspace(-3, 1, 5))\n",
    "\n",
    "# --- Tracking de resultados ---\n",
    "results = []\n",
    "best_score = 0.0  # F1 score (cuanto más alto, mejor)\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "# --- Grid Search ---\n",
    "print(\"🔍 Iniciando búsqueda de hiperparámetros basada en F1-score...\\n\")\n",
    "for nu in nu_values:\n",
    "    for gamma in gamma_values:\n",
    "        model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "        model.fit(X_train_scaled)\n",
    "\n",
    "        # Predicciones\n",
    "        preds = model.predict(X_val_scaled)              # 1 = inlier, -1 = outlier\n",
    "        pred_labels = np.where(preds == 1, 0, 1)         # Mapear a 0 = normal, 1 = anomalía\n",
    "        true_labels = y_val.astype(int)                  # Aseguramos tipo int\n",
    "\n",
    "        # Evaluación\n",
    "        f1 = f1_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "        results.append({'nu': nu, 'gamma': gamma, 'f1_score': f1})\n",
    "\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "\n",
    "# --- Resultados Finales ---\n",
    "print(\"✅ Mejor combinación de hiperparámetros:\")\n",
    "print(f\"   - nu = {best_params['nu']}\")\n",
    "print(f\"   - gamma = {best_params['gamma']}\")\n",
    "print(f\"📈 Mejor F1-Score en validación: {best_score:.4f}\")\n",
    "\n",
    "# --- Convertimos resultados en DataFrame (opcional) ---\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values(by='f1_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos el modelo con los mejores hiperparámetros\n",
    "best_model = OneClassSVM(kernel='rbf', nu=best_params['nu'], gamma=best_params['gamma'])\n",
    "best_model.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre datos de validación\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X_3d = X_val_scaled\n",
    "\n",
    "# Predecimos de nuevo sobre validación para la visualización\n",
    "preds = best_model.predict(X_3d)\n",
    "\n",
    "ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], c=preds, cmap='cool', edgecolor='k', s=30)\n",
    "\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel(features[2])\n",
    "plt.title(\"Distribución 3D con predicción (validación)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# Doble comprobación con datos ASTRO reservados de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos sobre los datos de prueba (X_test_scaled) con el mejor modelo ya entrenado\n",
    "test_preds = best_model.predict(X_test_scaled)\n",
    "\n",
    "n_test_outliers = np.sum(test_preds == -1)\n",
    "\n",
    "print(f\"Outliers en conjunto de datos reservado de prueba (test data): {n_test_outliers}\")\n",
    "test_labels = np.where(test_preds == 1, 0, 1)  # 1 = normal, -1 = outlier → mapeado\n",
    "true_labels_test = y_test.astype(int)\n",
    "\n",
    "print(\"\\n📉 Matriz de confusión (Test Set):\")\n",
    "print(confusion_matrix(true_labels_test, test_labels))\n",
    "\n",
    "print(\"\\n📋 Reporte de clasificación:\")\n",
    "print(classification_report(y_test, test_labels, target_names=[\"Normal\", \"Anomalía\"], zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(true_labels_test, test_labels, display_labels=[\"Normal\", \"Anomalía\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre datos de prueba\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X_3d = X_test_scaled\n",
    "preds = best_model.predict(X_3d)\n",
    "ax.scatter(X_3d[:, 0], X_3d[:, 1], X_3d[:, 2], c=preds, cmap='cool', edgecolor='k', s=30)\n",
    "\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel(features[2])\n",
    "plt.title(\"Distribución 3D con predicción (test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "unids_path = \"../../data/raw/unids_3F_beta_err_names.txt\"\n",
    "df_unids = pd.read_csv(unids_path, sep='\\s+')\n",
    "df_unids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos a logaritmo\n",
    "cols_to_log = [\"E_peak\", \"beta\", \"sigma_det\", \"beta_Rel\"]\n",
    "df_unids_log = df_unids.copy()\n",
    "df_unids_log[cols_to_log] = df_unids_log[cols_to_log].apply(lambda x: np.log10(x.clip(lower=1e-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer y escalar\n",
    "X_unids_log = df_unids_log[[\"E_peak\", \"beta\", \"beta_Rel\"]].values\n",
    "X_unids_scaled = scaler.transform(X_unids_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create subplots ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6), sharey=True)\n",
    "\n",
    "# --- Plot 1: Raw UNIDS data ---\n",
    "sns.scatterplot(\n",
    "    data=df_unids,\n",
    "    x=\"E_peak\",\n",
    "    y=\"beta\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"UNIDS Data: E_peak vs Beta\")\n",
    "axes[0].set_xlabel(\"E_peak\")\n",
    "axes[0].set_ylabel(\"beta\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Plot 2: Log-transformed UNIDS ---\n",
    "sns.scatterplot(\n",
    "    data=df_unids_log,\n",
    "    x=\"E_peak\",\n",
    "    y=\"beta\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"UNIDS (Log): E_peak vs Beta\")\n",
    "axes[1].set_xlabel(\"E_peak (log10)\")\n",
    "axes[1].set_ylabel(\"\")  # hide repeated ylabel\n",
    "axes[1].grid(True)\n",
    "\n",
    "# --- Plot 3: Scaled UNIDS ---\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Scaled UNIDS: E_peak vs Beta\")\n",
    "axes[2].set_xlabel(\"E_peak (scaled)\")\n",
    "axes[2].set_ylabel(\"\")  # hide repeated ylabel\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de 3D de UNIDS\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X_unids_scaled[:, 0], X_unids_scaled[:, 1], X_unids_scaled[:, 2], color=\"gold\", edgecolor='k', alpha=0.7, s=40)\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('beta_Rel (scaled)')\n",
    "plt.title('3D UNIDS Data (scaled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de unids después de escalar\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "plt.title(\"Scaled UNIDS Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de X_unids_scaled vs X_train_scaled 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], color=\"turquoise\", edgecolor='k', alpha=0.7, s=40, label=\"Train Data\")\n",
    "plt.scatter(X_unids_scaled[:, 0], X_unids_scaled[:, 1], color=\"gold\", edgecolor='k', alpha=0.7, s=40, label=\"UNIDS Data\")\n",
    "plt.title(\"2D Scaled Train Data vs UNIDS Data\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de UNIDs vs ASTRO 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter ASTRO (training data)\n",
    "ax.scatter(\n",
    "    X_train_scaled[:, 0], X_train_scaled[:, 1], X_train_scaled[:, 2],\n",
    "    color=\"steelblue\", edgecolor='k', alpha=0.2, s=60, label='ASTRO (train)',\n",
    ")\n",
    "\n",
    "# Scatter UNIDs (to predict)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[:, 0], X_unids_scaled[:, 1], X_unids_scaled[:, 2],\n",
    "    color=\"gold\", edgecolor='k', alpha=0.9, s=60, label='UNIDs',\n",
    "    marker='^'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('beta_Rel (scaled)')\n",
    "ax.set_title('3D Scatter: ASTRO vs UNIDs (scaled)')\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones sobre UNIDS\n",
    "unids_preds = best_model.predict(X_unids_scaled)\n",
    "\n",
    "n_unids_outliers = np.sum(unids_preds == -1)\n",
    "n_unids_normals = np.sum(unids_preds == 1)\n",
    "\n",
    "print(f\"🚀 Predicted ASTRO-like: {n_unids_normals}\")\n",
    "print(f\"❗ Predicted not ASTRO-like (anomalies): {n_unids_outliers}\")\n",
    "unids_labels = np.where(unids_preds == 1, 0, 1)  # 1 = normal, -1 = outlier → mapeado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers = X_unids_scaled[unids_preds == 1]\n",
    "outliers = X_unids_scaled[unids_preds == -1]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (likely astro)', alpha=0.6)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (potentially new)', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"UNIDs: Inlier vs Outlier (One-Class SVM)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre UNIDS\n",
    "\n",
    "# Get predictions from best model on UNIDs\n",
    "preds = best_model.predict(X_unids_scaled)  # 1 = inlier, -1 = outlier\n",
    "\n",
    "# Separate indices\n",
    "inlier_idx = preds == 1\n",
    "outlier_idx = preds == -1\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers (normal)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[inlier_idx, 0], X_unids_scaled[inlier_idx, 1], X_unids_scaled[inlier_idx, 2],\n",
    "    c='gold', edgecolor='k', s=30, label='Inlier (normal)', alpha=0.8\n",
    ")\n",
    "\n",
    "# Outliers (potential dark matter)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[outlier_idx, 0], X_unids_scaled[outlier_idx, 1], X_unids_scaled[outlier_idx, 2],\n",
    "    c='crimson', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('beta_Rel (scaled)')\n",
    "ax.set_title(\"3D Prediction Results on UNIDs\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Anomaly Scoring - UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_scores = best_model.decision_function(X_unids_scaled)  # Higher = more normal, lower = more anomalous\n",
    "\n",
    "unids_preds = best_model.predict(X_unids_scaled)  # 1 = inlier, -1 = outlier\n",
    "\n",
    "df_unids_log[\"svm_score\"] = decision_scores\n",
    "df_unids_log[\"prediction\"] = unids_preds\n",
    "\n",
    "anom_scores = -decision_scores  # Invert: higher = more anomalous\n",
    "anom_percent = MinMaxScaler(feature_range=(0, 100)).fit_transform(anom_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "df_unids_log[\"Anomaly_Score\"] = anom_scores\n",
    "df_unids_log[\"Anomaly_Rank(%)\"] = anom_percent\n",
    "\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "top_anomalies.to_csv(\"../../data/processed/unids_most_anomalous.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Top Most Anomalous UNID Sources (3F One-Class SVM):\")\n",
    "display(top_anomalies[['number', 'Anomaly_Score', 'Anomaly_Rank(%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaled values (for consistent comparison)\n",
    "X_unids = X_unids_scaled  # already scaled\n",
    "\n",
    "# Separate inliers and outliers\n",
    "inliers = X_unids[unids_preds == 1]\n",
    "outliers = X_unids[unids_preds == -1]\n",
    "\n",
    "# Get anomaly info\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Extract for plotting\n",
    "E_peak = X_unids[:, 0]\n",
    "beta = X_unids[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# All points\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (astro-like)', alpha=0.5)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (anomaly)', alpha=0.7)\n",
    "\n",
    "# Highlight & label top anomalies\n",
    "for idx in most_anomalous_idx:\n",
    "    x = X_unids[idx, 0]\n",
    "    y = X_unids[idx, 1]\n",
    "    source_id = df_unids_log.loc[idx, 'number']\n",
    "    \n",
    "    plt.scatter(x, y, facecolors='none', edgecolors='black', linewidths=1.5, s=100)\n",
    "    plt.text(x + 0.1, y, str(int(source_id)), color='black', fontsize=9)\n",
    "\n",
    "# Labels and layout\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"UNID Sources (3F w/betaRel) – Inliers vs Anomalies with ID Labels\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/scaled/3F_betaRel_UNIDs_OneClassSVM_2D_scaled.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Original/log-transformed values for 3 relevant features\n",
    "x_vals = df_unids_log['E_peak'].values\n",
    "y_vals = df_unids_log['beta'].values\n",
    "z_vals = df_unids_log['sigma_det'].values  # or 'beta_Rel' for 3F.2\n",
    "\n",
    "# Use model predictions for coloring\n",
    "inlier_idx = df_unids_log['prediction'] == 1\n",
    "outlier_idx = df_unids_log['prediction'] == -1\n",
    "\n",
    "# Inliers\n",
    "ax.scatter(\n",
    "    x_vals[inlier_idx], y_vals[inlier_idx], z_vals[inlier_idx],\n",
    "    c='#1f77b4', edgecolor='k', s=30, label='Inlier (astro-like)', alpha=0.5\n",
    ")\n",
    "\n",
    "# Outliers\n",
    "ax.scatter(\n",
    "    x_vals[outlier_idx], y_vals[outlier_idx], z_vals[outlier_idx],\n",
    "    c='#d62728', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "# Annotate top anomalies\n",
    "top_anomalies = df_unids_log[df_unids_log['prediction'] == -1].sort_values('Anomaly_Rank(%)', ascending=False).head(10)\n",
    "for idx in top_anomalies.index:\n",
    "    ax.scatter(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx],\n",
    "        facecolors='none', edgecolors='black', linewidths=2, s=100\n",
    "    )\n",
    "    ax.text(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx] + 0.05,\n",
    "        str(int(df_unids_log.loc[idx, 'number'])),\n",
    "        color='black', fontsize=9\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('E_peak')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_zlabel('sigma_det')  # or 'beta_Rel'\n",
    "ax.set_title(\"3F w/betaRel UNID Sources – Anomalies in Original Feature Space\")\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.tick_params(colors='#333333')\n",
    "ax.xaxis.label.set_color('#333333')\n",
    "ax.yaxis.label.set_color('#333333')\n",
    "ax.zaxis.label.set_color('#333333')\n",
    "ax.title.set_color('#111111')\n",
    "ax.grid(color='#aaaaaa', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/3F_betaRel_UNIDs_OneClassSVM_og.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top anomalies (already computed and sorted by anomaly rank)\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Prepare figure\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers (gold)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[inlier_idx, 0],\n",
    "    X_unids_scaled[inlier_idx, 1],\n",
    "    X_unids_scaled[inlier_idx, 2],\n",
    "    c='gold', edgecolor='k', s=30, label='Inlier (astro-like)', alpha=0.5\n",
    ")\n",
    "\n",
    "# Outliers (crimson)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[outlier_idx, 0],\n",
    "    X_unids_scaled[outlier_idx, 1],\n",
    "    X_unids_scaled[outlier_idx, 2],\n",
    "    c='crimson', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "# Annotate top anomalies\n",
    "for idx in most_anomalous_idx:\n",
    "    x = X_unids_scaled[idx, 0]\n",
    "    y = X_unids_scaled[idx, 1]\n",
    "    z = X_unids_scaled[idx, 2]\n",
    "    source_id = df_unids_log.loc[idx, 'number']\n",
    "\n",
    "    ax.scatter(x, y, z, facecolors='none', edgecolors='black', linewidths=2, s=100)\n",
    "    ax.text(x, y, z + 0.05, str(int(source_id)), color='black', fontsize=9)\n",
    "\n",
    "# Axes labels\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('sigma_det (scaled)')\n",
    "ax.set_title(\"UNID Sources (3F w/betaRel) – Inliers vs Anomalies with ID Labels\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.savefig(\"../../outputs/figures/scaled/3F_betaRel_UNIDs_OneClassSVM_3D_scaled_2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# Compare UNIDs most anomalous vs ANN most DM-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_unids_path = \"../ANN_4F/unids_DM_std_proba_check_repeated_kfold_rskf_4F_21.txt\"\n",
    "\n",
    "raw_ann_unids_data = np.genfromtxt(ann_unids_path, dtype='str')\n",
    "ann_unids_data = np.asarray(raw_ann_unids_data[1:], dtype=float)  # Salta cabecera\n",
    "n_samples = ann_unids_data.shape[1] - 1\n",
    "\n",
    "# Build DataFrame with probabilities per fold\n",
    "columns = ['number'] + [f'prob_{i}' for i in range(n_samples)]\n",
    "df_unids_ann = pd.DataFrame(ann_unids_data, columns=columns)\n",
    "\n",
    "# Average probabilities per UNID (group by number)\n",
    "df_mean_unids_ann = df_unids_ann.groupby('number').mean().reset_index()\n",
    "df_mean_unids_ann['prob_ann'] = df_mean_unids_ann[[f'prob_{i}' for i in range(n_samples)]].mean(axis=1)\n",
    "\n",
    "df_mean_unids_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 sources with the highest mean ANN DM probability\n",
    "top_ann_unids = df_mean_unids_ann.sort_values('prob_ann', ascending=False).head(50)\n",
    "\n",
    "# Display results\n",
    "print(\"🔝 Top 10 UNIDs with highest ANN-based DM probability:\")\n",
    "display(top_ann_unids[['number', 'prob_ann']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔝 Top 10 UNIDs with highest OCSVM-based anomaly scoring:\")\n",
    "display(top_anomalies[['number', 'Anomaly_Rank(%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 Data types before conversion:\")\n",
    "print(\"top_ann_unids['number'] dtype:\", top_ann_unids['number'].dtype)\n",
    "print(\"top_anomalies['number'] dtype:\", top_anomalies['number'].dtype)\n",
    "\n",
    "# Convert both to same type for comparison\n",
    "top_ann_unids['number'] = top_ann_unids['number'].round().astype(int)\n",
    "top_anomalies['number'] = top_anomalies['number'].round().astype(int)\n",
    "\n",
    "print(\"\\n🔍 Data types after conversion:\")\n",
    "print(\"top_ann_unids['number'] dtype:\", top_ann_unids['number'].dtype)\n",
    "print(\"top_anomalies['number'] dtype:\", top_anomalies['number'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ids = set(top_ann_unids['number']).intersection(set(top_anomalies['number']))\n",
    "print(f\"🎯 Common UNID IDs: {sorted(list(common_ids))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.merge(\n",
    "    top_ann_unids[['number', 'prob_ann']],\n",
    "    top_anomalies[['number', 'Anomaly_Rank(%)']],\n",
    "    on='number'\n",
    ")\n",
    "display(df_common)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
