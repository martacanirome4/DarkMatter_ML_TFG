{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de OneClassSVM entrenado con 2F de datos Astro, y predicción sobre datos Unid (no identificados)\n",
    "\n",
    "**Proyecto**: Detección de posibles fuentes de materia oscura usando ML en datos Fermi-LAT  \n",
    "**Autor**: Marta Canino Romero  \n",
    "**Fecha**: febrero-mayo 20225\n",
    "\n",
    "---\n",
    "\n",
    "## Descripción:\n",
    "\n",
    "Este notebook aplica un modelo **One-Class SVM** entrenado con datos de fuentes astrofísicas conocidas (ASTRO) usando las siguientes características:\n",
    "\n",
    "- E_peak\n",
    "- beta\n",
    "\n",
    "Este modelo se entrena para identificar anomalías que puedan corresponder a posibles fuentes de materia oscura (UNIDs) en los datos no identificados del catálogo 4FGL.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos específicos:\n",
    "\n",
    "- Entrenar modelo OCSVM con [número de features] \n",
    "- Optimizar hiperparámetros (grid search sobre `nu` y `gamma`)\n",
    "- Evaluar sobre datos de validación y prueba\n",
    "- Aplicar modelo final sobre datos UNID para predicción\n",
    "\n",
    "---\n",
    "\n",
    "## Entrada de datos:\n",
    "\n",
    "- `../../data/processed/XY_bal_log_Rel/astro/XY_bal_log_Rel_astro.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "\n",
    "# data_path = \"../../data/processed/XY_bal_log_Rel/astro/astro_df.txt\"\n",
    "data_path = '../../data/processed/XY_bal_log_Rel/astro/astro_data_with_labels.txt'\n",
    "# df_astro = pd.read_csv(data_path, sep='\\s+')\n",
    "df_astro = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# df_astro = df_astro.rename(columns={\"0,1=astro,DM\": \"class\"})\n",
    "# Comprobamos distribución del dataset\n",
    "print(f\" Dataset cargado. Forma: {df_astro.shape}\")\n",
    "print(f\" Nombres de las columnas: {list(df_astro.columns)}\")\n",
    "\n",
    "df_astro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características\n",
    "features = ['Log(E_peak)', 'Log(beta)']\n",
    "target = 'astro_DM'\n",
    "\n",
    "print(f\"Features seleccionadas: {features}\")\n",
    "print(f\"Columna objetivo: {target}\")\n",
    "\n",
    "# Comprobamos valores nulos\n",
    "print(\"\\n Valores faltantes por columna:\")\n",
    "print(df_astro[features + [target]].isnull().sum())\n",
    "\n",
    "print(\"\\n Muestra del dataset:\")\n",
    "display(df_astro[features + [target]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la distribución de los datos astro antes de escalar\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_astro,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"cornflowerblue\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "\n",
    "plt.title(\"ASTRO Data: Log(E_peak) vs Log(Beta)\")\n",
    "plt.xlabel(\"Log(E_peak)\")\n",
    "plt.ylabel(\"Log(beta)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_astro[features].values\n",
    "y = df_astro[target].values\n",
    "\n",
    "# SPLIT: Train / Val / Test\n",
    "# 60% train, 20% val, 20% test\n",
    "# de esta manera, el test set no se ve en el entrenamiento\n",
    "# y el val set se usa para ajustar los hiperparámetros)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Escalamos los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que los datos están bien escalados\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_train_scaled[:, 0],\n",
    "    y=X_train_scaled[:, 1],\n",
    "    color=\"cornflowerblue\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "plt.title(\"Scaled Train Data: Log(E_peak) vs Log(Beta)\")\n",
    "plt.xlabel(\"Log(E_peak)\")\n",
    "plt.ylabel(\"Log(beta)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetros a explorar\n",
    "nu_values = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05]\n",
    "# gamma_values = ['scale', 'auto'] + list(np.logspace(-4, 2, 7))\n",
    "# gamma_values = ['scale', 'auto', 0.001, 0.01, 0.1, 1, 10]\n",
    "# gamma_values = ['scale', 'auto'] + list(np.logspace(-3, 1, 5))\n",
    "gamma_values = [0.1]\n",
    "\n",
    "# Tracking\n",
    "results = []\n",
    "best_outliers = np.inf\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "print(\"Buscando hiperparámetros que minimicen outliers en ASTRO (validación)...\")\n",
    "\n",
    "for nu in nu_values:\n",
    "    for gamma in gamma_values:\n",
    "        model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "        model.fit(X_train_scaled)\n",
    "\n",
    "        preds_val = model.predict(X_val_scaled)  # 1 = normal, -1 = outlier\n",
    "        pred_labels = np.where(preds_val == 1, 0, 1)         # Mapear a 0 = normal, 1 = anomalía\n",
    "        true_labels = y_val.astype(int)                  # Aseguramos tipo int\n",
    "        n_outliers = np.sum(preds_val == -1)\n",
    "        # f1 = f1_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "        results.append({'nu': nu, 'gamma': gamma, 'val_outliers': n_outliers})\n",
    "\n",
    "        \"\"\"\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "        \"\"\"\n",
    "        if n_outliers < best_outliers:\n",
    "            best_outliers = n_outliers\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "\n",
    "# Mostrar resultado óptimo\n",
    "print(f\"\\n Mejor combinación de hiperparámetros:\")\n",
    "print(f\"   - ν = {best_params['nu']}\")\n",
    "print(f\"   - γ = {best_params['gamma']}\")\n",
    "print(f\"Outliers (val set): {best_outliers} de {len(X_val_scaled)} muestras\")\n",
    "\n",
    "# Convertir a DataFrame si quieres visualizar todo el grid\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results.sort_values(by='val_outliers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "val_preds = best_model.predict(X_val_scaled)\n",
    "n_val_outliers = np.sum(val_preds == -1)\n",
    "print(f\"Outliers (val set): {n_val_outliers} de {len(X_val_scaled)} muestras\")\n",
    "\n",
    "# Evaluar el modelo en el conjunto de test\n",
    "# (no se ha visto en el entrenamiento)\n",
    "test_preds = best_model.predict(X_test_scaled)\n",
    "n_test_outliers = np.sum(test_preds == -1)\n",
    "print(f\"Outliers (test set): {n_test_outliers} de {len(X_test_scaled)} muestras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.decision_function(X_val_scaled)\n",
    "\n",
    "sns.histplot(scores, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Colores mejorados\n",
    "palette = {\n",
    "    1: '#264653',   # ASTRO normal (azul petróleo)\n",
    "    -1: '#76b7b2'   # ASTRO outlier (azul claro)\n",
    "}\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_test_scaled[:, 0],\n",
    "    y=X_test_scaled[:, 1],\n",
    "    hue=test_preds,\n",
    "    palette=palette,\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=50,\n",
    "    marker='o'\n",
    ")\n",
    "\n",
    "plt.title(\"Predicción sobre datos ASTRO (test) – OCSVM\", fontsize=14)\n",
    "plt.xlabel(\"Log(E_peak)\", fontsize=12)\n",
    "plt.ylabel(\"Log(beta)\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.4)\n",
    "plt.legend(\n",
    "    title=\"Predicción\",\n",
    "    loc='upper right',\n",
    "    labels=[\"Normal (ASTRO)\", \"Anomalía (ASTRO)\"],\n",
    "    fontsize=10\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid (with correct feature order)\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_train_scaled[:, 0].min() - 0.5, X_train_scaled[:, 0].max() + 0.5, 300),  # E_peak\n",
    "    np.linspace(X_train_scaled[:, 1].min() - 0.5, X_train_scaled[:, 1].max() + 0.5, 300)   # beta\n",
    ")\n",
    "\n",
    "# xx = E_peak\n",
    "# yy = beta\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = best_model.decision_function(grid)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu_r, alpha=0.8)\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='crimson', linestyles='--')\n",
    "\n",
    "# Plot training and test data\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], c='skyblue', edgecolors='k', s=40, label='Train')\n",
    "plt.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], c='orchid', edgecolors='k', s=30, label='Test')\n",
    "# plt.scatter(X_val_scaled[:, 1], X_val_scaled[:, 0], c='magenta', edgecolors='k', s=30, label='Val')\n",
    "\n",
    "plt.xlabel(\"Log(E_peak) (scaled)\")\n",
    "plt.ylabel(\"Log(beta) (scaled)\")\n",
    "plt.title(\"Best One-Class SVM Decision Boundary\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unids_path = \"../../data/raw/unids_3F_beta_err_names.txt\"\n",
    "# unids_path = \"../../data/processed/unids_log/unids_log.txt\"\n",
    "unids_path = \"../../data/processed/unids_log/unids_transformed_complete.txt\"\n",
    "\n",
    "# df_unids = pd.read_csv(unids_path, sep='\\s+')\n",
    "df_unids = pd.read_csv(unids_path, sep='\\t')\n",
    "df_unids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer y escalar \n",
    "X_unids_log = df_unids[[\"Log(E_peak)\", \"Log(beta)\"]].values\n",
    "X_unids_scaled = scaler.transform(X_unids_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create subplots ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6), sharey=True)\n",
    "\n",
    "# --- Plot 1: Raw UNIDS data ---\n",
    "sns.scatterplot(\n",
    "    data=df_unids,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"UNIDS Data: E_peak vs Beta\")\n",
    "axes[0].set_xlabel(\"Log(E_peak)\")\n",
    "axes[0].set_ylabel(\"Log(beta)\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Plot 2: Scaled UNIDS ---\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Scaled UNIDS: E_peak vs Beta\")\n",
    "axes[1].set_xlabel(\"Log(E_peak) (scaled)\")\n",
    "axes[1].set_ylabel(\"Log(beta) (scaled)\")\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir sobre unids usando el mejor modelo\n",
    "# preds_non_astro = best_model.predict(X_unids_scaled)\n",
    "unids_preds = best_model.predict(X_unids_scaled)\n",
    "\n",
    "n_outliers = np.sum(unids_preds == -1)\n",
    "n_normals = np.sum(unids_preds == 1)\n",
    "\n",
    "print(f\"Predicted ASTRO-like: {n_normals}\")\n",
    "print(f\"Predicted not ASTRO-like (anomalies): {n_outliers}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers = X_unids_scaled[unids_preds == 1]\n",
    "outliers = X_unids_scaled[unids_preds == -1]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (likely astro)', alpha=0.6)\n",
    "plt.scatter(outliers[:, 0], outliers[:,1], c='red', edgecolors='k', label='Outlier (potentially new)', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"Log(E_peak) (scaled)\")\n",
    "plt.ylabel(\"Log(beta) (scaled)\")\n",
    "plt.title(\"UNIDs: Inlier vs Outlier (One-Class SVM)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create meshgrid (with correct feature order: [beta, E_peak])\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_train_scaled[:, 0].min() - 0.5, X_train_scaled[:, 0].max() + 0.5, 300),  # E_peak\n",
    "    np.linspace(X_train_scaled[:, 1].min() - 0.5, X_train_scaled[:, 1].max() + 0.5, 300)   # beta\n",
    ")\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "Z = best_model.decision_function(grid)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.PuBu_r, alpha=0.8)\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='crimson', linestyles='--')\n",
    "\n",
    "preds_unids = best_model.predict(X_unids_scaled)\n",
    "inliers = X_unids_scaled[preds_unids == 1]\n",
    "outliers = X_unids_scaled[preds_unids == -1]\n",
    "\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', s=40, label='UNIDs Inlier')\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', s=40, label='UNIDs Outlier')\n",
    "\n",
    "# Highlight most anomalous UNIDs using their lowest decision score:\n",
    "decision_scores = best_model.decision_function(X_unids_scaled)\n",
    "# Optional: mark top 5 most anomalous\n",
    "top_anomalies = X_unids_scaled[np.argsort(decision_scores)[:5]]\n",
    "plt.scatter(top_anomalies[:, 0], top_anomalies[:, 1], c='yellow', edgecolors='black', s=80, label='Top Outliers', marker='*')\n",
    "\n",
    "\n",
    "# Plot training and test data\n",
    "# plt.scatter(X_train_scaled[:, 1], X_train_scaled[:, 0], c='skyblue', edgecolors='k', s=40, label='ASTRO (Train)')\n",
    "# plt.scatter(X_unids_scaled[:, 1], X_unids_scaled[:, 0], c='orchid', edgecolors='k', s=40, label='Test')\n",
    "# plt.scatter(X_unids_scaled[:, 1], X_unids_scaled[:, 0], c='tomato', edgecolors='k', s=40, label='UNIDs')\n",
    "\n",
    "\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"Predictions on UNIDs with One-Class SVM Decision Boundary\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Scoring - UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar cada muestra no identificada con el modelo entrenado\n",
    "# decision_function devuelve un valor continuo: cuanto más alto, más normal (positivo); cuanto más bajo, más anómalo (negativo)\n",
    "decision_scores = best_model.decision_function(X_unids_scaled)  # X_unids_scaled = muestras no etiquetadas, ya escaladas\n",
    "\n",
    "#Predecir si cada punto es inlier (1) o outlier (-1)\n",
    "unids_preds = best_model.predict(X_unids_scaled)  # 1 = normal, -1 = anomalía\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(decision_scores, bins=30, kde=True)\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.title('Distribución del score de anormalidad (UNIDs)')\n",
    "plt.xlabel('Score de anomalía (OCSVM)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_unids['Anomaly_score'] = decision_scores\n",
    "top_anomalous = df_unids.sort_values('Anomaly_score').head(10)\n",
    "display(top_anomalous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_combined = np.vstack((X_train_scaled, X_unids_scaled))\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "\"\"\" Visualizar PCA\n",
    "Esto divide el resultado transformado (X_pca) en dos bloques:\n",
    "uno para ASTRO, otro para UNIDs, pero ambos ya están proyectados con el mismo PCA\"\"\"\n",
    "astro_pca = X_pca[:len(X_train_scaled)]\n",
    "unids_pca = X_pca[len(X_train_scaled):]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(astro_pca[:,0], astro_pca[:,1], alpha=0.5, label='ASTRO')\n",
    "plt.scatter(unids_pca[:,0], unids_pca[:,1], c=decision_scores, cmap='coolwarm', label='UNIDs', edgecolor='k')\n",
    "plt.colorbar(label='Score de anomalía')\n",
    "plt.title('PCA - ASTRO vs UNIDs (OCSVM)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Agregar los resultados al DataFrame original\n",
    "df_unids[\"svm_score\"] = decision_scores       # Puntaje bruto del modelo (positivo = normal)\n",
    "df_unids[\"prediction\"] = unids_preds          # Clasificación binaria: inlier o outlier\n",
    "\n",
    "# Invertimos el score para que valores más altos signifiquen más anomalía\n",
    "# Esto es útil para poder escalar la puntuación y ordenar más intuitivamente\n",
    "anom_scores = -decision_scores  # Ahora, valores grandes = más anómalos\n",
    "\n",
    "# Escalamos los scores de anomalía al rango [0, 100] para facilitar su interpretación\n",
    "anom_percent = MinMaxScaler(feature_range=(0, 100)).fit_transform(anom_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Guardamos el puntaje invertido y su porcentaje normalizado en el DataFrame\n",
    "df_unids[\"(-)Anomaly_Score\"] = anom_scores\n",
    "df_unids[\"Anomaly_Rank(%)\"] = anom_percent  # 100 = más anómalo, 0 = más normal\n",
    "\n",
    "# Paso 6: Filtramos solo los puntos predichos como anómalos y los ordenamos por su score más alto\n",
    "top_anomalies = df_unids[df_unids[\"prediction\"] == -1] \\\n",
    "                    .sort_values(by=\"Anomaly_Rank(%)\", ascending=False) \\\n",
    "                    .head(10)\n",
    "\n",
    "# Guardamos los índices (puede ser útil si queremos recuperar sus posiciones originales)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Paso 7: Guardamos los 10 más anómalos en un archivo\n",
    "top_anomalies.to_csv(\"../../data/processed/unids_most_anomalous_2F.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Paso 8: Mostramos en pantalla un resumen de las anomalías detectadas\n",
    "print(\"Top Most Anomalous UNID Sources (4F One-Class SVM):\")\n",
    "display(top_anomalies[['number', 'svm_score', 'Anomaly_score', '(-)Anomaly_Score', 'Anomaly_Rank(%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sort anomaly scores and grab top N labels\n",
    "N = 10\n",
    "sorted_idx = np.argsort(-anom_percent)  # high anomaly % = more anomalous\n",
    "top_N_idx = sorted_idx[:N]\n",
    "\n",
    "top_labels = df_unids.iloc[top_N_idx]['number'].astype(str).values\n",
    "top_scores = anom_percent[top_N_idx]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(anom_percent, bins=50, color='blue', edgecolor='k', alpha=0.7)\n",
    "plt.title(\"Anomaly Percentage Distribution (UNID Sources)\")\n",
    "plt.xlabel(\"Anomaly % (higher = more anomalous)\")\n",
    "plt.ylabel(\"Number of Sources\")\n",
    "\n",
    "for i in range(N):\n",
    "    x = top_scores[i]\n",
    "    label = top_labels[i]\n",
    "    plt.axvline(x, color='crimson', linestyle='--', alpha=0.8)\n",
    "    plt.text(x + 0.5, 3 + (i % 2) * 2, f\"ID {label}\", rotation=90, color='crimson', ha='left', fontsize=9)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Inliers and outliers from scaled data\n",
    "inliers = X_unids_scaled[unids_preds == 1]\n",
    "outliers = X_unids_scaled[unids_preds == -1]\n",
    "\n",
    "# Plot inliers (gold)\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (astro-like)', alpha=0.6)\n",
    "\n",
    "# Plot outliers (red)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (anomalous)', alpha=0.6)\n",
    "\n",
    "# Annotate top 10 anomalies by ID\n",
    "for idx in most_anomalous_idx:\n",
    "    x = X_unids_scaled[idx, 0]  # E_peak (scaled)\n",
    "    y = X_unids_scaled[idx, 1]  # beta (scaled)\n",
    "    label = int(df_unids.loc[idx, 'number'])\n",
    "    plt.text(x + 0.1, y, str(label), color='black', fontsize=9)\n",
    "\n",
    "# Axis labels and styling\n",
    "plt.xlabel(\"Log(E_peak) (scaled)\")\n",
    "plt.ylabel(\"Log(beta) (scaled)\")\n",
    "plt.title(\"UNID Sources (2F) – Inliers vs Anomalies with ID Labels\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/scaled/2F_UNIDs_OneClassSVM_2D_scaled.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Original/log-transformed values for 3 relevant features\n",
    "x_vals = df_unids['Log(E_peak)'].values\n",
    "y_vals = df_unids['Log(beta)'].values\n",
    "z_vals = df_unids['Log(sigma)'].values  # or 'Log(beta_Rel)' for 3F.2\n",
    "\n",
    "# Use model predictions for coloring\n",
    "inlier_idx = df_unids['prediction'] == 1\n",
    "outlier_idx = df_unids['prediction'] == -1\n",
    "\n",
    "# Inliers\n",
    "ax.scatter(\n",
    "    x_vals[inlier_idx], y_vals[inlier_idx], z_vals[inlier_idx],\n",
    "    c='#1f77b4', edgecolor='k', s=30, label='Inlier (astro-like)', alpha=0.5\n",
    ")\n",
    "\n",
    "# Outliers\n",
    "ax.scatter(\n",
    "    x_vals[outlier_idx], y_vals[outlier_idx], z_vals[outlier_idx],\n",
    "    c='#d62728', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "# Annotate top anomalies\n",
    "top_anomalies = df_unids[df_unids['prediction'] == -1].sort_values('Anomaly_Rank(%)', ascending=False).head(10)\n",
    "for idx in top_anomalies.index:\n",
    "    ax.scatter(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx],\n",
    "        facecolors='none', edgecolors='black', linewidths=2, s=100\n",
    "    )\n",
    "    ax.text(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx] + 0.05,\n",
    "        str(int(df_unids.loc[idx, 'number'])),\n",
    "        color='black', fontsize=9\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Log(E_peak)')\n",
    "ax.set_ylabel('Log(beta)')\n",
    "ax.set_zlabel('Log(sigma)')  # or 'Log(beta_Rel)' for 3F.2\n",
    "ax.set_title(\"2F UNID Sources – Anomalies in Original Feature Space\")\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.tick_params(colors='#333333')\n",
    "ax.xaxis.label.set_color('#333333')\n",
    "ax.yaxis.label.set_color('#333333')\n",
    "ax.zaxis.label.set_color('#333333')\n",
    "ax.title.set_color('#111111')\n",
    "ax.grid(color='#aaaaaa', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/2F_UNIDs_OneClassSVM_og.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar con UNIDs ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process supervised model predictions\n",
    "print(\"Loading supervised model predictions...\")\n",
    "\n",
    "# Load predictions data\n",
    "unids_DM_std_proba_repeated_kfold = np.genfromtxt('../../ANN_original/unids_DM_std_proba_check_repeated_kfold_2F_21.txt', dtype='str') \n",
    "unids_DM_std_proba_data_repeated_kfold = np.asarray(unids_DM_std_proba_repeated_kfold[1::], dtype=float)\n",
    "\n",
    "print(f\"Raw predictions shape: {unids_DM_std_proba_data_repeated_kfold.shape}\")\n",
    "\n",
    "# Get dimensions\n",
    "# Load unID source data\n",
    "unids_3F = np.genfromtxt('../../ANN_original/unids_3F_beta_err_names.txt',dtype='str') \n",
    "unids_3F_data = np.asarray(unids_3F[1::,:],dtype=float)\n",
    "unids_log=np.log10(unids_3F_data[:,[0,1]])\n",
    "N_unids = unids_log.shape[0]\n",
    "# N_sample = unids_DM_std_proba_data_repeated_kfold.shape[1] - 1  # CV folds\n",
    "N_sample = 10\n",
    "\n",
    "print(f\"Number of sources: {N_unids}\")\n",
    "print(f\"Number of CV folds: {N_sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract indices and reshape probabilities\n",
    "unids_number = unids_DM_std_proba_data_repeated_kfold[0:N_unids, 0]\n",
    "prob_values = unids_DM_std_proba_data_repeated_kfold[:, 1].reshape(N_unids, N_sample)\n",
    "\n",
    "# Create probability matrix\n",
    "unids_DM_std_proba_N_sample_repeated_kfold = np.zeros((N_unids, N_sample + 1))\n",
    "unids_DM_std_proba_N_sample_repeated_kfold[:, 0] = unids_number[:].astype(int)\n",
    "unids_DM_std_proba_N_sample_repeated_kfold[:, 1:(N_sample + 1)] = prob_values\n",
    "\n",
    "print(f\"Probability matrix shape: {unids_DM_std_proba_N_sample_repeated_kfold.shape}\")\n",
    "print(\"Sample of probability matrix:\")\n",
    "print(unids_DM_std_proba_N_sample_repeated_kfold[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probability data (excluding index column)\n",
    "prob_data = unids_DM_std_proba_N_sample_repeated_kfold[:, 1:(N_sample + 1)]\n",
    "\n",
    "# Calculate statistics across CV folds\n",
    "unids_mean = np.mean(prob_data, axis=1)\n",
    "unids_std = np.std(prob_data, axis=1)\n",
    "unids_median = np.median(prob_data, axis=1)\n",
    "\n",
    "unids_min = np.min(prob_data, axis=1)\n",
    "unids_max = np.max(prob_data, axis=1)\n",
    "\n",
    "unids_q25 = np.percentile(prob_data, 25, axis=1)\n",
    "unids_q75 = np.percentile(prob_data, 75, axis=1)\n",
    "\n",
    "print(\"Supervised model statistics calculated:\")\n",
    "print(f\"  Mean probability range: {unids_mean.min():.4f} - {unids_mean.max():.4f}\")\n",
    "print(f\"  Standard deviation range: {unids_std.min():.4f} - {unids_std.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create supervised model DataFrame\n",
    "supervised_df = pd.DataFrame({\n",
    "    'source_id': unids_number.astype(int),\n",
    "    'supervised_mean_prob': unids_mean,\n",
    "    'supervised_std_prob': unids_std,\n",
    "    'supervised_median_prob': unids_median,\n",
    "    'supervised_min_prob': unids_min,\n",
    "    'supervised_max_prob': unids_max,\n",
    "    'supervised_q25': unids_q25,\n",
    "    'supervised_q75': unids_q75,\n",
    "    'supervised_cv_range': unids_max - unids_min,\n",
    "    'E_peak': unids_3F_data[:, 0],\n",
    "    'Beta': unids_3F_data[:, 1],\n",
    "    'log_E_peak': unids_log[:, 0],\n",
    "    'log_Beta': unids_log[:, 1]\n",
    "})\n",
    "\n",
    "print(f\"Supervised DataFrame created with {len(supervised_df)} sources\")\n",
    "print(\"\\nSupervised model top 10 candidates:\")\n",
    "display(supervised_df.nlargest(10, 'supervised_mean_prob')[['source_id', 'supervised_mean_prob', 'supervised_std_prob', 'E_peak', 'Beta']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with OCSVM results\n",
    "print(\"Merging supervised and OCSVM results...\")\n",
    "\n",
    "# Check available columns in OCSVM DataFrame\n",
    "print(\"OCSVM DataFrame columns:\", df_unids.columns.tolist())\n",
    "\n",
    "# Merge datasets - adjust merge column as needed\n",
    "if 'number' in df_unids.columns:\n",
    "    combined_df = pd.merge(supervised_df, df_unids, left_on='source_id', right_on='number', how='inner')\n",
    "elif 'source_id' in df_unids.columns:\n",
    "    combined_df = pd.merge(supervised_df, df_unids, on='source_id', how='inner')\n",
    "else:\n",
    "    # If no common key, merge by index (assuming same order)\n",
    "    print(\"Warning: No common identifier found, merging by index\")\n",
    "    combined_df = pd.concat([supervised_df.reset_index(drop=True), \n",
    "                           df_unids.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(f\"Combined dataset shape: {combined_df.shape}\")\n",
    "print(f\"Combined dataset columns: {combined_df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model correlations\n",
    "print(\"Calculating model correlations...\")\n",
    "\n",
    "# Check if required columns exist\n",
    "required_cols = ['supervised_mean_prob', 'Anomaly_Rank(%)']\n",
    "missing_cols = [col for col in required_cols if col not in combined_df.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"Error: Missing columns {missing_cols}\")\n",
    "    print(\"Available columns:\", combined_df.columns.tolist())\n",
    "else:\n",
    "    # Calculate correlations\n",
    "\n",
    "    # Correlación de Pearson: Mide si hay una relación lineal entre los dos modelos\n",
    "    corr_pearson, p_pearson = pearsonr(combined_df['supervised_mean_prob'], \n",
    "                                      combined_df['Anomaly_Rank(%)'])\n",
    "    \n",
    "    # Correlación de Spearman: Mide si hay una relación de orden (si uno sube, el otro también)\n",
    "    corr_spearman, p_spearman = spearmanr(combined_df['supervised_mean_prob'], \n",
    "                                         combined_df['Anomaly_Rank(%)'])\n",
    "    \n",
    "    \"\"\" CÓMO INTERPRETAR LA CORRELACIÓN:\n",
    "        +1: Correlación perfecta positiva (cuando uno sube, el otro también)\n",
    "        0: No hay relación\n",
    "        -1: Correlación perfecta negativa (cuando uno sube, el otro baja)\n",
    "\n",
    "        Correlación baja (0 a +0.3): Los modelos ven cosas diferentes, pueden ser complementarios\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nMODEL CORRELATION RESULTS:\")\n",
    "    print(f\"  Pearson correlation: {corr_pearson:.4f} (p-value: {p_pearson:.4e})\")\n",
    "    print(f\"  Spearman correlation: {corr_spearman:.4f} (p-value: {p_spearman:.4e})\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if abs(corr_spearman) > 0.7:\n",
    "        print(\"  → Strong correlation between models\")\n",
    "    elif abs(corr_spearman) > 0.4:\n",
    "        print(\"  → Moderate correlation between models\")\n",
    "    else:\n",
    "        print(\"  → Weak correlation between models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALISIS DE SOLAPAMIENTO\n",
    "# Analyze top candidates overlap\n",
    "top_n = 20\n",
    "print(f\"\\nAnalyzing top {top_n} candidates from each model...\")\n",
    "\n",
    "# Get top candidates from each model\n",
    "top_supervised = combined_df.nlargest(top_n, 'supervised_mean_prob')\n",
    "top_anomalous = combined_df.nlargest(top_n, 'Anomaly_Rank(%)')\n",
    "\n",
    "# Find overlap\n",
    "supervised_ids = set(top_supervised.index)\n",
    "anomaly_ids = set(top_anomalous.index)\n",
    "overlap_ids = supervised_ids.intersection(anomaly_ids)\n",
    "\n",
    "# Calculate overlap metrics\n",
    "total_overlap = len(overlap_ids)\n",
    "overlap_percentage = total_overlap / top_n * 100 # Porcentaje de solapamiento: ¿Qué porcentaje de los top 20 de cada modelo coinciden?\n",
    "jaccard_index = total_overlap / len(supervised_ids.union(anomaly_ids)) # Índice de Jaccard: Una medida más rigurosa de similitud entre conjuntos\n",
    "\n",
    "\"\"\" \n",
    "    Solapamiento 80-100%: Los modelos están muy de acuerdo\n",
    "    Solapamiento 50-80%: Acuerdo moderado\n",
    "    Solapamiento <50%: Los modelos ven cosas muy diferentes\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nTOP {top_n} CANDIDATES OVERLAP:\")\n",
    "print(f\"  Sources in both top {top_n}: {total_overlap}\")\n",
    "print(f\"  Overlap percentage: {overlap_percentage:.1f}%\")\n",
    "print(f\"  Jaccard similarity index: {jaccard_index:.4f}\")\n",
    "\n",
    "# Show overlapping candidates\n",
    "if total_overlap > 0:\n",
    "    overlap_sources = combined_df.loc[list(overlap_ids)]\n",
    "    print(f\"\\nCONSENSUS CANDIDATES (in both top {top_n}):\")\n",
    "    display_cols = ['source_id', 'supervised_mean_prob', 'Anomaly_Rank(%)', 'F_peak', 'Beta']\n",
    "    available_cols = [col for col in display_cols if col in overlap_sources.columns]\n",
    "    display(overlap_sources[available_cols].round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create consensus ranking\n",
    "print(\"Creating consensus ranking...\")\n",
    "\n",
    "# Normalize scores to [0, 1] range\n",
    "supervised_norm = MinMaxScaler().fit_transform(\n",
    "    combined_df['supervised_mean_prob'].values.reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "ocsvm_norm = combined_df['Anomaly_Rank(%)'] / 100\n",
    "\n",
    "# Create weighted consensus score (adjust weights as needed)\n",
    "\"\"\" PUNTUACIÓN DE CONSENSO:\n",
    "    - Combina ambos modelos en una sola puntuación\n",
    "    - Los pesos (0.6 y 0.4) indican cuánto confías en cada modelo\n",
    "\n",
    "    NOS DA:\n",
    "    - Candidatos robustos: Fuentes que ambos modelos consideran interesantes\n",
    "    - Ranking único: Una lista ordenada combinando ambos enfoques\n",
    "\"\"\"\n",
    "weights = {'supervised': 0.5, 'ocsvm': 0.5}\n",
    "consensus_score = (weights['supervised'] * supervised_norm + \n",
    "                  weights['ocsvm'] * ocsvm_norm)\n",
    "\n",
    "# Add consensus columns to DataFrame\n",
    "combined_df['supervised_norm'] = supervised_norm\n",
    "combined_df['ocsvm_norm'] = ocsvm_norm\n",
    "combined_df['consensus_score'] = consensus_score\n",
    "combined_df['consensus_rank'] = combined_df['consensus_score'].rank(ascending=False, method='dense')\n",
    "\n",
    "print(f\"Consensus ranking created with weights: {weights}\")\n",
    "print(f\"Consensus score range: {consensus_score.min():.4f} - {consensus_score.max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top consensus candidates\n",
    "print(\"\\nTOP 15 CONSENSUS DARK MATTER CANDIDATES:\")\n",
    "\n",
    "# Sort by consensus score and display\n",
    "consensus_top = combined_df.sort_values('consensus_score', ascending=False)\n",
    "\n",
    "display_cols = ['source_id', 'consensus_rank', 'consensus_score', \n",
    "               'supervised_mean_prob', 'supervised_std_prob', \n",
    "               'Anomaly_Rank(%)', 'E_peak', 'Beta']\n",
    "available_display_cols = [col for col in display_cols if col in consensus_top.columns]\n",
    "\n",
    "display(consensus_top[available_display_cols].head(15).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualizations\n",
    "print(\"Creating comparison visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Scatter plot: Supervised prob vs Anomaly rank\n",
    "axes[0, 0].scatter(combined_df['supervised_mean_prob'], \n",
    "                  combined_df['Anomaly_Rank(%)'], \n",
    "                  alpha=0.6, s=40, c='blue')\n",
    "axes[0, 0].set_xlabel('Supervised Model Probability')\n",
    "axes[0, 0].set_ylabel('OCSVM Anomaly Rank (%)')\n",
    "axes[0, 0].set_title('Supervised vs OCSVM Scores')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add correlation text\n",
    "axes[0, 0].text(0.05, 0.95, \n",
    "               f\"Pearson: {corr_pearson:.3f}\\\\nSpearman: {corr_spearman:.3f}\",\n",
    "               transform=axes[0, 0].transAxes, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# 2. Distribution comparison\n",
    "axes[0, 1].hist(combined_df['supervised_mean_prob'], bins=30, alpha=0.7, \n",
    "               label='Supervised Prob', density=True, color='blue')\n",
    "axes[0, 1].hist(combined_df['Anomaly_Rank(%)']/100, bins=30, alpha=0.7, \n",
    "               label='OCSVM Anomaly Rank', density=True, color='red')\n",
    "axes[0, 1].set_xlabel('Score')\n",
    "axes[0, 1].set_ylabel('Density')\n",
    "axes[0, 1].set_title('Score Distributions')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Consensus score distribution\n",
    "axes[0, 2].hist(combined_df['consensus_score'], bins=30, alpha=0.7, \n",
    "               color='green', edgecolor='black')\n",
    "axes[0, 2].set_xlabel('Consensus Score')\n",
    "axes[0, 2].set_ylabel('Count')\n",
    "axes[0, 2].set_title('Consensus Score Distribution')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature space with supervised model coloring\n",
    "scatter1 = axes[1, 0].scatter(combined_df['E_peak'], combined_df['Beta'], \n",
    "                            c=combined_df['supervised_mean_prob'], \n",
    "                            cmap='viridis', alpha=0.7, s=40)\n",
    "axes[1, 0].set_xlabel('E_peak')\n",
    "axes[1, 0].set_ylabel('Beta')\n",
    "axes[1, 0].set_title('Feature Space (Supervised Prob)')\n",
    "axes[1, 0].set_xscale('log')\n",
    "axes[1, 0].set_yscale('log')\n",
    "plt.colorbar(scatter1, ax=axes[1, 0])\n",
    "\n",
    "# 5. Feature space with OCSVM colorin\n",
    "scatter2 = axes[1, 1].scatter(combined_df['E_peak'], combined_df['Beta'], \n",
    "                            c=combined_df['Anomaly_Rank(%)'], \n",
    "                            cmap='plasma', alpha=0.7, s=40)\n",
    "axes[1, 1].set_xlabel('E_peak')\n",
    "axes[1, 1].set_ylabel('Beta')\n",
    "axes[1, 1].set_title('Feature Space (OCSVM Anomaly)')\n",
    "axes[1, 1].set_xscale('log')\n",
    "axes[1, 1].set_yscale('log')\n",
    "plt.colorbar(scatter2, ax=axes[1, 1])\n",
    "\n",
    "# 6. Feature space with consensus coloring\n",
    "scatter3 = axes[1, 2].scatter(combined_df['E_peak'], combined_df['Beta'], \n",
    "                            c=combined_df['consensus_score'], \n",
    "                            cmap='coolwarm', alpha=0.7, s=40)\n",
    "axes[1, 2].set_xlabel('E_peak')\n",
    "axes[1, 2].set_ylabel('Beta')\n",
    "axes[1, 2].set_title('Feature Space (Consensus Score)')\n",
    "axes[1, 2].set_xscale('log')\n",
    "axes[1, 2].set_yscale('log')\n",
    "plt.colorbar(scatter3, ax=axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model agreement analysis\n",
    "print(\"\\nAnalyzing model agreement across score ranges...\")\n",
    "\n",
    "# Create score bins for agreement analysis\n",
    "supervised_bins = pd.cut(combined_df['supervised_mean_prob'], \n",
    "                        bins=5, labels=['Low', 'Med-Low', 'Med', 'Med-High', 'High'])\n",
    "anomaly_bins = pd.cut(combined_df['Anomaly_Rank(%)'], \n",
    "                     bins=5, labels=['Low', 'Med-Low', 'Med', 'Med-High', 'High'])\n",
    "\n",
    "# Create agreement matrix\n",
    "\"\"\" \n",
    "MATRIZ DE ACUERDO:\n",
    "\n",
    "    * Ve dónde están de acuerdo los modelos según rangos de puntuación\n",
    "    * Identifica patrones de desacuerdo\n",
    "\n",
    "    - Filas: Modelos supervisados\n",
    "    - Columnas: OCSVM\n",
    "    - Celdas: Número de fuentes en cada combinación de categorías\n",
    "\n",
    "    + Diagonal alta: Los modelos están de acuerdo\n",
    "    + Valores dispersos: Los modelos ven cosas diferentes\n",
    "    + Esquinas opuestas: Desacuerdo total\n",
    "\"\"\"\n",
    "agreement_matrix = pd.crosstab(supervised_bins, anomaly_bins, margins=True)\n",
    "print(\"\\nModel Agreement Matrix:\")\n",
    "print(\"(Rows: Supervised Model, Columns: OCSVM)\")\n",
    "display(agreement_matrix)\n",
    "\n",
    "# Plot agreement heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(agreement_matrix.iloc[:-1, :-1], annot=True, fmt='d', \n",
    "            cmap='Blues', cbar_kws={'label': 'Number of Sources'})\n",
    "plt.xlabel('OCSVM Anomaly Level')\n",
    "plt.ylabel('Supervised Model Probability Level')\n",
    "plt.title('Model Agreement Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics and final report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DARK MATTER CANDIDATE MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDATASET OVERVIEW:\")\n",
    "print(f\"  Total sources analyzed: {len(combined_df)}\")\n",
    "print(f\"  Supervised model probability range: {combined_df['supervised_mean_prob'].min():.4f} - {combined_df['supervised_mean_prob'].max():.4f}\")\n",
    "print(f\"  OCSVM anomaly rank range: {combined_df['Anomaly_Rank(%)'].min():.1f}% - {combined_df['Anomaly_Rank(%)'].max():.1f}%\")\n",
    "print(f\"  Consensus score range: {combined_df['consensus_score'].min():.4f} - {combined_df['consensus_score'].max():.4f}\")\n",
    "\n",
    "print(f\"\\nMODEL PERFORMANCE:\")\n",
    "print(f\"  Cross-validation folds used: {N_sample}\")\n",
    "print(f\"  Mean supervised model uncertainty: {combined_df['supervised_std_prob'].mean():.4f}\")\n",
    "print(f\"  Sources with high confidence (>90%): {sum(combined_df['supervised_mean_prob'] > 0.9)}\")\n",
    "print(f\"  Sources with low uncertainty (<10%): {sum(combined_df['supervised_std_prob'] < 0.1)}\")\n",
    "\n",
    "print(f\"\\nMODEL AGREEMENT:\")\n",
    "print(f\"  Pearson correlation: {corr_pearson:.4f}\")\n",
    "print(f\"  Spearman correlation: {corr_spearman:.4f}\")\n",
    "print(f\"  Top {top_n} overlap: {total_overlap} sources ({overlap_percentage:.1f}%)\")\n",
    "print(f\"  Jaccard similarity: {jaccard_index:.4f}\")\n",
    "\n",
    "# Identify most promising candidates\n",
    "high_consensus = combined_df[combined_df['consensus_score'] > 0.8]\n",
    "print(f\"\\nHIGH-CONFIDENCE CONSENSUS CANDIDATES:\")\n",
    "print(f\"  Sources with consensus score >0.8: {len(high_consensus)}\")\n",
    "\n",
    "if len(high_consensus) > 0:\n",
    "    print(\"\\nTop 5 highest consensus candidates:\")\n",
    "    top_consensus_cols = ['source_id', 'consensus_score', 'supervised_mean_prob', 'Anomaly_Rank(%)']\n",
    "    available_consensus_cols = [col for col in top_consensus_cols if col in high_consensus.columns]\n",
    "    display(high_consensus[available_consensus_cols].head().round(4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
