{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Modelo de OneClassSVM entrenado con 4F de datos Astro, y predicción sobre datos Unid (no identificados)\n",
    "\n",
    "**Proyecto**: Detección de posibles fuentes de materia oscura usando ML en datos Fermi-LAT  \n",
    "**Autor**: Marta Canino Romero  \n",
    "**Fecha**: febrero-mayo 20225\n",
    "\n",
    "---\n",
    "\n",
    "## Descripción:\n",
    "\n",
    "Este notebook aplica un modelo **One-Class SVM** entrenado con datos de fuentes astrofísicas conocidas (ASTRO) usando las siguientes características:\n",
    "\n",
    "- E_peak\n",
    "- beta\n",
    "- sigma\n",
    "- betaRel\n",
    "\n",
    "Este modelo se entrena para identificar anomalías que puedan corresponder a posibles fuentes de materia oscura (UNIDs) en los datos no identificados del catálogo 4FGL.\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivos específicos:\n",
    "\n",
    "- Entrenar modelo OCSVM con [número de features] \n",
    "- Optimizar hiperparámetros (grid search sobre `nu` y `gamma`)\n",
    "- Evaluar sobre datos de validación y prueba\n",
    "- Aplicar modelo final sobre datos UNID para predicción\n",
    "\n",
    "---\n",
    "\n",
    "## Entrada de datos:\n",
    "\n",
    "- `../../data/processed/XY_bal_log_Rel/astro/XY_bal_log_Rel_astro.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../../data/processed/XY_bal_log_Rel/astro/astro_df.txt\"\n",
    "data_path = '../../data/processed/XY_bal_log_Rel/astro/astro_data_with_labels.txt'\n",
    "# df_astro = pd.read_csv(data_path, sep='\\s+')\n",
    "df_astro = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "print(f\"Dataset cargado. Forma: {df_astro.shape}\")\n",
    "print(f\"Nombres de las columnas: {list(df_astro.columns)}\")\n",
    "\n",
    "df_astro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de características\n",
    "features = ['Log(E_peak)', 'Log(E_peak)', 'Log(sigma)', 'Log(beta_Rel)']\n",
    "target = 'astro_DM'\n",
    "\n",
    "print(f\"Features seleccionadas: {features}\")\n",
    "print(f\"Columna objetivo: {target}\")\n",
    "\n",
    "# Comprobamos valores nulos\n",
    "print(\"\\n Valores faltantes por columna:\")\n",
    "print(df_astro[features + [target]].isnull().sum())\n",
    "\n",
    "print(\"\\n Muestra del dataset:\")\n",
    "display(df_astro[features + [target]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_astro,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"turquoise\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "\n",
    "plt.title(\"2D Unscaled ASTRO Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"Log(E_peak)\")\n",
    "plt.ylabel(\"Log(beta)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representación 3D\n",
    "x = df_astro['Log(E_peak)']\n",
    "y = df_astro['Log(beta)']\n",
    "z = df_astro['Log(sigma)']\n",
    "\n",
    "labels = df_astro['astro_DM']\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(x, y, z, c=labels, cmap='cool', edgecolor='k')\n",
    "\n",
    "ax.set_xlabel('Log(E_peak)')\n",
    "ax.set_ylabel('Log(beta)')\n",
    "ax.set_zlabel('Log(sigma)')\n",
    "plt.title('3D Unscaled ASTRO Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos las features dinámicamente\n",
    "X = df_astro[features].values\n",
    "y = df_astro[target].values\n",
    "\n",
    "print(f\"Forma del dataset: {X.shape}\")\n",
    "print(f\"Distribución de clases: {np.unique(y, return_counts=True)}\")\n",
    "\n",
    "# Como todos los datos son clase 0, stratify no es necesario y puede causar errores\n",
    "# Simplificamos a:\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nu_values = [0.005, 0.01, 0.02, 0.05]\n",
    "nu_values = [0.001, 0.002, 0.005, 0.01, 0.02, 0.05]\n",
    "# gamma_values = ['scale', 'auto'] + list(np.logspace(-3, 1, 5))\n",
    "gamma_values = ['scale', 'auto', 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "results = []\n",
    "best_outliers = np.inf # Cantidad de outliers, queremos que sea el menor posible\n",
    "best_score = 0.0  # F1 score (cuanto más alto, mejor)\n",
    "best_model = None\n",
    "best_params = {}\n",
    "\n",
    "for nu in nu_values:\n",
    "    for gamma in gamma_values:\n",
    "        model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "        model.fit(X_train)\n",
    "\n",
    "        # Predicciones\n",
    "        preds = model.predict(X_val_scaled)              # 1 = inlier, -1 = outlier\n",
    "        pred_labels = np.where(preds == 1, 0, 1)         # Mapear a 0 = normal, 1 = anomalía\n",
    "        true_labels = y_val.astype(int)                  # Aseguramos tipo int\n",
    "        n_outliers = np.sum(preds == -1)\n",
    "\n",
    "        # Evaluación\n",
    "        # f1 = f1_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "        results.append({'nu': nu, 'gamma': gamma, 'val_outliers': n_outliers})\n",
    "\n",
    "        \"\"\"\n",
    "        if f1 > best_score:\n",
    "            best_score = f1\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "        \"\"\"\n",
    "\n",
    "        if n_outliers < best_outliers:\n",
    "            best_outliers = n_outliers\n",
    "            best_model = model\n",
    "            best_params = {'nu': nu, 'gamma': gamma}\n",
    "\n",
    "# Resultados Finales\n",
    "print(\"Mejor combinación de hiperparámetros:\")\n",
    "print(f\"   - nu = {best_params['nu']}\")\n",
    "print(f\"   - gamma = {best_params['gamma']}\")\n",
    "print(f\"Outliers (val set): {best_outliers} de {len(X_val_scaled)} muestras\")\n",
    "\n",
    "# Convertimos resultados en DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "# display(df_results.sort_values(by='f1_score', ascending=False))\n",
    "display(df_results.sort_values(by='val_outliers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo final con todos los datos astro (train + val)\n",
    "X_final_train = np.vstack([X_train, X_val])\n",
    "y_final_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "# Scaler final - SOLO ajustar con datos de entrenamiento\n",
    "final_scaler = StandardScaler()\n",
    "X_train_scaled = final_scaler.fit_transform(X_final_train)\n",
    "\n",
    "# Entrenamos el modelo con los mejores hiperparámetros\n",
    "best_model = OneClassSVM(kernel='rbf', nu=best_params['nu'], gamma=best_params['gamma'])\n",
    "best_model.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRÍTICO: Solo transform (NO fit_transform) para datos de test\n",
    "X_test_scaled = final_scaler.transform(X_test)\n",
    "\n",
    "# Evaluamos sobre los datos de prueba (X_test_scaled) con el mejor modelo ya entrenado\n",
    "decision_scores_test = best_model.decision_function(X_test_scaled)\n",
    "test_preds = best_model.predict(X_test_scaled)\n",
    "\n",
    "n_test_outliers = np.sum(test_preds == -1)\n",
    "\n",
    "print(f\"Outliers en conjunto de datos reservado de prueba (test data): {n_test_outliers}\")\n",
    "test_labels = np.where(test_preds == 1, 0, 1)  # 1 = normal, -1 = outlier → mapeado\n",
    "true_labels_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMatriz de confusión (Test Set):\")\n",
    "print(confusion_matrix(true_labels_test, test_labels))\n",
    "\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, test_labels, target_names=[\"Normal\", \"Anomalía\"], zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de X_unids_scaled vs X_train_scaled 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], color=\"turquoise\", edgecolor='k', alpha=0.7, s=40, label=\"Train Data\")\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], color=\"green\", edgecolor='k', alpha=0.7, s=40, label=\"Train Data\")\n",
    "plt.title(\"2D Scaled Training Data vs Test Data\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre datos de validación\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], X_test_scaled[:, 2], c=test_preds, cmap='cool', edgecolor='k', s=30)\n",
    "\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel(features[2])\n",
    "plt.title(\"Distribución 3D con predicción (validación)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre datos de prueba\n",
    "fig = plt.figure(figsize=(6, 5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_test_scaled[:, 0], X_test_scaled[:, 1], X_test_scaled[:, 2], c=test_preds, cmap='cool', edgecolor='k', s=30)\n",
    "\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel(features[2])\n",
    "plt.title(\"Distribución 3D con predicción (test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unids_path = \"../../data/raw/unids_3F_beta_err_names.txt\"\n",
    "unids_path = \"../../data/processed/unids_log/unids_transformed_complete.txt\"\n",
    "\n",
    "df_unids = pd.read_csv(unids_path, sep='\\s+')\n",
    "df_unids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer y escalar\n",
    "X_unids_log = df_unids[[\"Log(E_peak)\", \"Log(beta)\", \"Log(sigma)\", \"Log(beta_Rel)\"]].values\n",
    "X_unids_scaled = scaler.transform(X_unids_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6), sharey=True)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_unids,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"UNIDS Data: E_peak vs Beta\")\n",
    "axes[0].set_xlabel(\"E_peak\")\n",
    "axes[0].set_ylabel(\"beta\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_unids,\n",
    "    x=\"Log(E_peak)\",\n",
    "    y=\"Log(beta)\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"UNIDS (Log): E_peak vs Beta\")\n",
    "axes[1].set_xlabel(\"E_peak (log10)\")\n",
    "axes[1].set_ylabel(\"\")  # hide repeated ylabel\n",
    "axes[1].grid(True)\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Scaled UNIDS: E_peak vs Beta\")\n",
    "axes[2].set_xlabel(\"E_peak (scaled)\")\n",
    "axes[2].set_ylabel(\"\")  # hide repeated ylabel\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de 3D de UNIDS\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X_unids_scaled[:, 0], X_unids_scaled[:, 1], X_unids_scaled[:, 2], color=\"gold\", edgecolor='k', alpha=0.7, s=40)\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('sigma_det (scaled)')\n",
    "plt.title('3D UNIDS Data (scaled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de unids después de escalar\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "plt.title(\"Scaled UNIDS Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de X_unids_scaled vs X_train_scaled 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], color=\"turquoise\", edgecolor='k', alpha=0.7, s=40, label=\"Train Data\")\n",
    "plt.scatter(X_unids_scaled[:, 0], X_unids_scaled[:, 1], color=\"gold\", edgecolor='k', alpha=0.7, s=40, label=\"UNIDS Data\")\n",
    "plt.title(\"2D Scaled Train Data vs UNIDS Data\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de UNIDs vs ASTRO 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter ASTRO (training data)\n",
    "ax.scatter(\n",
    "    X_train_scaled[:, 0], X_train_scaled[:, 1], X_train_scaled[:, 2],\n",
    "    color=\"steelblue\", edgecolor='k', alpha=0.2, s=60, label='ASTRO (train)',\n",
    ")\n",
    "\n",
    "# Scatter UNIDs (to predict)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[:, 0], X_unids_scaled[:, 1], X_unids_scaled[:, 2],\n",
    "    color=\"gold\", edgecolor='k', alpha=0.9, s=60, label='UNIDs',\n",
    "    marker='^'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('sigma_det (scaled)')\n",
    "ax.set_title('3D Scatter: ASTRO vs UNIDs (scaled)')\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones sobre UNIDS\n",
    "unids_preds = best_model.predict(X_unids_scaled)\n",
    "\n",
    "n_unids_outliers = np.sum(unids_preds == -1)\n",
    "n_unids_normals = np.sum(unids_preds == 1)\n",
    "\n",
    "print(f\" Predicted ASTRO-like: {n_unids_normals}\")\n",
    "print(f\" Predicted not ASTRO-like (anomalies): {n_unids_outliers}\")\n",
    "unids_labels = np.where(unids_preds == 1, 0, 1)  # 1 = normal, -1 = outlier → mapeado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers = X_unids_scaled[unids_preds == 1]\n",
    "outliers = X_unids_scaled[unids_preds == -1]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (likely astro)', alpha=0.6)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (potentially new)', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"UNIDs: Inlier vs Outlier (One-Class SVM)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre UNIDS\n",
    "\n",
    "# Get predictions from best model on UNIDs\n",
    "preds = best_model.predict(X_unids_scaled)  # 1 = inlier, -1 = outlier\n",
    "\n",
    "# Separate indices\n",
    "inlier_idx = preds == 1\n",
    "outlier_idx = preds == -1\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers (normal)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[inlier_idx, 0], X_unids_scaled[inlier_idx, 1], X_unids_scaled[inlier_idx, 2],\n",
    "    c='gold', edgecolor='k', s=30, label='Inlier (normal)', alpha=0.8\n",
    ")\n",
    "\n",
    "# Outliers (potential dark matter)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[outlier_idx, 0], X_unids_scaled[outlier_idx, 1], X_unids_scaled[outlier_idx, 2],\n",
    "    c='crimson', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('sigma_det (scaled)')\n",
    "ax.set_title(\"3D Prediction Results on UNIDs\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Anomaly Scoring - UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Evaluar cada muestra no identificada con el modelo entrenado\n",
    "# decision_function devuelve un valor continuo: cuanto más alto, más normal (positivo); cuanto más bajo, más anómalo (negativo)\n",
    "decision_scores = best_model.decision_function(X_unids_scaled)  # X_unids_scaled = muestras no etiquetadas, ya escaladas\n",
    "\n",
    "# Paso 2: Predecir si cada punto es inlier (1) o outlier (-1)\n",
    "unids_preds = best_model.predict(X_unids_scaled)  # 1 = normal, -1 = anomalía\n",
    "\n",
    "# Paso 3: Agregar los resultados al DataFrame original\n",
    "df_unids_log[\"svm_score\"] = decision_scores       # Puntaje bruto del modelo (positivo = normal)\n",
    "df_unids_log[\"prediction\"] = unids_preds          # Clasificación binaria: inlier o outlier\n",
    "\n",
    "# Paso 4: Invertimos el score para que valores más altos signifiquen más anomalía\n",
    "# Esto es útil para poder escalar la puntuación y ordenar más intuitivamente\n",
    "anom_scores = -decision_scores  # Ahora, valores grandes = más anómalos\n",
    "\n",
    "# Paso 5: Escalamos los scores de anomalía al rango [0, 100] para facilitar su interpretación\n",
    "anom_percent = MinMaxScaler(feature_range=(0, 100)).fit_transform(anom_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Guardamos el puntaje invertido y su porcentaje normalizado en el DataFrame\n",
    "df_unids_log[\"Anomaly_Score\"] = anom_scores\n",
    "df_unids_log[\"Anomaly_Rank(%)\"] = anom_percent  # 100 = más anómalo, 0 = más normal\n",
    "\n",
    "# Paso 6: Filtramos solo los puntos predichos como anómalos y los ordenamos por su score más alto\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1] \\\n",
    "                    .sort_values(by=\"Anomaly_Rank(%)\", ascending=False) \\\n",
    "                    .head(10)\n",
    "\n",
    "# Guardamos los índices (puede ser útil si queremos recuperar sus posiciones originales)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Paso 7: Guardamos los 10 más anómalos en un archivo\n",
    "top_anomalies.to_csv(\"../../data/processed/unids_most_anomalous_4F.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "# Paso 8: Mostramos en pantalla un resumen de las anomalías detectadas\n",
    "print(\"Top Most Anomalous UNID Sources (4F One-Class SVM):\")\n",
    "display(top_anomalies[['E_peak', 'beta', 'number', 'svm_score', 'Anomaly_Score', 'Anomaly_Rank(%)']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort anomaly scores and grab top N labels\n",
    "N = 10\n",
    "sorted_idx = np.argsort(-anom_percent)  # high anomaly % = more anomalous\n",
    "top_N_idx = sorted_idx[:N]\n",
    "\n",
    "top_labels = df_unids_log.iloc[top_N_idx]['number'].astype(str).values\n",
    "top_scores = anom_percent[top_N_idx]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(anom_percent, bins=50, color='blue', edgecolor='k', alpha=0.7)\n",
    "plt.title(\"Anomaly Percentage Distribution (UNID Sources)\")\n",
    "plt.xlabel(\"Anomaly % (higher = more anomalous)\")\n",
    "plt.ylabel(\"Number of Sources\")\n",
    "\n",
    "for i in range(N):\n",
    "    x = top_scores[i]\n",
    "    label = top_labels[i]\n",
    "    plt.axvline(x, color='crimson', linestyle='--', alpha=0.8)\n",
    "    plt.text(x + 0.5, 3 + (i % 2) * 2, f\"ID {label}\", rotation=90, color='crimson', ha='left', fontsize=9)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaled values (for consistent comparison)\n",
    "X_unids = X_unids_scaled  # already scaled\n",
    "\n",
    "# Separate inliers and outliers\n",
    "inliers = X_unids[unids_preds == 1]\n",
    "outliers = X_unids[unids_preds == -1]\n",
    "\n",
    "# Get anomaly info\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Extract for plotting\n",
    "E_peak = X_unids[:, 0]\n",
    "beta = X_unids[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# All points\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (astro-like)', alpha=0.5)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (anomaly)', alpha=0.7)\n",
    "\n",
    "# Highlight & label top anomalies\n",
    "for idx in most_anomalous_idx:\n",
    "    x = X_unids[idx, 0]\n",
    "    y = X_unids[idx, 1]\n",
    "    source_id = df_unids_log.loc[idx, 'number']\n",
    "    \n",
    "    plt.scatter(x, y, facecolors='none', edgecolors='black', linewidths=1.5, s=100)\n",
    "    plt.text(x + 0.1, y, str(int(source_id)), color='black', fontsize=9)\n",
    "\n",
    "# Labels and layout\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"UNID Sources: Inliers vs Anomalies (2D View with Annotations)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Original/log-transformed values for 3 relevant features\n",
    "x_vals = df_unids_log['E_peak'].values\n",
    "y_vals = df_unids_log['beta'].values\n",
    "z_vals = df_unids_log['sigma_det'].values  # or 'beta_Rel' for 3F.2\n",
    "\n",
    "# Use model predictions for coloring\n",
    "inlier_idx = df_unids_log['prediction'] == 1\n",
    "outlier_idx = df_unids_log['prediction'] == -1\n",
    "\n",
    "# Inliers\n",
    "ax.scatter(\n",
    "    x_vals[inlier_idx], y_vals[inlier_idx], z_vals[inlier_idx],\n",
    "    c='#1f77b4', edgecolor='k', s=30, label='Inlier (astro-like)', alpha=0.5\n",
    ")\n",
    "\n",
    "# Outliers\n",
    "ax.scatter(\n",
    "    x_vals[outlier_idx], y_vals[outlier_idx], z_vals[outlier_idx],\n",
    "    c='#d62728', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "# Annotate top anomalies\n",
    "top_anomalies = df_unids_log[df_unids_log['prediction'] == -1].sort_values('Anomaly_Rank(%)', ascending=False).head(10)\n",
    "for idx in top_anomalies.index:\n",
    "    ax.scatter(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx],\n",
    "        facecolors='none', edgecolors='black', linewidths=2, s=100\n",
    "    )\n",
    "    ax.text(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx] + 0.05,\n",
    "        str(int(df_unids_log.loc[idx, 'number'])),\n",
    "        color='black', fontsize=9\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('E_peak')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_zlabel('sigma_det')  # or 'beta_Rel'\n",
    "ax.set_title(\"4F UNID Sources – Anomalies in Original Feature Space\")\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.tick_params(colors='#333333')\n",
    "ax.xaxis.label.set_color('#333333')\n",
    "ax.yaxis.label.set_color('#333333')\n",
    "ax.zaxis.label.set_color('#333333')\n",
    "ax.title.set_color('#111111')\n",
    "ax.grid(color='#aaaaaa', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/4F_UNIDs_OneClassSVM_og.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "# Compare UNIDs most anomalous vs ANN most DM-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. Cargar los datos de unIDs (features)\n",
    "unids_3F = np.genfromtxt('../../data/raw/unids_3F_beta_err_names.txt', dtype='str') \n",
    "unids_3F_data = np.asarray(unids_3F[1:, :], dtype=float)\n",
    "unids_log = np.log10(unids_3F_data[:, [0,1,2,3]])\n",
    "\n",
    "N_unids = unids_log.shape[0]\n",
    "N_splits = 5\n",
    "N_Repeats = 1\n",
    "N_sample = N_splits * N_Repeats\n",
    "\n",
    "# === 2. Cargar las predicciones ANN 4F\n",
    "ann_unids_path = \"../../ANN_original/unids_DM_std_proba_check_repeated_kfold_rskf_4F_21.txt\"\n",
    "unids_DM_raw = np.genfromtxt(ann_unids_path, dtype='str')[1:]  # quitar cabecera\n",
    "unids_DM_data = np.asarray(unids_DM_raw, dtype=float)\n",
    "\n",
    "# === 3. Reconstruir matriz (N_unids, N_sample)\n",
    "unids_number = unids_DM_data[:N_unids, 0]  # índice de los unIDs\n",
    "prob_matrix = np.reshape(unids_DM_data[:, 1], (N_unids, N_sample))\n",
    "\n",
    "# === 4. Calcular media y desviación estándar por unID\n",
    "unids_mean = prob_matrix.mean(axis=1)\n",
    "unids_std = prob_matrix.std(axis=1, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Crear DataFrame con resultados ANN\n",
    "df_ann = pd.DataFrame({\n",
    "    'unid_idx': unids_number.astype(int),\n",
    "    'ann_mean_prob': unids_mean,\n",
    "    'ann_std_prob': unids_std\n",
    "})\n",
    "\n",
    "df_ann.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6. Asegurar coincidencia de identificadores\n",
    "df_unids_log['unid_idx'] = df_unids_log['number'].astype(int)\n",
    "\n",
    "# === 7. Unir con resultados de OCSVM\n",
    "df_combined = pd.merge(df_unids_log, df_ann, on=\"unid_idx\", how=\"inner\")\n",
    "\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Análisis de solapamiento\n",
    "print(\"Total unIDs ann:\", len(df_ann))\n",
    "print(\"Total unIDs ocsvm:\", len(df_unids_log))\n",
    "print(\"High ANN prob (≥0.9):\", (df_ann['ann_mean_prob'] >= 0.9).sum())\n",
    "print(\"High ANN prob (≥0.7):\", (df_ann['ann_mean_prob'] >= 0.7).sum())\n",
    "print(\"High ANN prob (≥0.5):\", (df_ann['ann_mean_prob'] >= 0.5).sum())\n",
    "print(\"Predicted anomalies (OCSVM):\", (df_unids_log['prediction'] == -1).sum())\n",
    "print(\"Anomaly rank ≥95%:\", (df_unids_log['Anomaly_Rank(%)'] >= 95).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 9. Extraer unIDs destacados por ambos modelos\n",
    "p_cut = 0.4\n",
    "anom_cut = 40\n",
    "\n",
    "top_candidates = df_combined[\n",
    "    (df_combined[\"ann_mean_prob\"] >= p_cut) &\n",
    "    (df_combined[\"Anomaly_Rank(%)\"] >= anom_cut)\n",
    "].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "\n",
    "print(\"Top UNIDs by ANN and OCSVM agreement:\")\n",
    "display(top_candidates[[\"unid_idx\", \"E_peak\", \"beta\", \"ann_mean_prob\", \"Anomaly_Rank(%)\", \"Anomaly_Score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_combined[\"ann_mean_prob\"], df_combined[\"Anomaly_Rank(%)\"], alpha=0.8)\n",
    "plt.axvline(p_cut, color='red', linestyle='--', label=f'ANN prob ≥ {p_cut}')\n",
    "plt.axhline(anom_cut, color='green', linestyle='--', label=f'Anomaly Rank ≥ {anom_cut}')\n",
    "plt.xlabel(\"Probabilidad media ANN 4F (DM-like)\")\n",
    "plt.ylabel(\"Rango de anomalía OCSVM 4F (%)\")\n",
    "plt.title(\"Comparación entre ANN 4F y OCSVM 4F en unIDs\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"comparacion_ann4f_ocsvm4f.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
