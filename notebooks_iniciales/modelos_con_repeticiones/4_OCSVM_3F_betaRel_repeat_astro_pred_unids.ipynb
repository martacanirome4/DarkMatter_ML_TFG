{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# üìì OCSVM - 3F (betaRel) - Validaci√≥n por Repetici√≥n\n",
    "\n",
    "**Proyecto**: Detecci√≥n de posibles fuentes de materia oscura usando ML en datos Fermi-LAT  \n",
    "**Autor**: Marta Canino Romero  \n",
    "**Fecha**: mayo 2025\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Descripci√≥n:\n",
    "\n",
    "Este notebook implementa un modelo **One-Class SVM** entrenado con datos de fuentes astrof√≠sicas conocidas (ASTRO) usando las siguientes caracter√≠sticas:\n",
    "\n",
    "- E_peak\n",
    "- beta\n",
    "- beta_Rel\n",
    "\n",
    "**A diferencia de otros notebooks, aqu√≠ el proceso se repite m√∫ltiples veces (con diferentes semillas aleatorias en los splits) para comprobar la robustez y variabilidad del modelo.** Cada iteraci√≥n realiza:\n",
    "\n",
    "1. Divisi√≥n de datos (train/val/test)\n",
    "2. Escalado\n",
    "3. B√∫squeda de hiperpar√°metros (grid search sobre `nu` y `gamma`)\n",
    "4. Evaluaci√≥n sobre validaci√≥n y prueba\n",
    "5. Registro de m√©tricas clave (f1-score, n√∫mero de outliers, matriz de confusi√≥n)\n",
    "\n",
    "Los resultados de cada iteraci√≥n se almacenan y analizan para estimar la estabilidad del modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Objetivos espec√≠ficos:\n",
    "\n",
    "- Evaluar la variabilidad del modelo OCSVM tras `N` repeticiones\n",
    "- Analizar la dispersi√≥n del mejor f1-score entre repeticiones\n",
    "- Comparar n√∫mero de anomal√≠as detectadas en cada iteraci√≥n\n",
    "- Obtener m√©tricas medias y desviaciones est√°ndar\n",
    "\n",
    "---\n",
    "\n",
    "## üóÇÔ∏è Entrada de datos:\n",
    "\n",
    "- `../../data/processed/XY_bal_log_Rel/astro/XY_bal_log_Rel_astro.txt`\n",
    "\n",
    "## üíæ Salida esperada:\n",
    "\n",
    "- Tabla resumen de m√©tricas por iteraci√≥n\n",
    "- Mejor combinaci√≥n de hiperpar√°metros promedio\n",
    "- Exportaci√≥n de anomal√≠as m√°s recurrentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, roc_curve, auc\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cargar dataset ---\n",
    "data_path = \"../../data/processed/XY_bal_log_Rel/astro/XY_bal_log_Rel_astro.txt\"\n",
    "df_astro = pd.read_csv(data_path, sep=r\"\\s+\")\n",
    "\n",
    "# Renombramos la columna target por claridad\n",
    "df_astro = df_astro.rename(columns={\"0,1=astro,DM\": \"class\"})\n",
    "\n",
    "# --- Comprobamos distribuci√≥n del dataset ---\n",
    "print(f\"üìÅ Dataset cargado. Forma: {df_astro.shape}\")\n",
    "print(f\"üß† Nombres de las columnas: {list(df_astro.columns)}\")\n",
    "\n",
    "display(df_astro.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Selecci√≥n de caracter√≠sticas ---\n",
    "features = ['E_peak', 'beta', 'beta_Rel']\n",
    "target = 'class'\n",
    "\n",
    "print(f\"‚úÖ Features seleccionadas: {features}\")\n",
    "print(f\"üéØ Columna objetivo: {target}\")\n",
    "\n",
    "# --- Comprobamos valores nulos ---\n",
    "print(\"\\nüîç Valores faltantes por columna:\")\n",
    "print(df_astro[features + [target]].isnull().sum())\n",
    "\n",
    "print(\"\\nüìå Muestra del dataset:\")\n",
    "display(df_astro[features + [target]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representaci√≥n 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=df_astro,\n",
    "    x=\"E_peak\",\n",
    "    y=\"beta\",\n",
    "    color=\"turquoise\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "\n",
    "plt.title(\"2D Unscaled ASTRO Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"E_peak\")\n",
    "plt.ylabel(\"beta\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representaci√≥n 3D\n",
    "x = df_astro['E_peak']\n",
    "y = df_astro['beta']\n",
    "z = df_astro['beta_Rel']\n",
    "\n",
    "labels = df_astro['class']\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(x, y, z, c=labels, cmap='cool', edgecolor='k')\n",
    "\n",
    "ax.set_xlabel('E_peak')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_zlabel('beta_Rel')\n",
    "plt.title('3D Unscaled ASTRO Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#¬†Entrenar modelo + Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üí• N√∫mero de repeticiones\n",
    "n_iterations = 5\n",
    "\n",
    "# Guardar resultados de todas las iteraciones\n",
    "all_iterations_results = []\n",
    "best_models = []  # opcional: guardar modelo por iteraci√≥n\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    print(f\"\\nüîÑ Iteraci√≥n {i+1}/{n_iterations}\")\n",
    "\n",
    "    # =============== 1Ô∏è‚É£ Split din√°mico por iteraci√≥n ===============\n",
    "    X = df_astro[features].values\n",
    "    y = df_astro[\"class\"].values\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.4, stratify=y, random_state=42 + i\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=99 + i\n",
    "    )\n",
    "\n",
    "    # =============== 2Ô∏è‚É£ Escalado ===============\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # =============== 3Ô∏è‚É£ Grid search en esta iteraci√≥n ===============\n",
    "    nu_values = [0.005, 0.01, 0.02, 0.05]\n",
    "    gamma_values = ['scale', 'auto'] + list(np.logspace(-3, 1, 5))\n",
    "\n",
    "    best_score = 0.0\n",
    "    best_model_iter = None\n",
    "    best_params_iter = {}\n",
    "    iteration_results = []\n",
    "\n",
    "    for nu in nu_values:\n",
    "        for gamma in gamma_values:\n",
    "            model = OneClassSVM(kernel='rbf', nu=nu, gamma=gamma)\n",
    "            model.fit(X_train_scaled)\n",
    "\n",
    "            preds = model.predict(X_val_scaled)\n",
    "            pred_labels = np.where(preds == 1, 0, 1)  # 1‚Üínormal, -1‚Üíoutlier\n",
    "            true_labels = y_val.astype(int)\n",
    "\n",
    "            f1 = f1_score(true_labels, pred_labels, pos_label=0)\n",
    "\n",
    "            iteration_results.append({'nu': nu, 'gamma': gamma, 'f1_score': f1})\n",
    "\n",
    "            if f1 > best_score:\n",
    "                best_score = f1\n",
    "                best_model_iter = model\n",
    "                best_params_iter = {'nu': nu, 'gamma': gamma}\n",
    "\n",
    "    print(f\"‚úÖ Mejor iteraci√≥n {i+1}: nu={best_params_iter['nu']}, gamma={best_params_iter['gamma']}, F1={best_score:.4f}\")\n",
    "\n",
    "    # Guardar resultados de esta iteraci√≥n\n",
    "    all_iterations_results.extend(\n",
    "        [dict(iter=i+1, **res) for res in iteration_results]\n",
    "    )\n",
    "\n",
    "    best_models.append(best_model_iter)  # opcional\n",
    "\n",
    "# üéâ Convertimos a DataFrame global\n",
    "df_all_results = pd.DataFrame(all_iterations_results)\n",
    "\n",
    "# Mostrar el top global\n",
    "display(df_all_results.sort_values(by='f1_score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Comparamos resultados de todas las iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(best_models):\n",
    "    test_preds = model.predict(X_test_scaled)\n",
    "    test_labels = np.where(test_preds == 1, 0, 1)\n",
    "    print(f\"\\nüìù Iteraci√≥n {i+1}\")\n",
    "    print(confusion_matrix(y_test, test_labels))\n",
    "    print(classification_report(y_test, test_labels, target_names=['Normal', 'Anomal√≠a']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Reentrenamos el modelo con los resultados de la 'mejor iteraci√≥n' (f1-score m√°s alto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: identificar hiperpar√°metros globales\n",
    "best_global = df_all_results.sort_values(by='f1_score', ascending=False).iloc[0]\n",
    "print(\"üéØ Mejor combinaci√≥n global:\")\n",
    "print(best_global)\n",
    "\n",
    "# Paso 2: reentrenar con X_train + X_val\n",
    "X_final_train = np.vstack([X_train, X_val])\n",
    "y_final_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "scaler_final = StandardScaler()\n",
    "X_final_train_scaled = scaler_final.fit_transform(X_final_train)\n",
    "X_test_scaled = scaler_final.transform(X_test)\n",
    "\n",
    "# Paso 3: entrenar modelo final\n",
    "final_model = OneClassSVM(kernel='rbf', nu=best_global['nu'], gamma=best_global['gamma'])\n",
    "final_model.fit(X_final_train_scaled)\n",
    "\n",
    "# Paso 4: evaluar en test\n",
    "test_preds = final_model.predict(X_test_scaled)\n",
    "test_labels = np.where(test_preds == 1, 0, 1)\n",
    "\n",
    "print(confusion_matrix(y_test, test_labels))\n",
    "print(classification_report(y_test, test_labels, target_names=['Normal', 'Anomal√≠a']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "unids_path = \"../../data/raw/unids_3F_beta_err_names.txt\"\n",
    "df_unids = pd.read_csv(unids_path, sep='\\s+')\n",
    "df_unids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos a logaritmo\n",
    "cols_to_log = [\"E_peak\", \"beta\", \"sigma_det\", \"beta_Rel\"]\n",
    "df_unids_log = df_unids.copy()\n",
    "df_unids_log[cols_to_log] = df_unids_log[cols_to_log].apply(lambda x: np.log10(x.clip(lower=1e-10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer y escalar\n",
    "X_unids_log = df_unids_log[[\"E_peak\", \"beta\", \"beta_Rel\"]].values\n",
    "X_unids_scaled = scaler.transform(X_unids_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create subplots ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6), sharey=True)\n",
    "\n",
    "# --- Plot 1: Raw UNIDS data ---\n",
    "sns.scatterplot(\n",
    "    data=df_unids,\n",
    "    x=\"E_peak\",\n",
    "    y=\"beta\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"UNIDS Data: E_peak vs Beta\")\n",
    "axes[0].set_xlabel(\"E_peak\")\n",
    "axes[0].set_ylabel(\"beta\")\n",
    "axes[0].grid(True)\n",
    "\n",
    "# --- Plot 2: Log-transformed UNIDS ---\n",
    "sns.scatterplot(\n",
    "    data=df_unids_log,\n",
    "    x=\"E_peak\",\n",
    "    y=\"beta\",\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"UNIDS (Log): E_peak vs Beta\")\n",
    "axes[1].set_xlabel(\"E_peak (log10)\")\n",
    "axes[1].set_ylabel(\"\")  # hide repeated ylabel\n",
    "axes[1].grid(True)\n",
    "\n",
    "# --- Plot 3: Scaled UNIDS ---\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40,\n",
    "    ax=axes[2]\n",
    ")\n",
    "axes[2].set_title(\"Scaled UNIDS: E_peak vs Beta\")\n",
    "axes[2].set_xlabel(\"E_peak (scaled)\")\n",
    "axes[2].set_ylabel(\"\")  # hide repeated ylabel\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de 3D de UNIDS\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "scatter = ax.scatter(X_unids_scaled[:, 0], X_unids_scaled[:, 1], X_unids_scaled[:, 2], color=\"gold\", edgecolor='k', alpha=0.7, s=40)\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('beta_Rel (scaled)')\n",
    "plt.title('3D UNIDS Data (scaled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de unids despu√©s de escalar\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.scatterplot(\n",
    "    x=X_unids_scaled[:, 0],\n",
    "    y=X_unids_scaled[:, 1],\n",
    "    color=\"gold\",  # \"skyblue\" \"cornflowerblue\"\n",
    "    edgecolor='k',\n",
    "    alpha=0.7,\n",
    "    s=40\n",
    ")\n",
    "plt.title(\"Scaled UNIDS Data: E_peak vs Beta\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de X_unids_scaled vs X_train_scaled 2D\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1], color=\"turquoise\", edgecolor='k', alpha=0.7, s=40, label=\"Train Data\")\n",
    "plt.scatter(X_unids_scaled[:, 0], X_unids_scaled[:, 1], color=\"gold\", edgecolor='k', alpha=0.7, s=40, label=\"UNIDS Data\")\n",
    "plt.title(\"2D Scaled Train Data vs UNIDS Data\")\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter de UNIDs vs ASTRO 3D\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter ASTRO (training data)\n",
    "ax.scatter(\n",
    "    X_train_scaled[:, 0], X_train_scaled[:, 1], X_train_scaled[:, 2],\n",
    "    color=\"steelblue\", edgecolor='k', alpha=0.2, s=60, label='ASTRO (train)',\n",
    ")\n",
    "\n",
    "# Scatter UNIDs (to predict)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[:, 0], X_unids_scaled[:, 1], X_unids_scaled[:, 2],\n",
    "    color=\"gold\", edgecolor='k', alpha=0.9, s=60, label='UNIDs',\n",
    "    marker='^'\n",
    ")\n",
    "\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('beta_Rel (scaled)')\n",
    "ax.set_title('3D Scatter: ASTRO vs UNIDs (scaled)')\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones sobre UNIDS\n",
    "unids_preds = final_model.predict(X_unids_scaled)\n",
    "\n",
    "n_unids_outliers = np.sum(unids_preds == -1)\n",
    "n_unids_normals = np.sum(unids_preds == 1)\n",
    "\n",
    "print(f\"üöÄ Predicted ASTRO-like: {n_unids_normals}\")\n",
    "print(f\"‚ùó Predicted not ASTRO-like (anomalies): {n_unids_outliers}\")\n",
    "unids_labels = np.where(unids_preds == 1, 0, 1)  # 1 = normal, -1 = outlier ‚Üí mapeado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "inliers = X_unids_scaled[unids_preds == 1]\n",
    "outliers = X_unids_scaled[unids_preds == -1]\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (likely astro)', alpha=0.6)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (potentially new)', alpha=0.6)\n",
    "\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"UNIDs: Inlier vs Outlier (One-Class SVM)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos predicciones en 3D sobre UNIDS\n",
    "\n",
    "# Get predictions from best model on UNIDs\n",
    "preds = final_model.predict(X_unids_scaled)  # 1 = inlier, -1 = outlier\n",
    "\n",
    "# Separate indices\n",
    "inlier_idx = preds == 1\n",
    "outlier_idx = preds == -1\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers (normal)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[inlier_idx, 0], X_unids_scaled[inlier_idx, 1], X_unids_scaled[inlier_idx, 2],\n",
    "    c='gold', edgecolor='k', s=30, label='Inlier (normal)', alpha=0.8\n",
    ")\n",
    "\n",
    "# Outliers (potential dark matter)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[outlier_idx, 0], X_unids_scaled[outlier_idx, 1], X_unids_scaled[outlier_idx, 2],\n",
    "    c='crimson', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('beta_Rel (scaled)')\n",
    "ax.set_title(\"3D Prediction Results on UNIDs\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "# Anomaly Scoring - UNIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_scores = final_model.decision_function(X_unids_scaled)  # Higher = more normal, lower = more anomalous\n",
    "\n",
    "unids_preds = final_model.predict(X_unids_scaled)  # 1 = inlier, -1 = outlier\n",
    "\n",
    "df_unids_log[\"svm_score\"] = decision_scores\n",
    "df_unids_log[\"prediction\"] = unids_preds\n",
    "\n",
    "anom_scores = -decision_scores  # Invert: higher = more anomalous\n",
    "anom_percent = MinMaxScaler(feature_range=(0, 100)).fit_transform(anom_scores.reshape(-1, 1)).flatten()\n",
    "\n",
    "df_unids_log[\"Anomaly_Score\"] = anom_scores\n",
    "df_unids_log[\"Anomaly_Rank(%)\"] = anom_percent\n",
    "\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "top_anomalies.to_csv(\"../../data/processed/unids_most_anomalous.txt\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Top Most Anomalous UNID Sources (3F One-Class SVM):\")\n",
    "display(top_anomalies[['number', 'Anomaly_Score', 'Anomaly_Rank(%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaled values (for consistent comparison)\n",
    "X_unids = X_unids_scaled  # already scaled\n",
    "\n",
    "# Separate inliers and outliers\n",
    "inliers = X_unids[unids_preds == 1]\n",
    "outliers = X_unids[unids_preds == -1]\n",
    "\n",
    "# Get anomaly info\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Extract for plotting\n",
    "E_peak = X_unids[:, 0]\n",
    "beta = X_unids[:, 1]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# All points\n",
    "plt.scatter(inliers[:, 0], inliers[:, 1], c='gold', edgecolors='k', label='Inlier (astro-like)', alpha=0.5)\n",
    "plt.scatter(outliers[:, 0], outliers[:, 1], c='red', edgecolors='k', label='Outlier (anomaly)', alpha=0.7)\n",
    "\n",
    "# Highlight & label top anomalies\n",
    "for idx in most_anomalous_idx:\n",
    "    x = X_unids[idx, 0]\n",
    "    y = X_unids[idx, 1]\n",
    "    source_id = df_unids_log.loc[idx, 'number']\n",
    "    \n",
    "    plt.scatter(x, y, facecolors='none', edgecolors='black', linewidths=1.5, s=100)\n",
    "    plt.text(x + 0.1, y, str(int(source_id)), color='black', fontsize=9)\n",
    "\n",
    "# Labels and layout\n",
    "plt.xlabel(\"E_peak (scaled)\")\n",
    "plt.ylabel(\"beta (scaled)\")\n",
    "plt.title(\"UNID Sources (3F w/betaRel) ‚Äì Inliers vs Anomalies with ID Labels\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/scaled/3F_betaRel_UNIDs_OneClassSVM_2D_scaled.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Original/log-transformed values for 3 relevant features\n",
    "x_vals = df_unids_log['E_peak'].values\n",
    "y_vals = df_unids_log['beta'].values\n",
    "z_vals = df_unids_log['sigma_det'].values  # or 'beta_Rel' for 3F.2\n",
    "\n",
    "# Use model predictions for coloring\n",
    "inlier_idx = df_unids_log['prediction'] == 1\n",
    "outlier_idx = df_unids_log['prediction'] == -1\n",
    "\n",
    "# Inliers\n",
    "ax.scatter(\n",
    "    x_vals[inlier_idx], y_vals[inlier_idx], z_vals[inlier_idx],\n",
    "    c='#1f77b4', edgecolor='k', s=30, label='Inlier (astro-like)', alpha=0.5\n",
    ")\n",
    "\n",
    "# Outliers\n",
    "ax.scatter(\n",
    "    x_vals[outlier_idx], y_vals[outlier_idx], z_vals[outlier_idx],\n",
    "    c='#d62728', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "# Annotate top anomalies\n",
    "top_anomalies = df_unids_log[df_unids_log['prediction'] == -1].sort_values('Anomaly_Rank(%)', ascending=False).head(10)\n",
    "for idx in top_anomalies.index:\n",
    "    ax.scatter(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx],\n",
    "        facecolors='none', edgecolors='black', linewidths=2, s=100\n",
    "    )\n",
    "    ax.text(\n",
    "        x_vals[idx], y_vals[idx], z_vals[idx] + 0.05,\n",
    "        str(int(df_unids_log.loc[idx, 'number'])),\n",
    "        color='black', fontsize=9\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('E_peak')\n",
    "ax.set_ylabel('beta')\n",
    "ax.set_zlabel('sigma_det')  # or 'beta_Rel'\n",
    "ax.set_title(\"3F w/betaRel UNID Sources ‚Äì Anomalies in Original Feature Space\")\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "ax.tick_params(colors='#333333')\n",
    "ax.xaxis.label.set_color('#333333')\n",
    "ax.yaxis.label.set_color('#333333')\n",
    "ax.zaxis.label.set_color('#333333')\n",
    "ax.title.set_color('#111111')\n",
    "ax.grid(color='#aaaaaa', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.savefig(\"../../outputs/figures/3F_betaRel_UNIDs_OneClassSVM_og.png\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top anomalies (already computed and sorted by anomaly rank)\n",
    "top_anomalies = df_unids_log[df_unids_log[\"prediction\"] == -1].sort_values(by=\"Anomaly_Rank(%)\", ascending=False).head(10)\n",
    "most_anomalous_idx = top_anomalies.index\n",
    "\n",
    "# Prepare figure\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Inliers (gold)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[inlier_idx, 0],\n",
    "    X_unids_scaled[inlier_idx, 1],\n",
    "    X_unids_scaled[inlier_idx, 2],\n",
    "    c='gold', edgecolor='k', s=30, label='Inlier (astro-like)', alpha=0.5\n",
    ")\n",
    "\n",
    "# Outliers (crimson)\n",
    "ax.scatter(\n",
    "    X_unids_scaled[outlier_idx, 0],\n",
    "    X_unids_scaled[outlier_idx, 1],\n",
    "    X_unids_scaled[outlier_idx, 2],\n",
    "    c='crimson', marker='^', edgecolor='k', s=50, label='Outlier (anomaly)', alpha=0.9\n",
    ")\n",
    "\n",
    "# Annotate top anomalies\n",
    "for idx in most_anomalous_idx:\n",
    "    x = X_unids_scaled[idx, 0]\n",
    "    y = X_unids_scaled[idx, 1]\n",
    "    z = X_unids_scaled[idx, 2]\n",
    "    source_id = df_unids_log.loc[idx, 'number']\n",
    "\n",
    "    ax.scatter(x, y, z, facecolors='none', edgecolors='black', linewidths=2, s=100)\n",
    "    ax.text(x, y, z + 0.05, str(int(source_id)), color='black', fontsize=9)\n",
    "\n",
    "# Axes labels\n",
    "ax.set_xlabel('E_peak (scaled)')\n",
    "ax.set_ylabel('beta (scaled)')\n",
    "ax.set_zlabel('sigma_det (scaled)')\n",
    "ax.set_title(\"UNID Sources (3F w/betaRel) ‚Äì Inliers vs Anomalies with ID Labels\")\n",
    "\n",
    "ax.legend(loc='upper left')\n",
    "plt.savefig(\"../../outputs/figures/scaled/3F_betaRel_UNIDs_OneClassSVM_3D_scaled_2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# Compare UNIDs most anomalous vs ANN most DM-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_unids_path = \"../ANN_4F/unids_DM_std_proba_check_repeated_kfold_rskf_4F_21.txt\"\n",
    "\n",
    "raw_ann_unids_data = np.genfromtxt(ann_unids_path, dtype='str')\n",
    "ann_unids_data = np.asarray(raw_ann_unids_data[1:], dtype=float)  # Salta cabecera\n",
    "n_samples = ann_unids_data.shape[1] - 1\n",
    "\n",
    "# Build DataFrame with probabilities per fold\n",
    "columns = ['number'] + [f'prob_{i}' for i in range(n_samples)]\n",
    "df_unids_ann = pd.DataFrame(ann_unids_data, columns=columns)\n",
    "\n",
    "# Average probabilities per UNID (group by number)\n",
    "df_mean_unids_ann = df_unids_ann.groupby('number').mean().reset_index()\n",
    "df_mean_unids_ann['prob_ann'] = df_mean_unids_ann[[f'prob_{i}' for i in range(n_samples)]].mean(axis=1)\n",
    "\n",
    "df_mean_unids_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 sources with the highest mean ANN DM probability\n",
    "top_ann_unids = df_mean_unids_ann.sort_values('prob_ann', ascending=False).head(50)\n",
    "\n",
    "# Display results\n",
    "print(\"üîù Top 10 UNIDs with highest ANN-based DM probability:\")\n",
    "display(top_ann_unids[['number', 'prob_ann']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîù Top 10 UNIDs with highest OCSVM-based anomaly scoring:\")\n",
    "display(top_anomalies[['number', 'Anomaly_Rank(%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Data types before conversion:\")\n",
    "print(\"top_ann_unids['number'] dtype:\", top_ann_unids['number'].dtype)\n",
    "print(\"top_anomalies['number'] dtype:\", top_anomalies['number'].dtype)\n",
    "\n",
    "# Convert both to same type for comparison\n",
    "top_ann_unids['number'] = top_ann_unids['number'].round().astype(int)\n",
    "top_anomalies['number'] = top_anomalies['number'].round().astype(int)\n",
    "\n",
    "print(\"\\nüîç Data types after conversion:\")\n",
    "print(\"top_ann_unids['number'] dtype:\", top_ann_unids['number'].dtype)\n",
    "print(\"top_anomalies['number'] dtype:\", top_anomalies['number'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_ids = set(top_ann_unids['number']).intersection(set(top_anomalies['number']))\n",
    "print(f\"üéØ Common UNID IDs: {sorted(list(common_ids))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_common = pd.merge(\n",
    "    top_ann_unids[['number', 'prob_ann']],\n",
    "    top_anomalies[['number', 'Anomaly_Rank(%)']],\n",
    "    on='number'\n",
    ")\n",
    "display(df_common)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv DarkMatter_TFG)",
   "language": "python",
   "name": "venv-tfg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
